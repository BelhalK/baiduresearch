\begin{thebibliography}{8}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Capp{\'e} and Moulines(2009)]{cappe2009line}
O.~Capp{\'e} and E.~Moulines.
\newblock On-line expectation--maximization algorithm for latent data models.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 71\penalty0 (3):\penalty0 593--613, 2009.

\bibitem[Chen et~al.(2018)Chen, Zhu, Teh, and Zhang]{chen2018stochastic}
J.~Chen, J.~Zhu, Y.~W. Teh, and T.~Zhang.
\newblock Stochastic expectation maximization with variance reduction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  7978--7988, 2018.

\bibitem[Defazio et~al.(2014)Defazio, Bach, and
  Lacoste-Julien]{defazio2014saga}
A.~Defazio, F.~Bach, and S.~Lacoste-Julien.
\newblock Saga: A fast incremental gradient method with support for
  non-strongly convex composite objectives.
\newblock In \emph{Advances in neural information processing systems}, pages
  1646--1654, 2014.

\bibitem[Dempster et~al.(1977)Dempster, Laird, and Rubin]{dempster1977Maximum}
A.~P. Dempster, N.~M. Laird, and D.~B. Rubin.
\newblock Maximum likelihood from incomplete data via the {EM} algorithm.
\newblock \emph{Journal of the royal statistical society. Series B
  (methodological)}, pages 1--38, 1977.

\bibitem[Ghadimi and Lan(2013)]{ghadimi2013stochastic}
S.~Ghadimi and G.~Lan.
\newblock Stochastic first-and zeroth-order methods for nonconvex stochastic
  programming.
\newblock \emph{SIAM Journal on Optimization}, 23\penalty0 (4):\penalty0
  2341--2368, 2013.

\bibitem[McLachlan and Krishnan(2007)]{mclachlan2007algorithm}
G.~McLachlan and T.~Krishnan.
\newblock \emph{The {EM} algorithm and extensions}, volume 382.
\newblock John Wiley \& Sons, 2007.

\bibitem[Neal and Hinton(1998)]{neal1998view}
R.~M. Neal and G.~E. Hinton.
\newblock A view of the {EM} algorithm that justifies incremental, sparse, and
  other variants.
\newblock In \emph{Learning in graphical models}, pages 355--368. Springer,
  1998.

\bibitem[Reddi et~al.(2016)Reddi, Sra, P{\'o}czos, and Smola]{reddi2016fast}
S.~J. Reddi, S.~Sra, B.~P{\'o}czos, and A.~Smola.
\newblock Fast incremental method for nonconvex optimization.
\newblock \emph{arXiv preprint arXiv:1603.06159}, 2016.

\end{thebibliography}
