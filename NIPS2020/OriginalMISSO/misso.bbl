\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2015)Abadi, Agarwal, Barham, Brevdo, Chen, Citro,
  Corrado, Davis, Dean, Devin, Ghemawat, Goodfellow, Harp, Irving, Isard, Jia,
  Jozefowicz, Kaiser, Kudlur, Levenberg, Man\'{e}, Monga, Moore, Murray, Olah,
  Schuster, Shlens, Steiner, Sutskever, Talwar, Tucker, Vanhoucke, Vasudevan,
  Vi\'{e}gas, Vinyals, Warden, Wattenberg, Wicke, Yu, and
  Zheng]{tensorflow2015-whitepaper}
M.~Abadi, A.~Agarwal, P.~Barham, E.~Brevdo, Z.~Chen, C.~Citro, G.~Corrado,
  A.~Davis, J.~Dean, M.~Devin, S.~Ghemawat, I.~Goodfellow, A.~Harp, G.~Irving,
  M.~Isard, Y.~Jia, R.~Jozefowicz, L.~Kaiser, M.~Kudlur, J.~Levenberg,
  D.~Man\'{e}, R.~Monga, S.~Moore, D.~Murray, C.~Olah, M.~Schuster, J.~Shlens,
  B.~Steiner, I.~Sutskever, K.~Talwar, P.~Tucker, V.~Vanhoucke, V.~Vasudevan,
  F.~Vi\'{e}gas, O.~Vinyals, P.~Warden, M.~Wattenberg, M.~Wicke, Y.~Yu, and
  X.~Zheng.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock URL \url{https://www.tensorflow.org/}.
\newblock Software available from tensorflow.org.

\bibitem[Bishop(2006)]{bishop2006pattern}
C.~M. Bishop.
\newblock \emph{Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{blei2017vi}
D.~M. Blei, A.~Kucukelbir, and J.~D. McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American Statistical Association}, 112\penalty0
  (518):\penalty0 859--877, 2017.
\newblock \doi{10.1080/01621459.2017.1285773}.
\newblock URL \url{https://doi.org/10.1080/01621459.2017.1285773}.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
C.~Blundell, J.~Cornebise, K.~Kavukcuoglu, and D.~Wierstra.
\newblock Weight uncertainty in neural network.
\newblock In \emph{International Conference on Machine Learning}, pages
  1613--1622, 2015.

\bibitem[Boucheron et~al.(2013)Boucheron, Lugosi, and
  Massart]{boucheron2013concentration}
S.~Boucheron, G.~Lugosi, and P.~Massart.
\newblock \emph{Concentration inequalities: A nonasymptotic theory of
  independence}.
\newblock Oxford university press, 2013.

\bibitem[Delyon et~al.(1999)Delyon, Lavielle, and Moulines]{delyon1999}
B.~Delyon, M.~Lavielle, and E.~Moulines.
\newblock Convergence of a stochastic approximation version of the em
  algorithm.
\newblock \emph{Ann. Statist.}, 27\penalty0 (1):\penalty0 94--128, 03 1999.
\newblock \doi{10.1214/aos/1018031103}.
\newblock URL \url{https://doi.org/10.1214/aos/1018031103}.

\bibitem[Dillon et~al.(2017)Dillon, Langmore, Tran, Brevdo, Vasudevan, Moore,
  Patton, Alemi, Hoffman, and Saurous]{dillon2017tfp}
J.~V. Dillon, I.~Langmore, D.~Tran, E.~Brevdo, S.~Vasudevan, D.~Moore,
  B.~Patton, A.~Alemi, M.~D. Hoffman, and R.~A. Saurous.
\newblock Tensorflow distributions.
\newblock \emph{CoRR}, abs/1711.10604, 2017.
\newblock URL \url{http://arxiv.org/abs/1711.10604}.

\bibitem[Doukhan et~al.(1995)Doukhan, Massart, and Rio]{doukhan1995invariance}
P.~Doukhan, P.~Massart, and E.~Rio.
\newblock Invariance principles for absolutely regular empirical processes.
\newblock In \emph{Annales de l'IHP Probabilit{\'e}s et statistiques},
  volume~31, pages 393--427, 1995.

\bibitem[Fletcher et~al.(2002)Fletcher, Gould, Leyffer, Toint, and
  W{\"a}chter]{fletcher2002global}
R.~Fletcher, N.~I. Gould, S.~Leyffer, P.~L. Toint, and A.~W{\"a}chter.
\newblock Global convergence of a trust-region sqp-filter algorithm for general
  nonlinear programming.
\newblock \emph{SIAM Journal on Optimization}, 13\penalty0 (3):\penalty0
  635--659, 2002.

\bibitem[Ghahramani(2015)]{ghahramani2015probabilistic}
Z.~Ghahramani.
\newblock Probabilistic machine learning and artificial intelligence.
\newblock \emph{Nature}, 521\penalty0 (7553):\penalty0 452--459, May 2015.
\newblock \doi{10.1038/nature14541}.
\newblock URL \url{https://www.ncbi.nlm.nih.gov/pubmed/26017444/}.
\newblock On Probabilistic models.

\bibitem[Jiang et~al.(2018)Jiang, Josse, and Lavielle]{jiang2018logistic}
W.~Jiang, J.~Josse, and M.~Lavielle.
\newblock Logistic regression with missing covariates--parameter estimation,
  model selection and prediction.
\newblock 2018.

\bibitem[Jordan et~al.(1999)Jordan, Ghahramani, Jaakkola, and
  Saul]{jordan1999var}
M.~I. Jordan, Z.~Ghahramani, T.~S. Jaakkola, and L.~K. Saul.
\newblock An introduction to variational methods for graphical models.
\newblock \emph{Mach. Learn.}, 37\penalty0 (2):\penalty0 183--233, Nov. 1999.
\newblock ISSN 0885-6125.
\newblock \doi{10.1023/A:1007665907178}.
\newblock URL \url{https://doi.org/10.1023/A:1007665907178}.

\bibitem[Kingma and Ba(2015)]{kingma:adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{3rd International Conference on Learning Representations,
  {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track
  Proceedings}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6980}.

\bibitem[Kingma and Welling(2014)]{kingma}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{2nd International Conference on Learning Representations,
  {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track
  Proceedings}, 2014.
\newblock URL \url{http://arxiv.org/abs/1312.6114}.

\bibitem[Lange(2016)]{lange2016mm}
K.~Lange.
\newblock \emph{MM Optimization Algorithms}.
\newblock SIAM-Society for Industrial and Applied Mathematics, USA, 2016.
\newblock ISBN 1611974399, 9781611974393.

\bibitem[LeCun(1998)]{lecun1998mnist}
Y.~LeCun.
\newblock The mnist database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, Haffner,
  et~al.]{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, P.~Haffner, et~al.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Li and Gal(2017)]{li2017dropout}
Y.~Li and Y.~Gal.
\newblock Dropout inference in bayesian neural networks with alpha-divergences.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2052--2061. JMLR. org, 2017.

\bibitem[Mairal(2015)]{mairal2015miso}
J.~Mairal.
\newblock Incremental majorization-minimization optimization with application
  to large-scale machine learning.
\newblock \emph{SIAM J. Optim.}, 25\penalty0 (2):\penalty0 829--855, 2015.
\newblock ISSN 1052-6234.
\newblock \doi{10.1137/140957639}.
\newblock URL \url{https://doi.org/10.1137/140957639}.

\bibitem[McLachlan and Krishnan(2008)]{mcLachlan2008em}
G.~J. McLachlan and T.~Krishnan.
\newblock \emph{The {EM} algorithm and extensions}.
\newblock Wiley Series in Probability and Statistics. Wiley-Interscience [John
  Wiley \& Sons], Hoboken, NJ, second edition, 2008.
\newblock ISBN 978-0-471-20170-0.
\newblock \doi{10.1002/9780470191613}.
\newblock URL \url{https://doi.org/10.1002/9780470191613}.

\bibitem[Meyn and Tweedie(2012)]{meyn2012markov}
S.~P. Meyn and R.~L. Tweedie.
\newblock \emph{Markov chains and stochastic stability}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Neal(2012)]{neal2012bayesian}
R.~M. Neal.
\newblock \emph{Bayesian learning for neural networks}, volume 118.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Paisley et~al.(2012)Paisley, Blei, and Jordan]{paisley2013}
J.~Paisley, D.~Blei, and M.~Jordan.
\newblock Variational bayesian inference with stochastic search.
\newblock In \emph{ICML}. icml.cc / Omnipress, 2012.

\bibitem[Polson et~al.(2017)Polson, Sokolov, et~al.]{polson2017deep}
N.~G. Polson, V.~Sokolov, et~al.
\newblock Deep learning: a bayesian perspective.
\newblock \emph{Bayesian Analysis}, 12\penalty0 (4):\penalty0 1275--1304, 2017.

\bibitem[Razaviyayn et~al.(2013)Razaviyayn, Hong, and
  Luo]{razaviyayn2013unified}
M.~Razaviyayn, M.~Hong, and Z.-Q. Luo.
\newblock A unified convergence analysis of block successive minimization
  methods for nonsmooth optimization.
\newblock \emph{SIAM Journal on Optimization}, 23\penalty0 (2):\penalty0
  1126--1153, 2013.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
D.~J. Rezende, S.~Mohamed, and D.~Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{International Conference on Machine Learning}, pages
  1278--1286, 2014.

\bibitem[Schmidt et~al.(2017)Schmidt, Le~Roux, and Bach]{schmidt2017minimizing}
M.~Schmidt, N.~Le~Roux, and F.~Bach.
\newblock Minimizing finite sums with the stochastic average gradient.
\newblock \emph{Mathematical Programming}, 162\penalty0 (1-2):\penalty0
  83--112, 2017.

\bibitem[Shapiro et~al.(2009)Shapiro, Dentcheva, and
  Ruszczy{\'n}ski]{shapiro2009lectures}
A.~Shapiro, D.~Dentcheva, and A.~Ruszczy{\'n}ski.
\newblock \emph{Lectures on stochastic programming: modeling and theory}.
\newblock SIAM, 2009.

\bibitem[Sutskever et~al.(2013)Sutskever, Martens, Dahl, and
  Hinton]{sutskever2013importance}
I.~Sutskever, J.~Martens, G.~Dahl, and G.~Hinton.
\newblock On the importance of initialization and momentum in deep learning.
\newblock In \emph{International conference on machine learning}, pages
  1139--1147, 2013.

\bibitem[Wei and Tanner(1990)]{wei1990mcem}
G.~C.~G. Wei and M.~A. Tanner.
\newblock A monte carlo implementation of the em algorithm and the poor man's
  data augmentation algorithms.
\newblock \emph{Journal of the American Statistical Association}, 85\penalty0
  (411):\penalty0 699--704, 1990.
\newblock \doi{10.1080/01621459.1990.10474930}.
\newblock URL
  \url{https://www.tandfonline.com/doi/abs/10.1080/01621459.1990.10474930}.

\end{thebibliography}
