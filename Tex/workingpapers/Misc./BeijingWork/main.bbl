\begin{thebibliography}{10}

\bibitem{chen2020decent}
Xiangyi Chen, \textbf{B. Karimi}, Weijie Zhao, and Ping Li.
\newblock Convergent adaptive gradient methods in decentralized optimization.
\newblock {\em Submitted}, 2020.

\bibitem{had2020}
Farzin Haddadpour, \textbf{B. Karimi}, Ping Li, and Xiaoyun Li.
\newblock {FedSKETCH}: Communication-efficient federated learning via
  sketching.
\newblock {\em Submitted}, 2020.

\bibitem{ren2020vfg}
Shaogang Ren, Yang Zhao, \textbf{B. Karimi}, and Ping Li.
\newblock {VFG}: Variational flow graphical model with hierarchical latent
  structure.
\newblock {\em Submitted}, 2020.

\bibitem{karimi2020hwa}
\textbf{B. Karimi} and Ping Li.
\newblock {HWA}: Hyperparameters weight averaging bayesian neural networks.
\newblock {\em Submitted}, 2020.

\bibitem{karimi2020tts}
\textbf{B. Karimi} and Ping Li.
\newblock Two timescale stochastic em algorithms.
\newblock {\em Submitted}, 2020.

\bibitem{karimi2020lars}
\textbf{B. Karimi}, Xiaoyun Li, and Ping Li.
\newblock Layerwise and dimensionwise adaptive local ams method for federated
  learning.
\newblock {\em Work in progress}, 2020.

\bibitem{karimi2020misso}
\textbf{B. Karimi}, Hoi-To Wai, Eric Moulines, and Ping Li.
\newblock {MISSO}: Minimization by incremental stochastic surrogate
  optimization for large scale nonconvex problems.
\newblock {\em Submitted}, 2020.

\bibitem{karimi2020anila}
\textbf{B. Karimi}, Jianwen Xie, and Ping Li.
\newblock Anila: Anisotropic langevin dynamics for training energy-based
  models.
\newblock {\em Work in progress}, 2020.

\bibitem{kun2020}
Jun-Kun Wang, Xiaoyun Li, \textbf{B. Karimi}, and Ping Li.
\newblock An optimistic acceleration of amsgrad for nonconvex optimization.
\newblock {\em Submitted}, 2020.

\bibitem{zhou2020towards}
Yingxue Zhou, \textbf{B. Karimi}, Jinxing Yu, Zhiqiang Xu, and Ping Li.
\newblock Towards better generalization of adaptive gradient methods.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  pages 1--10, 2020.

\end{thebibliography}
