\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{madigan1995bayesian,hruschka2007bayesian}
\citation{koller2007graphical}
\citation{bilmes2005graphical}
\citation{shwe1990probabilistic}
\citation{jordan1999graphical}
\citation{sanner2012symbolic}
\citation{kahle2008junction}
\citation{jordan1999introduction}
\citation{salimans2015markov}
\citation{hoffman2013stochastic,kingma2013auto,liu2016stein}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{xing2012generalized}
\citation{winn2005variational}
\citation{kingma2018glow,rezende2015variational}
\citation{tabak2010density}
\citation{Dinh2016DensityEU,rippel2013high}
\citation{rezende2015variational}
\citation{Dinh2016DensityEU,dinh2014nice,de2020block,ho2019flow++,papamakarios2019normalizing}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{2}{section.2}}
\newlabel{sec:prelim}{{2}{2}{Preliminaries}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Normalizing flows}{2}{subsection.2.1}}
\newlabel{subsec:nf}{{2.1}{2}{Normalizing flows}{subsection.2.1}{}}
\citation{bishop2003vibes}
\newlabel{eq:flow}{{1}{3}{Normalizing flows}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Variational inference}{3}{subsection.2.2}}
\newlabel{eq:vi_elbo}{{2}{3}{Variational inference}{equation.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Variational graphical models}{3}{subsection.2.3}}
\citation{Dinh2016DensityEU}
\@writefile{toc}{\contentsline {section}{\numberline {3}Variational Flow Graphical Model}{4}{section.3}}
\newlabel{sec:main}{{3}{4}{Variational Flow Graphical Model}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The evidence lower bound of Variational Flow Graphical Models}{4}{subsection.3.1}}
\newlabel{eq:elbo_tree}{{5}{4}{The evidence lower bound of Variational Flow Graphical Models}{equation.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  {\relax \fontsize  {9}{10pt}\selectfont  (Left) The structure of one node. Node $\mathbf  {h}^{2, 1}$ connects with its children with invertible functions. The messages from its children are aggregated at $\mathbf  {h}^{2,1}$. (Right) An illustration of the latent structure from layer $l-1$ to $l+1$. $\mathbf  {h}^{l, i}$ means the $i$th latent variable in layer $l$.}\relax }}{5}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:node_tree}{{1}{5}{{\small (Left) The structure of one node. Node $\mathbf {h}^{2, 1}$ connects with its children with invertible functions. The messages from its children are aggregated at $\mathbf {h}^{2,1}$. (Right) An illustration of the latent structure from layer $l-1$ to $l+1$. $\mathbf {h}^{l, i}$ means the $i$th latent variable in layer $l$.}\relax }{figure.caption.1}{}}
\newlabel{eq:elbo_dag}{{6}{5}{The evidence lower bound of Variational Flow Graphical Models}{equation.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces (Left) Aggregation with average. (Right) Aggregation with concatenation. \relax }}{5}{figure.caption.2}}
\newlabel{fig:node_aggre}{{2}{5}{(Left) Aggregation with average. (Right) Aggregation with concatenation. \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Node Aggregation}{5}{subsection.3.2}}
\newlabel{eq:average}{{7}{5}{Node Aggregation}{equation.3.7}{}}
\newlabel{eq:yllk}{{8}{6}{Node Aggregation}{equation.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Inference on Sub-graphs }{6}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces {\relax \fontsize  {9}{10pt}\selectfont  (Left) Inference of single aggregation node model. Node 4 aggregates from node 1 and 2, and pass the updated state to node 3 for prediction. (Right) Inference on a DAG model. Observed node states are gathered in node 5 to predict the state of node 4.}\relax }}{6}{figure.caption.3}}
\newlabel{fig:two_layer_infer}{{3}{6}{{\small (Left) Inference of single aggregation node model. Node 4 aggregates from node 1 and 2, and pass the updated state to node 3 for prediction. (Right) Inference on a DAG model. Observed node states are gathered in node 5 to predict the state of node 4.}\relax }{figure.caption.3}{}}
\newlabel{lm:apprx}{{1}{6}{}{lemma.1}{}}
\newlabel{eq:cond_llk}{{9}{6}{}{equation.3.9}{}}
\citation{Khemakhem20a,Sorrenson2020}
\newlabel{rmk:apprx_mul}{{1}{7}{}{remark.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Algorithm and Implementation}{7}{subsection.3.4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Inference model parameters with forward and backward message propagation\relax }}{7}{algorithm.1}}
\newlabel{alg:main}{{1}{7}{Inference model parameters with forward and backward message propagation\relax }{algorithm.1}{}}
\newlabel{line:forward}{{5}{7}{Inference model parameters with forward and backward message propagation\relax }{ALC@unique.5}{}}
\newlabel{line:backward}{{9}{7}{Inference model parameters with forward and backward message propagation\relax }{ALC@unique.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Theory}{7}{section.4}}
\newlabel{sec:theory}{{4}{7}{Theory}{section.4}{}}
\newlabel{eq:exp_h}{{10}{7}{Theory}{equation.4.10}{}}
\citation{bengio2013representation}
\citation{scikit-learn}
\newlabel{thm:identif}{{1}{8}{}{theorem.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical Experiments}{8}{section.5}}
\newlabel{sec:numerical}{{5}{8}{Numerical Experiments}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Missing entries imputation}{8}{subsection.5.1}}
\citation{Dua:2019}
\citation{Karaletsos2015BayesianRL,Glorot2011DomainAF,Higgins17,Kim18,Eastwood18}
\citation{Chen18}
\citation{Eastwood18}
\citation{Eastwood18}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces ELBO on the synthetic data\relax }}{9}{figure.4}}
\newlabel{fig:elbo}{{4}{9}{ELBO on the synthetic data\relax }{figure.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Imputation Results on Synthetic Data.\relax }}{9}{table.1}}
\newlabel{tab:causality2}{{1}{9}{Imputation Results on Synthetic Data.\relax }{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Imputation with $\mathsf  {Mask}$ on the child nodes [0, 1, 2, 3] indicated by colored legends. \relax }}{9}{figure.caption.4}}
\newlabel{fig:mse}{{5}{9}{Imputation with $\mathsf {Mask}$ on the child nodes [0, 1, 2, 3] indicated by colored legends. \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Disentanglement on MNIST}{9}{subsection.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{9}{section.6}}
\newlabel{sec:conclusion}{{6}{9}{Conclusion}{section.6}{}}
\bibstyle{iclr2021_conference}
\bibdata{references}
\bibcite{bengio2013representation}{{1}{2013}{{Bengio et~al.}}{{Bengio, Courville, and Vincent}}}
\bibcite{bilmes2005graphical}{{2}{2005}{{Bilmes \& Bartels}}{{Bilmes and Bartels}}}
\bibcite{bishop2003vibes}{{3}{2003}{{Bishop et~al.}}{{Bishop, Spiegelhalter, and Winn}}}
\bibcite{Chen18}{{4}{2018}{{Chen et~al.}}{{Chen, Li, Grosse, and Duvenaud}}}
\bibcite{de2020block}{{5}{2020}{{De~Cao et~al.}}{{De~Cao, Aziz, and Titov}}}
\bibcite{dinh2014nice}{{6}{2014}{{Dinh et~al.}}{{Dinh, Krueger, and Bengio}}}
\bibcite{Dinh2016DensityEU}{{7}{2016}{{Dinh et~al.}}{{Dinh, Sohl-Dickstein, and Bengio}}}
\bibcite{Dua:2019}{{8}{2017}{{Dua \& Graff}}{{Dua and Graff}}}
\bibcite{Eastwood18}{{9}{2018}{{Eastwood \& Williams}}{{Eastwood and Williams}}}
\bibcite{Glorot2011DomainAF}{{10}{2011}{{Glorot et~al.}}{{Glorot, Bordes, and Bengio}}}
\bibcite{Higgins17}{{11}{2017}{{Higgins et~al.}}{{Higgins, Matthey, Pal, Burgess, Glorot, Botvinick, Mohamed, and Lerchner}}}
\bibcite{ho2019flow++}{{12}{2019}{{Ho et~al.}}{{Ho, Chen, Srinivas, Duan, and Abbeel}}}
\bibcite{hoffman2013stochastic}{{13}{2013}{{Hoffman et~al.}}{{Hoffman, Blei, Wang, and Paisley}}}
\bibcite{hruschka2007bayesian}{{14}{2007}{{Hruschka et~al.}}{{Hruschka, Hruschka, and Ebecken}}}
\bibcite{jordan1999graphical}{{15}{1999}{{Jordan}}{{}}}
\bibcite{jordan1999introduction}{{16}{1999}{{Jordan et~al.}}{{Jordan, Ghahramani, Jaakkola, and Saul}}}
\bibcite{kahle2008junction}{{17}{2008}{{Kahle et~al.}}{{Kahle, Savitsky, Schnelle, and Cevher}}}
\bibcite{Karaletsos2015BayesianRL}{{18}{2015}{{Karaletsos et~al.}}{{Karaletsos, Belongie, and Ratsch}}}
\bibcite{Khemakhem20a}{{19}{2020}{{Khemakhem et~al.}}{{Khemakhem, Kingma, Monti, and Hyvarinen}}}
\bibcite{Kim18}{{20}{2018}{{Kim \& Mnih}}{{Kim and Mnih}}}
\bibcite{kingma2013auto}{{21}{2013}{{Kingma \& Welling}}{{Kingma and Welling}}}
\bibcite{kingma2018glow}{{22}{2018}{{Kingma \& Dhariwal}}{{Kingma and Dhariwal}}}
\bibcite{koller2007graphical}{{23}{2007}{{Koller et~al.}}{{Koller, Friedman, Getoor, and Taskar}}}
\bibcite{liu2016stein}{{24}{2016}{{Liu \& Wang}}{{Liu and Wang}}}
\bibcite{madigan1995bayesian}{{25}{1995}{{Madigan et~al.}}{{Madigan, York, and Allard}}}
\bibcite{papamakarios2019normalizing}{{26}{2019}{{Papamakarios et~al.}}{{Papamakarios, Nalisnick, Rezende, Mohamed, and Lakshminarayanan}}}
\bibcite{scikit-learn}{{27}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}}}
\bibcite{rezende2015variational}{{28}{2015}{{Rezende \& Mohamed}}{{Rezende and Mohamed}}}
\bibcite{rippel2013high}{{29}{2013}{{Rippel \& Adams}}{{Rippel and Adams}}}
\bibcite{salimans2015markov}{{30}{2015}{{Salimans et~al.}}{{Salimans, Kingma, and Welling}}}
\bibcite{sanner2012symbolic}{{31}{2012}{{Sanner \& Abbasnejad}}{{Sanner and Abbasnejad}}}
\bibcite{shwe1990probabilistic}{{32}{1990}{{Shwe et~al.}}{{Shwe, Middleton, Heckerman, Henrion, Horvitz, Lehmann, and Cooper}}}
\bibcite{Sorrenson2020}{{33}{2020}{{Sorrenson et~al.}}{{Sorrenson, Rother, and K{\" o}the}}}
\bibcite{tabak2010density}{{34}{2010}{{Tabak et~al.}}{{Tabak, Vanden-Eijnden, et~al.}}}
\bibcite{winn2005variational}{{35}{2005}{{Winn \& Bishop}}{{Winn and Bishop}}}
\bibcite{xing2012generalized}{{36}{2012}{{Xing et~al.}}{{Xing, Jordan, and Russell}}}
\newlabel{appd:tree_elbo}{{6}{12}{Appendix A. ELBO of Tree Models}{section*.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Tree structure.\relax }}{12}{figure.caption.7}}
\newlabel{fig:tree-d}{{6}{12}{Tree structure.\relax }{figure.caption.7}{}}
\newlabel{eq:chain}{{11}{12}{Appendix A. ELBO of Tree Models}{equation.6.11}{}}
\newlabel{eq:tree_elbo}{{12}{13}{Appendix A. ELBO of Tree Models}{equation.6.12}{}}
\newlabel{eq:layer0_a}{{13}{13}{Appendix A. ELBO of Tree Models}{equation.6.13}{}}
\newlabel{eq:layer0_b}{{14}{13}{Appendix A. ELBO of Tree Models}{equation.6.14}{}}
\newlabel{eq:kl_1}{{15}{13}{Appendix A. ELBO of Tree Models}{equation.6.15}{}}
\newlabel{eq:kl_a}{{16}{13}{Appendix A. ELBO of Tree Models}{equation.6.16}{}}
\newlabel{eq:a_inner}{{17}{13}{Appendix A. ELBO of Tree Models}{equation.6.17}{}}
\newlabel{eq:kl_b}{{18}{13}{Appendix A. ELBO of Tree Models}{equation.6.18}{}}
\newlabel{eq:KL_tree}{{19}{14}{Appendix A. ELBO of Tree Models}{equation.6.19}{}}
\newlabel{eq:KL_all}{{20}{14}{Appendix A. ELBO of Tree Models}{equation.6.20}{}}
\newlabel{appd:dag_elbo}{{6}{14}{Appendix B. ELBO of DAG Models}{section*.8}{}}
\newlabel{eq:dag_elbo}{{21}{14}{Appendix B. ELBO of DAG Models}{equation.6.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces DAG structure. The inverse topology order is {\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\nulldelimiterspace \z@ \left \{\vcenter to\@ne \big@size {}\right .$}\box \z@ } \{1,2,3\}, \{4,5\}, \{6\}, \{7\} {\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\nulldelimiterspace \z@ \left \}\vcenter to\@ne \big@size {}\right .$}\box \z@ }, and it corresponds to layers 0 to 3. \relax }}{15}{figure.caption.9}}
\newlabel{fig:dag}{{7}{15}{DAG structure. The inverse topology order is \big \{ \{1,2,3\}, \{4,5\}, \{6\}, \{7\} \big \}, and it corresponds to layers 0 to 3. \relax }{figure.caption.9}{}}
\newlabel{eq:KL_dag1}{{22}{15}{Appendix B. ELBO of DAG Models}{equation.6.22}{}}
\newlabel{eq:KL_dag2}{{23}{15}{Appendix B. ELBO of DAG Models}{equation.6.23}{}}
\newlabel{eq:kl_dag3}{{24}{15}{Appendix B. ELBO of DAG Models}{equation.6.24}{}}
\newlabel{appd:proof_lm1}{{6}{15}{Appendix C. Proof of Lemma1}{section*.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces (Left) Message passing in a node. (Right) Message passing in a tree.\relax }}{16}{figure.caption.10}}
\newlabel{fig:message}{{8}{16}{(Left) Message passing in a node. (Right) Message passing in a tree.\relax }{figure.caption.10}{}}
\newlabel{appd:proof_thm1}{{6}{16}{Appendix D. Proof of Theorem 1}{section*.12}{}}
