\begin{thebibliography}{11}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra.
\newblock Weight uncertainty in neural networks.
\newblock \emph{arXiv preprint arXiv:1505.05424}, 2015.

\bibitem[Graves(2011)]{graves2011practical}
Alex Graves.
\newblock Practical variational inference for neural networks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2348--2356, 2011.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock \emph{arXiv preprint arXiv:1706.04599}, 2017.

\bibitem[He et~al.(2019)He, Huang, and Yuan]{he2019asymmetric}
Haowei He, Gao Huang, and Yang Yuan.
\newblock Asymmetric valleys: Beyond sharp and flat local minima.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2553--2564, 2019.

\bibitem[Hoffman et~al.(2013)Hoffman, Blei, Wang, and
  Paisley]{hoffman2013stochastic}
Matthew~D Hoffman, David~M Blei, Chong Wang, and John Paisley.
\newblock Stochastic variational inference.
\newblock \emph{The Journal of Machine Learning Research}, 14\penalty0
  (1):\penalty0 1303--1347, 2013.

\bibitem[Izmailov et~al.(2018)Izmailov, Podoprikhin, Garipov, Vetrov, and
  Wilson]{izmailov2018averaging}
Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and
  Andrew~Gordon Wilson.
\newblock Averaging weights leads to wider optima and better generalization.
\newblock \emph{arXiv preprint arXiv:1803.05407}, 2018.

\bibitem[Kendall \& Gal(2017)Kendall and Gal]{kendall2017uncertainties}
Alex Kendall and Yarin Gal.
\newblock What uncertainties do we need in bayesian deep learning for computer
  vision?
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5574--5584, 2017.

\bibitem[Keskar et~al.(2016)Keskar, Mudigere, Nocedal, Smelyanskiy, and
  Tang]{keskar2016large}
Nitish~Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy,
  and Ping Tak~Peter Tang.
\newblock On large-batch training for deep learning: Generalization gap and
  sharp minima.
\newblock \emph{arXiv preprint arXiv:1609.04836}, 2016.

\bibitem[Kingma et~al.(2015)Kingma, Salimans, and
  Welling]{kingma2015variational}
Durk~P Kingma, Tim Salimans, and Max Welling.
\newblock Variational dropout and the local reparameterization trick.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2575--2583, 2015.

\bibitem[Neal(2012)]{neal2012bayesian}
Radford~M Neal.
\newblock \emph{Bayesian learning for neural networks}, volume 118.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Polyak \& Juditsky(1992)Polyak and Juditsky]{polyak1992acceleration}
Boris~T Polyak and Anatoli~B Juditsky.
\newblock Acceleration of stochastic approximation by averaging.
\newblock \emph{SIAM journal on control and optimization}, 30\penalty0
  (4):\penalty0 838--855, 1992.

\end{thebibliography}
