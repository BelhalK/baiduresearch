\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Our Contributions}{section.1}% 2
\BOOKMARK [1][-]{section.2}{Related Work}{}% 3
\BOOKMARK [2][-]{subsection.2.1}{Distributed SGD with Compressed Gradients}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.2}{Adaptive Optimization}{section.2}% 5
\BOOKMARK [1][-]{section.3}{Communication-Efficient Adaptive Optimization}{}% 6
\BOOKMARK [2][-]{subsection.3.1}{Gradient Compressors}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.2}{Comp-AMS: Distributed Adaptive Training by Gradient Aggregation}{section.3}% 8
\BOOKMARK [1][-]{section.4}{Convergence Analysis}{}% 9
\BOOKMARK [1][-]{section.5}{Experiments}{}% 10
\BOOKMARK [2][-]{subsection.5.1}{Datasets and Models}{section.5}% 11
\BOOKMARK [2][-]{subsection.5.2}{General Evaluation and Communication Efficiency}{section.5}% 12
\BOOKMARK [2][-]{subsection.5.3}{Linear Speedup of Comp-AMS}{section.5}% 13
\BOOKMARK [2][-]{subsection.5.4}{Discussion}{section.5}% 14
\BOOKMARK [1][-]{section.6}{Conclusion}{}% 15
\BOOKMARK [1][-]{appendix.A}{More Experimental Results on ResNet-18}{}% 16
\BOOKMARK [1][-]{appendix.B}{Proof of the Convergence Results}{}% 17
\BOOKMARK [2][-]{subsection.B.1}{Proof of Theorem 1}{appendix.B}% 18
\BOOKMARK [2][-]{subsection.B.2}{Intermediate Lemmas}{appendix.B}% 19
