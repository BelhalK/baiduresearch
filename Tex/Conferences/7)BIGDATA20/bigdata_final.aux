\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Proc:Bottou_COMPSTAT10,Collect:Bottou_LNCS12,Proc:Zhang_ICML04,Article:Toulis_SAC15}
\citation{Proc:Reddi_NIPS15}
\citation{Article:Polyak_1964}
\citation{Article:Murata_1998}
\citation{Article:Nemirovski_SIOPT09,Article:Toulis_AOS17}
\citation{Article:Murata_1998}
\citation{Article:Bottou_SIREV18,BooK:Ermoliev_1988}
\citation{Proc:Blum_COLT99,Collect:Bottou_LNCS12}
\citation{Article:Pflug_1990,Proc:Yin_1989}
\citation{Article:Pflug_1990}
\citation{Article:Delyon_SIOPT93,Article:Kesten_AOMS58,Proc:Roux_NIPS12}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{eq:stoch_opt}{{1}{1}{Introduction}{equation.1.1}{}}
\newlabel{eq:sgd-vanilla}{{2}{1}{Introduction}{equation.1.2}{}}
\newlabel{eq:sgdm}{{3}{1}{Introduction}{equation.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Related work}{1}{subsection.1.1}}
\citation{Proc:Chee_AISTATS18}
\citation{Report:Shirish_arXiv17}
\citation{Proc:Kingma_ICLR15}
\citation{matteo2019JSM}
\citation{Report:Su_arXiv18}
\citation{Proc:Lang_NeurIPS19}
\citation{Proc:Yaida_ICLR19}
\citation{Proc:Ge_NeurIPS19}
\citation{Report:Yang_arXiv16}
\citation{Proc:Bach_NIPS11,Article:Needell_MP16}
\citation{Report:Yang_arXiv16}
\citation{Report:Loizou_arXiv17}
\citation{Report:Loizou_arXiv17}
\citation{Article:Pflug_1990}
\citation{Proc:Chee_AISTATS18}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Our contributions}{2}{subsection.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Convergence diagnostic}{2}{section.2}}
\newlabel{sec:sgd-vanilla}{{II}{2}{Convergence diagnostic}{section.2}{}}
\newlabel{thm:mom_convg_analysis}{{1}{2}{\cite {Report:Yang_arXiv16}}{theorem.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Modified Pflug diagnostic}{2}{subsection.2.1}}
\citation{Report:Yang_arXiv16}
\citation{Bach_NIPS13,Proc:Bach_NIPS11}
\citation{Report:Yang_arXiv16}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{line:test_stat}{{9}{3}{Modified Pflug diagnostic}{AlgoLine.1.9}{}}
\newlabel{line:mom_start}{{15}{3}{Modified Pflug diagnostic}{AlgoLine.1.15}{}}
\newlabel{line:heur_convg}{{16}{3}{Modified Pflug diagnostic}{AlgoLine.1.16}{}}
\newlabel{line:mom_end}{{20}{3}{Modified Pflug diagnostic}{AlgoLine.1.20}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Convergence diagnostic for SGDM.\relax }}{3}{algocf.1}}
\newlabel{alg:diagnostic}{{1}{3}{Modified Pflug diagnostic}{algocf.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}The difficulty with momentum}{3}{section.3}}
\newlabel{sec:momentum-stationarity}{{III}{3}{The difficulty with momentum}{section.3}{}}
\newlabel{assump:strcvx}{{1}{3}{}{assumption.1}{}}
\newlabel{assump:Lsmooth}{{2}{3}{}{assumption.2}{}}
\newlabel{assump:Fbound}{{3}{3}{}{assumption.3}{}}
\newlabel{assump:min_noise}{{4}{3}{}{assumption.4}{}}
\newlabel{assump:scaling}{{5}{3}{}{assumption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Constructing a test statistic}{3}{subsection.3.1}}
\newlabel{eq:ip_loss}{{4}{3}{Constructing a test statistic}{equation.3.4}{}}
\newlabel{thm:ip_exp_bd}{{2}{3}{}{theorem.2}{}}
\newlabel{thm:ip_opt}{{3}{3}{}{theorem.3}{}}
\newlabel{eq:alt_test_stat}{{5}{3}{}{equation.3.5}{}}
\newlabel{eq:ip_breakdown}{{6}{4}{Constructing a test statistic}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Effect of high momentum}{4}{subsection.3.2}}
\newlabel{cor:ip_exp_neg}{{4}{4}{}{theorem.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Quadratic loss model}{4}{subsection.3.3}}
\newlabel{sec:quadratic}{{\unhbox \voidb@x \hbox {III-C}}{4}{Quadratic loss model}{subsection.3.3}{}}
\newlabel{eq:quad_start_star}{{7}{4}{Quadratic loss model}{equation.3.7}{}}
\newlabel{thm:quad_diag}{{5}{4}{}{theorem.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Mean test statistic in stationarity across 25 independent runs with $\gamma = 10^{-2}$. Low $\beta $ setting has $\beta =0.2$. High $\beta $ setting has $\beta =0.8$. \vspace  {-0.1in} \relax }}{4}{table.caption.2}}
\newlabel{tab:high_momentum_ip}{{I}{4}{Mean test statistic in stationarity across 25 independent runs with $\gamma = 10^{-2}$. Low $\beta $ setting has $\beta =0.2$. High $\beta $ setting has $\beta =0.8$. \vspace {-0.1in} \relax }{table.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Distribution of inner products}{4}{section.4}}
\newlabel{sec:distribution_IP}{{IV}{4}{Distribution of inner products}{section.4}{}}
\newlabel{prop:noise_key_iter}{{6}{5}{}{theorem.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Left panel: Histogram of the inner product of successive gradients (Eq.\nobreakspace  {}(\ref  {eq:ip_loss})) for SGDM in the transient phase. Right panel: Histogram of the inner products for SGDM in the stationary phase. Training settings from the low $\beta $ quadratic setting in Section\nobreakspace  {}\ref  {sec:quadratic}. Note the asymmetry in the distribution of inner products in the stationary phase. \relax }}{5}{figure.caption.3}}
\newlabel{fig:hist_ip}{{1}{5}{Left panel: Histogram of the inner product of successive gradients (Eq.~(\ref {eq:ip_loss})) for SGDM in the transient phase. Right panel: Histogram of the inner products for SGDM in the stationary phase. Training settings from the low $\beta $ quadratic setting in Section~\ref {sec:quadratic}. Note the asymmetry in the distribution of inner products in the stationary phase. \relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Histogram of the inner product of successive gradients with high momentum $\beta =0.8$ and no momentum reduction. Left panel: Transient phase. Right panel: Stationary phase. Quadratic loss model from Section\nobreakspace  {}\ref  {sec:quadratic}. Note the symmetry in the distribution of inner products in the stationary phase. \relax }}{5}{figure.caption.4}}
\newlabel{fig:hist_ip_highmom}{{2}{5}{Histogram of the inner product of successive gradients with high momentum $\beta =0.8$ and no momentum reduction. Left panel: Transient phase. Right panel: Stationary phase. Quadratic loss model from Section~\ref {sec:quadratic}. Note the symmetry in the distribution of inner products in the stationary phase. \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Cosine similarity vs gradient norm for SGDM in the stationary phase. The red circle indicates those key inner products with negative angle and high gradient norm. Left panel: Training settings from the low $\beta $ quadratic setting in Section\nobreakspace  {}\ref  {sec:quadratic}. Right panel: high momentum $\beta = 0.8$. The inner product distribution is symmetric in this case. \relax }}{5}{figure.caption.5}}
\newlabel{fig:angle_norm}{{3}{5}{Cosine similarity vs gradient norm for SGDM in the stationary phase. The red circle indicates those key inner products with negative angle and high gradient norm. Left panel: Training settings from the low $\beta $ quadratic setting in Section~\ref {sec:quadratic}. Right panel: high momentum $\beta = 0.8$. The inner product distribution is symmetric in this case. \relax }{figure.caption.5}{}}
\citation{Article:Chen_MP19}
\citation{Proc:Chee_AISTATS18}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Variance bounds}{6}{subsection.4.1}}
\newlabel{thm:ip_var_bound}{{7}{6}{}{theorem.7}{}}
\newlabel{cor:set_gamma_threshold}{{8}{6}{}{theorem.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Numerical experiments}{6}{section.5}}
\newlabel{sec:synth-data-experiments}{{V}{6}{Numerical experiments}{section.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces  Empirical evaluation of the convergence diagnostic in Alg.\nobreakspace  {}\ref  {alg:diagnostic} over 100 independent runs for each experimental setting. SGDM run for $20$ epochs with batch size $20$. Quadratic low $\beta $ (Q-Low) set $\beta = 0.2$, $\gamma = 10^{-2}$, $\eta = 10^{-3}$, $\kappa = 0.65$. Quadratic high $\beta $ (Q-High) set $\beta = 0.8$, $\gamma = 10^{-2}$, $\eta = 2 \times 10^{-3}$, $\kappa = 0.30$. Phase retrieval low $\beta $ (PR-Low) set $\beta =0.2$, $\gamma =10^{-2}$, $\eta = 10^{-2}$, $\kappa = 0.6$. Phase retrieval high $\beta $ (PR-High) set $\beta =0.8$, $\gamma =10^{-2}$, $\eta = 10^{-2}$, $\kappa = 0.65$. \vspace  {-0.1in}\relax }}{6}{table.caption.6}}
\newlabel{tab:diag_errors}{{II}{6}{Empirical evaluation of the convergence diagnostic in Alg.~\ref {alg:diagnostic} over 100 independent runs for each experimental setting. SGDM run for $20$ epochs with batch size $20$. Quadratic low $\beta $ (Q-Low) set $\beta = 0.2$, $\gamma = 10^{-2}$, $\eta = 10^{-3}$, $\kappa = 0.65$. Quadratic high $\beta $ (Q-High) set $\beta = 0.8$, $\gamma = 10^{-2}$, $\eta = 2 \times 10^{-3}$, $\kappa = 0.30$. Phase retrieval low $\beta $ (PR-Low) set $\beta =0.2$, $\gamma =10^{-2}$, $\eta = 10^{-2}$, $\kappa = 0.6$. Phase retrieval high $\beta $ (PR-High) set $\beta =0.8$, $\gamma =10^{-2}$, $\eta = 10^{-2}$, $\kappa = 0.65$. \vspace {-0.1in}\relax }{table.caption.6}{}}
\citation{Proc:He_CVPR16,Article:Krizhevsky_CACM17}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Application: an automatic learning rate schedule}{7}{section.6}}
\newlabel{sec:autoLR}{{VI}{7}{Application: an automatic learning rate schedule}{section.6}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces SGDM with automatic learning rate\relax }}{7}{algocf.2}}
\newlabel{alg:autoLR}{{2}{7}{Application: an automatic learning rate schedule}{algocf.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Binary logistic regression with SGDM using Alg.\nobreakspace  {}\ref  {alg:autoLR} and decreasing rate $\gamma = \gamma _0 / n$, $\beta = 0.8$. Upper panel: MNIST. Bottom panel: Online News Popularity. \relax }}{7}{figure.caption.8}}
\newlabel{fig:mnist_news_binary}{{4}{7}{Binary logistic regression with SGDM using Alg.~\ref {alg:autoLR} and decreasing rate $\gamma = \gamma _0 / n$, $\beta = 0.8$. Upper panel: MNIST. Bottom panel: Online News Popularity. \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Upper: Vertical lines marks the diagnostic activation and learning rate reduction on MNIST. Bottom: SGDM using Alg.\nobreakspace  {}\ref  {alg:autoLR} and varying momentum $\beta \in \{0.2, 0.4, 0.6, 0.8\}$. \relax }}{7}{figure.caption.9}}
\newlabel{fig:mnistactivate_momvary}{{5}{7}{Upper: Vertical lines marks the diagnostic activation and learning rate reduction on MNIST. Bottom: SGDM using Alg.~\ref {alg:autoLR} and varying momentum $\beta \in \{0.2, 0.4, 0.6, 0.8\}$. \relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Upper: Vertical line marks a consistent momentum reduction using convergence heuristic of $\delimiter "026B30D  \theta _n - \theta _{n-1} \delimiter "026B30D ^2$. Bottom: Binary logistic regression with SGDM using Alg.\nobreakspace  {}\ref  {alg:autoLR} and constant learning rate $\gamma _0 \in \{1.0, 0.1, 0.01, 0.001\}$ on MNIST. \relax }}{8}{figure.caption.10}}
\newlabel{fig:momred_constlr}{{6}{8}{Upper: Vertical line marks a consistent momentum reduction using convergence heuristic of $\| \theta _n - \theta _{n-1} \|^2$. Bottom: Binary logistic regression with SGDM using Alg.~\ref {alg:autoLR} and constant learning rate $\gamma _0 \in \{1.0, 0.1, 0.01, 0.001\}$ on MNIST. \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Test accuracy and convergence diagnostic test statistic from Alg.\nobreakspace  {}\ref  {alg:diagnostic} on MNIST. The vertical line marks the diagnostic's activation, which coincides with the test accuracy flattening out. \relax }}{8}{figure.caption.11}}
\newlabel{fig:mnist_teststat}{{7}{8}{Test accuracy and convergence diagnostic test statistic from Alg.~\ref {alg:diagnostic} on MNIST. The vertical line marks the diagnostic's activation, which coincides with the test accuracy flattening out. \relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Test accuracy and convergence diagnostic test statistic on MNIST. The momentum reduction has been removed, and $\beta = 0.8$. The test accuracy has flattened out and SGDM has converged, but the diagnostic does not activate because the test statistic is perpetually positive. \relax }}{8}{figure.caption.12}}
\newlabel{fig:mnist_ablation}{{8}{8}{Test accuracy and convergence diagnostic test statistic on MNIST. The momentum reduction has been removed, and $\beta = 0.8$. The test accuracy has flattened out and SGDM has converged, but the diagnostic does not activate because the test statistic is perpetually positive. \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Test statistic for different values of momentum $\beta \in \{0.2, 0.4, 0.6, 0.8\}$. Higher momentum increases the slope of the test statistic, indicating an even greater difficulty for the convergence diagnostic to detect the stationary phase. \relax }}{8}{figure.caption.13}}
\newlabel{fig:mnist_ablation2}{{9}{8}{Test statistic for different values of momentum $\beta \in \{0.2, 0.4, 0.6, 0.8\}$. Higher momentum increases the slope of the test statistic, indicating an even greater difficulty for the convergence diagnostic to detect the stationary phase. \relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{8}{section.7}}
\citation{Proc:Chen_FODS20}
\bibstyle{plain}
\bibdata{standard}
\bibcite{Proc:Bach_NIPS11}{1}
\bibcite{Bach_NIPS13}{2}
\bibcite{Proc:Blum_COLT99}{3}
\bibcite{Proc:Bottou_COMPSTAT10}{4}
\bibcite{Collect:Bottou_LNCS12}{5}
\bibcite{Article:Bottou_SIREV18}{6}
\bibcite{Proc:Chee_AISTATS18}{7}
\bibcite{Proc:Chen_FODS20}{8}
\bibcite{Article:Chen_MP19}{9}
\bibcite{Article:Delyon_SIOPT93}{10}
\bibcite{BooK:Ermoliev_1988}{11}
\bibcite{Proc:Ge_NeurIPS19}{12}
\bibcite{Proc:He_CVPR16}{13}
\bibcite{Report:Shirish_arXiv17}{14}
\bibcite{Article:Kesten_AOMS58}{15}
\bibcite{Proc:Kingma_ICLR15}{16}
\bibcite{Article:Krizhevsky_CACM17}{17}
\bibcite{Proc:Lang_NeurIPS19}{18}
\bibcite{Report:Loizou_arXiv17}{19}
\bibcite{Article:Murata_1998}{20}
\bibcite{Article:Needell_MP16}{21}
\bibcite{Article:Nemirovski_SIOPT09}{22}
\bibcite{Article:Pflug_1990}{23}
\bibcite{Article:Polyak_1964}{24}
\bibcite{Proc:Reddi_NIPS15}{25}
\bibcite{Proc:Roux_NIPS12}{26}
\bibcite{matteo2019JSM}{27}
\bibcite{Report:Su_arXiv18}{28}
\bibcite{Report:Yang_arXiv16}{29}
\bibcite{Article:Toulis_SAC15}{30}
\bibcite{Article:Toulis_AOS17}{31}
\bibcite{Proc:Yaida_ICLR19}{32}
\bibcite{Proc:Yin_1989}{33}
\bibcite{Proc:Zhang_ICML04}{34}
\@writefile{toc}{\contentsline {section}{References}{9}{section*.14}}
\citation{Report:Yang_arXiv16}
\@writefile{toc}{\contentsline {section}{Appendix}{10}{section*.15}}
\newlabel{lemma:lower_bound_thetadiff}{{9}{10}{}{theorem.9}{}}
\citation{Report:Yang_arXiv16}
\newlabel{lemma:MSE_SGDM_bound}{{10}{13}{}{theorem.10}{}}
\newlabel{lemma:exp_ip_sq_lower}{{11}{14}{}{theorem.11}{}}
\newlabel{lemma:exp_ip_lower}{{12}{15}{}{theorem.12}{}}
