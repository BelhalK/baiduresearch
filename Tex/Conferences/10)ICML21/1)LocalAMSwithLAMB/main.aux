\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{konevcny2016federated,mcmahan2017communication}
\citation{alistarh2017qsgd,wangni2018gradient}
\citation{lin2017deep}
\citation{mcmahan2017communication}
\citation{chen2020toward}
\citation{you2019large}
\newlabel{sec:introduction}{{1}{1}{}{section.1}{}}
\newlabel{eq:opt}{{1}{1}{}{equation.1.1}{}}
\citation{RKK18}
\citation{KB15}
\citation{TH12}
\citation{Z12}
\citation{D16}
\citation{DHS11,MS10}
\citation{N04}
\citation{P64}
\citation{DHS11}
\citation{KB15}
\citation{KB15}
\citation{RKK18}
\citation{RKK18}
\citation{you2019large}
\citation{konevcny2016federated}
\newlabel{sec:related}{{1.1}{2}{}{subsection.1.1}{}}
\newlabel{alg:amsgrad}{{1}{2}{}{algorithm.1}{}}
\newlabel{line:maxop}{{1}{2}{}{algorithm.1}{}}
\citation{recht2011hogwild,li2014scaling,zhao2020distributed}
\citation{mcmahan2017communication}
\citation{mcmahan2017communication}
\citation{konevcny2016federated,zhou2017convergence}
\citation{stich2018local,yu2019linear}
\citation{chen2020toward}
\newlabel{sec:main}{{2}{3}{}{section.2}{}}
\newlabel{fig:illustrate}{{1}{4}{Illustration of Fed-LAMB (Algorithm~\ref {alg:ldams}), with a three-layer network and $\phi (x)=x$ as an example. The depth of each network layer represents the norm of its weights. For device $i$ and each local iteration in round $r$, the adaptive ratio of $j$-th layer $p_{r,i}^j$ is normalized according to $\Vert \theta _{r,i}^j\Vert $, and then used for updating the local model. At the end of each round $r$, local worker $i$ sends $\theta _{r,i}$ and $v_{r,i}$ to the central server, which transmits back aggregated $\theta $ and $\hat v$ to local devices to complete a round of training}{figure.1}{}}
\newlabel{alg:ldams}{{2}{4}{}{algorithm.2}{}}
\newlabel{line:first}{{2}{4}{}{algorithm.2}{}}
\newlabel{line:new1}{{2}{4}{}{algorithm.2}{}}
\newlabel{line:second}{{2}{4}{}{algorithm.2}{}}
\newlabel{line:new2}{{2}{4}{}{algorithm.2}{}}
\newlabel{line:scale}{{2}{4}{}{algorithm.2}{}}
\newlabel{line:layer}{{2}{4}{}{algorithm.2}{}}
\newlabel{line:final}{{2}{4}{}{algorithm.2}{}}
\newlabel{sec:theory}{{3}{4}{}{section.3}{}}
\newlabel{tab:notations}{{1}{4}{Summary of notations used in the paper}{table.1}{}}
\newlabel{ass:smooth}{{1}{4}{}{assumption.1}{}}
\citation{you2019large}
\citation{you2019large}
\citation{ghadimi2013stochastic}
\citation{you2019large}
\newlabel{ass:boundgrad}{{2}{5}{}{assumption.2}{}}
\newlabel{ass:var}{{3}{5}{}{assumption.3}{}}
\newlabel{ass:phi}{{4}{5}{}{assumption.4}{}}
\newlabel{th:main}{{1}{5}{}{theo.1}{}}
\newlabel{bound1}{{2}{5}{}{equation.3.2}{}}
\newlabel{lemma:iterates}{{1}{5}{}{lem.1}{}}
\newlabel{lemma:ratio}{{2}{5}{}{lem.2}{}}
\citation{chen2020toward}
\citation{chen2020toward}
\citation{chen2020toward}
\citation{chen2020toward}
\citation{karimireddy2019scaffold}
\citation{reddi2020adaptive}
\citation{chen2020toward}
\citation{li2019federated,liang2019variance}
\citation{haddadpour2020federated,horvath2019stochastic,karimireddy2019scaffold}
\citation{haddadpour2020fedsketch,ivkin2019communication,li2019privacy}
\newlabel{ass:boundv}{{5}{6}{}{assumption.5}{}}
\newlabel{coro:main}{{1}{6}{}{coro.1}{}}
\newlabel{bound1coro}{{6}{6}{}{equation.3.6}{}}
\citation{RKK18}
\citation{lecun1998mnist}
\citation{krizhevsky2009learning}
\citation{Proc:He-resnet16}
\citation{mcmahan2017communication}
\citation{chen2020toward,reddi2020adaptive}
\newlabel{sec:numerical}{{4}{7}{}{section.4}{}}
\newlabel{fig:mnist-mlp-noniid}{{2}{7}{\textbf {Top Row}: Test accuracy on MNIST+MLP, with non-iid data distribution. \textbf {Bottom Row}: Test accuracy on MNIST+CNN, with non-iid data distribution. \textbf {Left panel:} 1 local epoch. \textbf {Right panel:} 5 local epochs}{figure.2}{}}
\bibstyle{icml2021}
\bibdata{ref}
\bibcite{alistarh2017qsgd}{{1}{2017}{{Alistarh et~al.}}{{Alistarh, Grubic, Li, Tomioka, and Vojnovic}}}
\bibcite{chen2020toward}{{2}{2020}{{Chen et~al.}}{{Chen, Li, and Li}}}
\bibcite{D16}{{3}{2016}{{Dozat}}{{}}}
\newlabel{sec:conclusion}{{5}{8}{}{section.5}{}}
\newlabel{fig:cifar-cnn-iid}{{3}{8}{\textbf {Top Row}: Test accuracy on CIFAR+CNN, with iid data distribution. \textbf {Mid and Bottom Row}: Test accuracy on CIFAR+ResNet, with iid data distribution, 10 and 50 clients, respectively. \textbf {Left panel:} 1 local epoch. \textbf {Right panel:} 3 local epochs}{figure.3}{}}
\bibcite{DHS11}{{4}{2011}{{Duchi et~al.}}{{Duchi, Hazan, and Singer}}}
\bibcite{ghadimi2013stochastic}{{5}{2013}{{Ghadimi \& Lan}}{{Ghadimi and Lan}}}
\bibcite{haddadpour2020federated}{{6}{2020{a}}{{Haddadpour et~al.}}{{Haddadpour, Kamani, Mokhtari, and Mahdavi}}}
\bibcite{haddadpour2020fedsketch}{{7}{2020{b}}{{Haddadpour et~al.}}{{Haddadpour, Karimi, Li, and Li}}}
\bibcite{Proc:He-resnet16}{{8}{2016}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{horvath2019stochastic}{{9}{2019}{{Horv{\'a}th et~al.}}{{Horv{\'a}th, Kovalev, Mishchenko, Stich, and Richt{\'a}rik}}}
\bibcite{ivkin2019communication}{{10}{2019}{{Ivkin et~al.}}{{Ivkin, Rothchild, Ullah, Braverman, Stoica, and Arora}}}
\bibcite{karimireddy2019scaffold}{{11}{2019}{{Karimireddy et~al.}}{{Karimireddy, Kale, Mohri, Reddi, Stich, and Suresh}}}
\bibcite{KB15}{{12}{2015}{{Kingma \& Ba}}{{Kingma and Ba}}}
\bibcite{konevcny2016federated}{{13}{2016}{{Kone{\v {c}}n{\`y} et~al.}}{{Kone{\v {c}}n{\`y}, McMahan, Yu, Richt{\'a}rik, Suresh, and Bacon}}}
\bibcite{krizhevsky2009learning}{{14}{2009}{{Krizhevsky \& Hinton}}{{Krizhevsky and Hinton}}}
\bibcite{lecun1998mnist}{{15}{1998}{{LeCun}}{{}}}
\bibcite{li2014scaling}{{16}{2014}{{Li et~al.}}{{Li, Andersen, Park, Smola, Ahmed, Josifovski, Long, Shekita, and Su}}}
\bibcite{li2019privacy}{{17}{2019}{{Li et~al.}}{{Li, Liu, Sekar, and Smith}}}
\bibcite{li2019federated}{{18}{2020}{{Li et~al.}}{{Li, Sahu, Talwalkar, and Smith}}}
\bibcite{liang2019variance}{{19}{2019}{{Liang et~al.}}{{Liang, Shen, Liu, Pan, Chen, and Cheng}}}
\bibcite{lin2017deep}{{20}{2017}{{Lin et~al.}}{{Lin, Han, Mao, Wang, and Dally}}}
\bibcite{mcmahan2017communication}{{21}{2017}{{McMahan et~al.}}{{McMahan, Moore, Ramage, Hampson, and y~Arcas}}}
\bibcite{MS10}{{22}{2010}{{McMahan \& Streeter}}{{McMahan and Streeter}}}
\bibcite{N04}{{23}{2004}{{Nesterov}}{{}}}
\bibcite{P64}{{24}{1964}{{Polyak}}{{}}}
\bibcite{recht2011hogwild}{{25}{2011}{{Recht et~al.}}{{Recht, Re, Wright, and Niu}}}
\bibcite{reddi2020adaptive}{{26}{2020}{{Reddi et~al.}}{{Reddi, Charles, Zaheer, Garrett, Rush, Kone{\v {c}}n{\`y}, Kumar, and McMahan}}}
\bibcite{RKK18}{{27}{2018}{{Reddi et~al.}}{{Reddi, Kale, and Kumar}}}
\bibcite{stich2018local}{{28}{2018}{{Stich}}{{}}}
\bibcite{TH12}{{29}{2012}{{Tieleman \& Hinton}}{{Tieleman and Hinton}}}
\bibcite{wangni2018gradient}{{30}{2018}{{Wangni et~al.}}{{Wangni, Wang, Liu, and Zhang}}}
\bibcite{you2019large}{{31}{2019}{{You et~al.}}{{You, Li, Reddi, Hseu, Kumar, Bhojanapalli, Song, Demmel, Keutzer, and Hsieh}}}
\bibcite{yu2019linear}{{32}{2019}{{Yu et~al.}}{{Yu, Jin, and Yang}}}
\bibcite{Z12}{{33}{2012}{{Zeiler}}{{}}}
\bibcite{zhao2020distributed}{{34}{2020}{{Zhao et~al.}}{{Zhao, Xie, Jia, Qian, Ding, Sun, and Li}}}
\bibcite{zhou2017convergence}{{35}{2017}{{Zhou \& Cong}}{{Zhou and Cong}}}
\citation{RKK18}
\newlabel{eq:main}{{15}{12}{}{equation.A.15}{}}
\newlabel{eq:defseq}{{16}{12}{}{equation.A.16}{}}
\newlabel{eq:gap}{{17}{12}{}{equation.A.17}{}}
\newlabel{eq:main2}{{20}{12}{}{equation.A.20}{}}
\newlabel{eq:inner}{{21}{13}{}{equation.A.21}{}}
\newlabel{eqn1}{{23}{13}{}{equation.A.23}{}}
\newlabel{eq:finala1}{{33}{13}{}{equation.A.33}{}}
\newlabel{eq:maina2}{{38}{14}{}{equation.A.38}{}}
\newlabel{eq:first}{{39}{15}{}{equation.A.39}{}}
\newlabel{eq:finala2}{{40}{15}{}{equation.A.40}{}}
\newlabel{eq:finala3}{{41}{15}{}{equation.A.41}{}}
\newlabel{eq:final2}{{45}{16}{}{equation.A.45}{}}
\newlabel{eqn:transform}{{48}{16}{}{equation.A.48}{}}
\newlabel{eqn:x1}{{52}{17}{}{equation.A.52}{}}
\newlabel{eq:inter}{{60}{17}{}{equation.A.60}{}}
\newlabel{eqn:B1}{{61}{18}{}{equation.A.61}{}}
