\begin{thebibliography}{1}

\bibitem{chen2020quantized}
Congliang Chen, Li~Shen, Haozhi Huang, Qi~Wu, and Wei Liu.
\newblock Quantized adam with error feedback.
\newblock {\em arXiv preprint arXiv:2004.14180}, 2020.

\bibitem{karimireddy2019error}
Sai~Praneeth Karimireddy, Quentin Rebjock, Sebastian~U Stich, and Martin Jaggi.
\newblock Error feedback fixes signsgd and other gradient compression schemes.
\newblock {\em arXiv preprint arXiv:1901.09847}, 2019.

\bibitem{shi2019convergence}
Shaohuai Shi, Kaiyong Zhao, Qiang Wang, Zhenheng Tang, and Xiaowen Chu.
\newblock A convergence analysis of distributed sgd with
  communication-efficient gradient sparsification.
\newblock In {\em IJCAI}, pages 3411--3417, 2019.

\bibitem{stich2018sparsified}
Sebastian~U Stich, Jean-Baptiste Cordonnier, and Martin Jaggi.
\newblock Sparsified sgd with memory.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4447--4458, 2018.

\end{thebibliography}
