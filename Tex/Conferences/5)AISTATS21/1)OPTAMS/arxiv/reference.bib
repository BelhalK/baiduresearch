@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@article{gers1999learning,
  author    = {Felix A. Gers and
               J{\"{u}}rgen Schmidhuber and
               Fred A. Cummins},
  title     = {Learning to Forget: Continual Prediction with {LSTM}},
  journal   = {Neural Comput.},
  volume    = {12},
  number    = {10},
  pages     = {2451--2471},
  year      = {2000},
  url       = {https://doi.org/10.1162/089976600300015015},
  doi       = {10.1162/089976600300015015},
  timestamp = {Tue, 01 Sep 2020 13:11:47 +0200},
  biburl    = {https://dblp.org/rec/journals/neco/GersSC00.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{mertikopoulos2018optimistic,
  title={Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile},
  author={Mertikopoulos, Panayotis and Lecouat, Bruno and Zenati, Houssam and Foo, Chuan-Sheng and Chandrasekhar, Vijay and Piliouras, Georgios},
  journal={arXiv preprint arXiv:1807.02629},
  year={2018}
}


@article{defossez2020convergence,
  title={On the Convergence of Adam and Adagrad},
  author={D{\'e}fossez, Alexandre and Bottou, L{\'e}on and Bach, Francis and Usunier, Nicolas},
  journal={arXiv preprint arXiv:2003.02395},
  year={2020}
}

@article{ghadimi2013stochastic,
	Author = {Ghadimi, Saeed and Lan, Guanghui},
	Date-Added = {2018-10-27 15:50:56 -0400},
	Date-Modified = {2018-10-27 15:50:56 -0400},
	Journal = {SIAM Journal on Optimization},
	Number = {4},
	Pages = {2341--2368},
	Publisher = {SIAM},
	Title = {Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
	Volume = {23},
	Year = {2013}}

@article{yan2018unified,
  title={A unified analysis of stochastic momentum methods for deep learning},
  author={Yan, Yan and Yang, Tianbao and Li, Zhe and Lin, Qihang and Yang, Yi},
  journal={arXiv preprint arXiv:1808.10396},
  year={2018}
}


@ARTICLE{LH19,
  title={Decoupled Weight Decay Regularization.},
  author={Ilya Loshchilov and Frank Hutter},
  journal   = {ICLR},
  year      = {2019}
}

@ARTICLE{LJHCLGH19,
  title={On the Variance of the Adaptive Learning Rate and Beyond.},
  author={Liyuan Liu and Haoming Jiang and Pengcheng He and Weizhu Chen and Xiaodong Liu and Jianfeng Gao and Jiawei Han},
  journal   = {arXiv:1908.03265},
  year      = {2019}
}

@ARTICLE{HHS17,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks.},
  author={Elad Hoffer and Itay Hubara and Daniel Soudry.},
  journal   = {NPIS},
  year      = {2017}
}

@ARTICLE{KS17,
  title={Improving generalization performance by switching from adam to sgd.},
  author={Nitish Shirish Keskar and Richard Socher.},
  journal   = {arXiv:1712.07628},
  year      = {2017}
}

@ARTICLE{KS17,
  title={Improving generalization performance by switching from adam to sgd.},
  author={Nitish Shirish Keskar and Richard Socher.},
  journal   = {arXiv:1712.07628},
  year      = {2017}
}


@ARTICLE{WRSSR17,
  title={The marginal value of adaptive gradient methods in machine learning.},
  author={Ashia C Wilson and Rebecca Roelofs and Mitchell Stern and Nati Srebro and Benjamin Recht.},
  journal   = {NIPS},
  year      = {2017}
}


@ARTICLE{CG18,
  title={Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks.},
  author={Jinghui Chen and Quanquan Gu},
  journal   = {arXiv:1806.06763},
  year      = {2018}
}


@ARTICLE{SRKKS19,
  title={Escaping Saddle Points with Adaptive Gradient Methods.},
  author={Matthew Staib and Sashank J. Reddi and Satyen Kale and Sanjiv Kumar and Suvrit Sra},
  journal   = {International Conference on Machine Learning (ICML)},
  year      = {2019}
}

@ARTICLE{AGKS19,
  title={Memory Efficient Adaptive Optimization.},
  author={Rohan Anil and Vineet Gupta and Tomer Koren and Yoram Singer},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2019}
}

@ARTICLE{GKS19,
  title={Shampoo: Preconditioned Stochastic Tensor Optimization.},
  author={Vineet Gupta and Tomer Koren and Yoram Singer},
  journal   = {International Conference on Machine Learning (ICML)},
  year      = {2018}
}

@ARTICLE{LXLS19,
  title={Adaptive Gradient Methods with Dynamic Bound of Learning Rate.},
  author={Liangchen Luo and Yuanhao Xiong and Yan Liu and Xu Sun},
  journal   = {ICLR},
  year      = {2019}
}


@ARTICLE{ZZLWZY19,
  title={AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods.},
  author={Zhiming Zhou and Qingru Zhang and Guansong Lu and Hongwei Wang and Weinan Zhang and Yong Yu},
  journal   = {ICLR},
  year      = {2019}
}

@ARTICLE{BG19,
  title={Riemannian Adaptive Optimization Methods.},
  author={Gary Becigneul and Octavian-Eugen Ganea},
  journal   = {ICLR},
  year      = {2019}
}


@ARTICLE{DBXCR19,
  title={Direct Nonlinear Acceleration},
  author={Aritra Dutta and El Houcine Bergou and Yunming Xiao and Marco Canini and Peter Richtarik},
  journal   = {arXiv:1905.11692},
  year      = {2019}
}


@ARTICLE{MG15,
  title={Optimizing Neural Networks with Kronecker-factored Approximate Curvature},
  author={James Martens and Roger Grosse},
  journal   = {International Conference on Machine Learning (ICML)},
  year      = {2015}
}

@ARTICLE{LSGB11,
  title={One shot learning of simple visual concepts},
  author={Brenden M. Lake and Ruslan Salakhutdinov and Jason Gross and Joshua B. Tenenbaum},
  journal   = {CogSci},
  year      = {2011}
}


@ARTICLE{VBLKW16,
  title={Matching networks for one shot learning},
  author={Oriol Vinyals and Charles Blundell and Timothy Lillicrap and Koray Kavukcuoglu and Daan Wierstra},
  journal   = {NIPS},
  year      = {2016}
}


@ARTICLE{DCSP18,
  title={Learning To Learn Around A Common Mean.},
  author={Giulia Denevi and Carlo Ciliberto and Dimitris Stamos and Massimiliano Pontil},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2018}
}

@ARTICLE{KFT19,
  title={Provable Guarantees for Gradient-Based Meta-Learning.},
  author={Mikhail Khodak and Maria-Florina Balcan and Ameet Talwalkar},
  journal   = {arXiv:1902.10644},
  year      = {2019}
}


@ARTICLE{CLR14,
  title={Sparse Multi-Task Reinforcement Learning.},
  author={Daniele Calandriello and Alessandro Lazaric and Marcello Restelli},
  journal   = {NIPS},
  year      = {2014}
}


@ARTICLE{FAL17,
  title={Model-agnostic meta-learning for fast adaptation of deep
networks.},
  author={Chelsea Finn and Pieter Abbeel and Sergey Levine},
  journal   = {International Conference on Machine Learning (ICML)},
  year      = {2017}
}

@ARTICLE{M05,
  title={Algorithmic stability and meta-learning.},
  author={Andreas Maurer},
  journal   = {Journal of Machine Learning Research},
  year      = {2005}
}


@inproceedings{RS13b,
  title={Optimization, learning, and games with predictable sequences},
  author={Rakhlin, Sasha and Sridharan, Karthik},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3066--3074},
  year={2013}
}

@ARTICLE{WWB18,
    title = {Adagrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
    Author = {Rachel Ward and Xiaoxia Wu and Leon Bottou.},
  journal   = {International Conference on Machine Learning (ICML)},
    year = {2019},
}

@ARTICLE{ZTYCG18,
    title = {On the convergence of adaptive gradient methods for nonconvex optimization.},
    Author = {Dongruo Zhou and Yiqi Tang and Ziyan Yang and Yuan Cao and Quanquan Gu},
    journal={arXiv:1808.05671},
    year = {2018},
}

@ARTICLE{ZS18,
    title = {On the convergence of adagrad with momentum for training deep neural
networks.},
    Author = {Fangyu Zou and Li Shen},
    journal={arXiv:1808.03408},
    year = {2018},
}

@inproceedings{DBLP:conf/aistats/LiO19,
  author    = {Xiaoyu Li and
               Francesco Orabona},
  editor    = {Kamalika Chaudhuri and
               Masashi Sugiyama},
  title     = {On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes},
  booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2019, 16-18 April 2019, Naha, Okinawa, Japan},
  series    = {Proceedings of Machine Learning Research},
  volume    = {89},
  pages     = {983--992},
  publisher = {{PMLR}},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v89/li19c.html},
  timestamp = {Fri, 07 Jun 2019 09:03:47 +0200},
  biburl    = {https://dblp.org/rec/conf/aistats/LiO19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{CYYZC19,
  author    = {Zaiyi Chen and
               Zhuoning Yuan and
               Jinfeng Yi and
               Bowen Zhou and
               Enhong Chen and
               Tianbao Yang},
  title     = {Universal Stagewise Learning for Non-Convex Problems with Convergence
               on Averaged Solutions},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=Syx5V2CcFm},
  timestamp = {Thu, 25 Jul 2019 14:25:44 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ChenYYZCY19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




%%%%%%%%%%%%%%%%%%%%%%%

@ARTICLE{MY16,
    title = {Accelerating Optimization via Adaptive Prediction},
    Author = {Mehryar Mohri and Scott Yang},
    journal={AISTATS},
    year = {2016},
}


@ARTICLE{LLM11,
  title={Primal-dual first-order methods with $${\mathcal {O}(1/\epsilon)}$$iteration-complexity for cone programming},
  author={Guanghui Lan and Zhaosong Lu and Renato D. C. Monteiro},
  journal   = {Mathematical Programming},
  year      = {2011}
}

@ARTICLE{T08,
  title={On accelerated proximal gradient methods for convex-concave optimization},
  author={Paul Tseng},
  year      = {2008}
}

@ARTICLE{ZRSKK18,
  title = {Adaptive Methods for Nonconvex Optimization},
  author = {Manzil Zaheer and Sashank Reddi and Devendra Sachan and Satyen Kale and Sanjiv Kumar},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2018},

}

@inproceedings{CLSH19,
  author    = {Xiangyi Chen and
               Sijia Liu and
               Ruoyu Sun and
               Mingyi Hong},
  title     = {On the Convergence of {A} Class of Adam-Type Algorithms for Non-Convex
               Optimization},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=H1x-x309tm},
  timestamp = {Thu, 03 Sep 2020 16:02:23 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ChenLSH19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{DISZ18,
  author    = {Constantinos Daskalakis and
               Andrew Ilyas and
               Vasilis Syrgkanis and
               Haoyang Zeng},
  title     = {Training GANs with Optimism},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=SJJySbbAZ},
  timestamp = {Thu, 25 Jul 2019 14:25:46 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DaskalakisISZ18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{H14,
  author    = {Elad Hazan},
  title     = {Introduction to Online Convex Optimization},
  journal   = {Found. Trends Optim.},
  volume    = {2},
  number    = {3-4},
  pages     = {157--325},
  year      = {2016},
  url       = {https://doi.org/10.1561/2400000013},
  doi       = {10.1561/2400000013},
  timestamp = {Thu, 02 Apr 2020 08:34:29 +0200},
  biburl    = {https://dblp.org/rec/journals/ftopt/Hazan16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@ARTICLE{CCG04,
  title = {On the generalization ability of on-line learning algorithms},
  author    = {Nicol{\'o'} Cesa-Bianchi and Alex Conconi and Claudio Gentile},
  journal = {Information Theory, IEEE Transactions},
  year = {2004}
}


@ARTICLE{P64,
  title = {Some methods of speeding up the convergence of iteration methods},
  author    = {B. T. Polyak},
  journal = {Mathematics and Mathematical Physics},
  year = {1964}
}


@ARTICLE{SALS15,
Author={Vasilis Syrgkanis and Alekh Agarwal and Haipeng Luo and Robert E. Schapire},
title={Fast Convergence of Regularized Learning in Games},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2015}
}



@inproceedings{CJ12,
  author    = {Chao{-}Kai Chiang and
               Tianbao Yang and
               Chia{-}Jung Lee and
               Mehrdad Mahdavi and
               Chi{-}Jen Lu and
               Rong Jin and
               Shenghuo Zhu},
  editor    = {Shie Mannor and
               Nathan Srebro and
               Robert C. Williamson},
  title     = {Online Optimization with Gradual Variations},
  booktitle = {{COLT} 2012 - The 25th Annual Conference on Learning Theory, June
               25-27, 2012, Edinburgh, Scotland},
  series    = {{JMLR} Proceedings},
  volume    = {23},
  pages     = {6.1--6.20},
  publisher = {JMLR.org},
  year      = {2012},
  url       = {http://proceedings.mlr.press/v23/chiang12/chiang12.pdf},
  timestamp = {Wed, 29 May 2019 08:41:47 +0200},
  biburl    = {https://dblp.org/rec/journals/jmlr/ChiangYLMLJZ12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@ARTICLE{N04,
    title = {Introductory Lectures on Convex Optimization:
A Basic Course},
    Author = {Yurii Nesterov},
    journal = {Springer},
    year = {2004},
}

@inproceedings{goodfellow2014generative,
  author    = {Ian J. Goodfellow and
               Jean Pouget{-}Abadie and
               Mehdi Mirza and
               Bing Xu and
               David Warde{-}Farley and
               Sherjil Ozair and
               Aaron C. Courville and
               Yoshua Bengio},
  editor    = {Zoubin Ghahramani and
               Max Welling and
               Corinna Cortes and
               Neil D. Lawrence and
               Kilian Q. Weinberger},
  title     = {Generative Adversarial Nets},
  booktitle = {Advances in Neural Information Processing Systems 27: Annual Conference
               on Neural Information Processing Systems 2014, December 8-13 2014,
               Montreal, Quebec, Canada},
  pages     = {2672--2680},
  year      = {2014},
  url       = {http://papers.nips.cc/paper/5423-generative-adversarial-nets},
  timestamp = {Fri, 06 Mar 2020 16:58:17 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/GoodfellowPMXWOCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DHS11,
  author    = {John C. Duchi and
               Elad Hazan and
               Yoram Singer},
  title     = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal   = {J. Mach. Learn. Res.},
  volume    = {12},
  pages     = {2121--2159},
  year      = {2011},
  url       = {http://dl.acm.org/citation.cfm?id=2021068},
  timestamp = {Wed, 10 Jul 2019 15:28:02 +0200},
  biburl    = {https://dblp.org/rec/journals/jmlr/DuchiHS11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@ARTICLE{SAB16,
  title = {Regularized Nonlinear Acceleration},
  author    = {Damien Scieur and Alexandre d'Aspremont and Francis Bach},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2016}
}


@InProceedings{Princeton18,
  title = 	 {Efficient Full-Matrix Adaptive Regularization},
  author =       {Agarwal, Naman and Bullins, Brian and Chen, Xinyi and Hazan, Elad and Singh, Karan and Zhang, Cyril and Zhang, Yi},
  pages = 	 {102--110},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/agarwal19b/agarwal19b.pdf},
  url = 	 {http://proceedings.mlr.press/v97/agarwal19b.html},
  abstract = 	 {Adaptive regularization methods pre-multiply a descent direction by a preconditioning matrix. Due to the large number of parameters of machine learning problems, full-matrix preconditioning methods are prohibitively expensive. We show how to modify full-matrix adaptive regularization in order to make it practical and effective. We also provide a novel theoretical analysis for adaptive regularization in <em>non-convex</em> optimization settings. The core of our algorithm, termed GGT, consists of the efficient computation of the inverse square root of a low-rank matrix. Our preliminary experiments show improved iteration-wise convergence rates across synthetic tasks and standard deep learning benchmarks, and that the more carefully-preconditioned steps sometimes lead to a better solution.}
}

@book{BZ13,
  author    = {Claude Brezinski and
               Michela Redivo{-}Zaglia},
  title     = {Extrapolation methods - theory and practice},
  series    = {Studies in computational mathematics},
  volume    = {2},
  publisher = {North-Holland},
  year      = {1991},
  isbn      = {978-0-444-88814-3},
  timestamp = {Wed, 17 Jul 2019 17:20:52 +0200},
  biburl    = {https://dblp.org/rec/books/daglib/0078112.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{CJ76,
  title = {A polynomial extrapolation method for finding limits and antilimits of vector sequences},
  author    = {S. Cabay and L. Jackson},
  journal = {SIAM Journal on Numerical Analysis},
  year = {1976}
}

@ARTICLE{WN11,
  title = {Anderson acceleration for fixed-point iterations},
  author    = {H. F. Walker and P. Ni.},
  journal = {SIAM Journal on Numerical Analysis},
  year = {2011}
}

@ARTICLE{E79,
  title = {Extrapolating to the limit of a vector sequence},
  author    = {R. Eddy},
  journal = {Information linkage between applied mathematics and industry, Elsevier},
  year = {1979}
}


@InProceedings{ALLW18,
  title = 	 {Faster Rates for Convex-Concave Games},
  author =       {Abernethy, Jacob and Lai, Kevin A. and Levy, Kfir Y. and Wang, Jun-Kun},
  pages = 	 {1595--1625},
  year = 	 {2018},
  editor = 	 {SÃ©bastien Bubeck and Vianney Perchet and Philippe Rigollet},
  volume = 	 {75},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {06--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v75/abernethy18a/abernethy18a.pdf},
  url = 	 {http://proceedings.mlr.press/v75/abernethy18a.html},
  abstract = 	 {We consider the use of no-regret algorithms to compute equilibria for particular classes of convex-concave games. While standard regret bounds would lead to convergence rates on the order of $O(T^{-1/2})$, recent work \citep{RS13,SALS15} has established $O(1/T)$ rates by taking advantage of a particular class of optimistic prediction algorithms. In this work we go further, showing that for a particular class of games one achieves a $O(1/T^2)$ rate, and we show how this applies to the Frank-Wolfe method and recovers a similar bound \citep{D15}. We also show that such no-regret techniques can even achieve a linear rate, $O(\exp(-T))$, for equilibrium computation under additional curvature assumptions. }
}

@inproceedings{KB15,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@ARTICLE{D16,
  title = {Incorporating Nesterov Momentum into Adam},
  author    = {Timothy Dozat},
  journal = {ICLR (Workshop Track)},
  year = {2016}
}

@ARTICLE{MS10,
  title = {Adaptive bound optimization for online convex optimization},
  author    = {H. Brendan McMahan and Matthew J. Streeter},
  journal = {Conference on Learning Theory (COLT)},
  year = {2010}
}

@ARTICLE{TH12,
  title = {RmsProp: Divide the gradient by a running average of its recent magnitude},
  author    = {T. Tieleman and G. Hinton},
  journal = {COURSERA: Neural Networks for Machine Learning},
  year = {2012}
}


@ARTICLE{Z12,
  title = {ADADELTA: An Adaptive Learning Rate Method},
  author    = {Matthew D. Zeiler},
  journal = {arXiv:1212.5701},
  year = {2012}
}

@ARTICLE{DSSC08,
  title = {Efficient projections onto the l1-ball for learning in high dimensions},
  author    = {John C. Duchi and
               Shai Shalev{-}Shwartz and
               Yoram Singer and
               Tushar Chandra},
  journal = {ICML},
  year = {2008}
}

@inproceedings{PS14,
  author    = {Mu Li and
               David G. Andersen and
               Jun Woo Park and
               Alexander J. Smola and
               Amr Ahmed and
               Vanja Josifovski and
               James Long and
               Eugene J. Shekita and
               Bor{-}Yiing Su},
  title     = {Scaling Distributed Machine Learning with the Parameter Server},
  booktitle = {{OSDI}},
  year      = {2014}
}

@ARTICLE{Petumn13,
  title = {More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server},
  author = {Qirong Ho and James Cipar and Henggang Cui and Jin Kyu Kim and Seunghak Lee and Phillip. B. Gibbon
and Garth A. Gibson and Gregory R. Ganger and Eric P. Xing
  },
  booktitle = {NIPS},
  year = {2013}
}

@inproceedings{GMH13,
  author    = {Alex Graves and
               Abdel{-}rahman Mohamed and
               Geoffrey E. Hinton},
  title     = {Speech recognition with deep recurrent neural networks},
  booktitle = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,
               {ICASSP} 2013, Vancouver, BC, Canada, May 26-31, 2013},
  pages     = {6645--6649},
  publisher = {{IEEE}},
  year      = {2013},
  url       = {https://doi.org/10.1109/ICASSP.2013.6638947},
  doi       = {10.1109/ICASSP.2013.6638947},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/icassp/GravesMH13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{LFDA17,
  author    = {Sergey Levine and
               Chelsea Finn and
               Trevor Darrell and
               Pieter Abbeel},
  title     = {End-to-End Training of Deep Visuomotor Policies},
  journal   = {J. Mach. Learn. Res.},
  volume    = {17},
  pages     = {39:1--39:40},
  year      = {2016},
  url       = {http://jmlr.org/papers/v17/15-522.html},
  timestamp = {Wed, 10 Jul 2019 15:28:13 +0200},
  biburl    = {https://dblp.org/rec/journals/jmlr/LevineFDA16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}






@ARTICLE{Atari13,
  title = {Playing Atari With Deep Reinforcement Learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  journal={NIPS (Deep Learning Workshop)},
  year = {2013}
}

@ARTICLE{Gan14,
  title={Generative Adversarial Networks},
  author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
    journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year={2014}
}

@inproceedings{Rnet16,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
  pages     = {770--778},
  publisher = {{IEEE} Computer Society},
  year      = {2016},
  url       = {https://doi.org/10.1109/CVPR.2016.90},
  doi       = {10.1109/CVPR.2016.90},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/HeZRS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@ARTICLE{RKK18,
  title={On the Convergence of Adam and Beyond },
  author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
    journal = {International Conference on Learning Representations (ICLR)},
  year={2018}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@ARTICLE{CNN15,
  title={Striving for Simplicity: The All Convolutional Net},
  author={Jost Springenberg and Alexey Dosovitskiy and Thomas Brox and Martin Riedmiller},
    journal = {International Conference on Learning Representations (ICLR)},
  year={2015}
}


@inproceedings{MNIST07,
  author    = {Hugo Larochelle and
               Dumitru Erhan and
               Aaron C. Courville and
               James Bergstra and
               Yoshua Bengio},
  editor    = {Zoubin Ghahramani},
  title     = {An empirical evaluation of deep architectures on problems with many
               factors of variation},
  booktitle = {Machine Learning, Proceedings of the Twenty-Fourth International Conference
               {(ICML} 2007), Corvallis, Oregon, USA, June 20-24, 2007},
  series    = {{ACM} International Conference Proceeding Series},
  volume    = {227},
  pages     = {473--480},
  publisher = {{ACM}},
  year      = {2007},
  url       = {https://doi.org/10.1145/1273496.1273556},
  doi       = {10.1145/1273496.1273556},
  timestamp = {Wed, 28 Nov 2018 12:57:16 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/LarochelleECBB07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{IMDB11,
  title={Learning Word Vectors for Sentiment Analysis},
  author={Andrew L. Maas and Raymond E. Daly and Peter T. Pham and Dan Huang and Andrew Y. Ng and Christopher Potts},
  journal={ACL},
  year={2011}
}

@inproceedings{Proc:Yu_KDD10,
 author = {Yu, Hsiang-Fu and Hsieh, Cho-Jui and Chang, Kai-Wei and Lin, Chih-Jen},
 title = {Large linear classification when data cannot fit in memory},
 booktitle = {KDD},
 year = {2010},
 location = {Washington, DC, USA},
 pages = {833--842}
}

@inproceedings{WangIP12,
  author    = {De Wang and
               Danesh Irani and
               Calton Pu},
  title     = {Evolutionary study of web spam: Webb Spam Corpus 2011 versus Webb
               Spam Corpus 2006},
  booktitle = {8th International Conference on Collaborative Computing: Networking,
               Applications and Worksharing, CollaborateCom 2012, Pittsburgh, PA,
               USA, October 14-17, 2012},
  pages     = {40--49},
  year      = {2012},
}

@ARTICLE{Proc:ABC_UAI10,
  author    = {Ping Li},
  title     = {Robust LogitBoost and Adaptive Base Class (ABC) LogitBoost},
  journal   = {UAI},
  year      = {2010}
}

@ARTICLE{arXiv:Li2018,
  title={Several Tunable \text{GMM} Kernels},
  author={Ping Li},
  journal   = {arXiv:1805.02830},
  year      = {2018}
}

@article{Scieur18,
  author    = {Damien Scieur and
               Edouard Oyallon and
               Alexandre d'Aspremont and
               Francis Bach},
  title     = {Nonlinear Acceleration of Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1805.09639},
  year      = {2018}
}
