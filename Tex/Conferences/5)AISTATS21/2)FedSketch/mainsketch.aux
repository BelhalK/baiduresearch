\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mcmahan2016communication,konevcny2016federated}
\citation{carlini2019secret,mcmahan2017learning}
\citation{zhou2018convergence,stich2019local,yu2019parallel,wang2018cooperative}
\citation{bottou-bousquet-2008}
\citation{lin2019don}
\citation{mcmahan2016communication,konevcny2016federated}
\citation{zhou2018convergence,yu2019parallel,stich2019local,wang2018cooperative}
\citation{haddadpour2019local,haddadpour2019trading,basu2019qsparse,haddadpour2019convergence,bayoumi2020tighter,stich2019error}
\citation{yu2019linear,li2019convergence,sahu2018convergence,liang2019variance,haddadpour2019convergence,karimireddy2019scaffold}
\citation{alistarh2017qsgd,bernstein2018signsgd,tang2018communication,wen2017terngrad,wu2018error}
\citation{alistarh2018convergence,lin2017deep,stich2018sparsified,stich2019error}
\citation{li2019federated,liang2019variance}
\citation{liang2019variance,karimireddy2019scaffold,horvath2019stochastic,haddadpour2020federated}
\citation{geyer2017differentially,hardy2017private}
\citation{mcmahan2017learning}
\citation{bonawitz2017practical}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{eq:main}{{1}{1}{Introduction}{equation.1.1}{}}
\citation{DBLP:journals/tcs/CharikarCF04,cormode2005improved,kleinberg2003bursty,Proc:Li_Church_Hastie_NIPS08}
\citation{ivkin2019communication}
\citation{li2019privacy}
\citation{ivkin2019communication}
\citation{ivkin2019communication,rothchild2020fetchsgd}
\citation{ivkin2019communication}
\citation{robbins1951stochastic,bottou-bousquet-2008}
\citation{alistarh2017qsgd,lin2017deep,stich2018sparsified,horvath2019stochastic,horvath2020better}
\citation{li2019privacy}
\citation{DBLP:journals/tcs/CharikarCF04}
\citation{DBLP:journals/tcs/CharikarCF04}
\citation{DBLP:journals/tcs/CharikarCF04}
\@writefile{toc}{\contentsline {section}{\numberline {2}Compressions using Count Sketch}{2}{section.2}}
\newlabel{sec:compression}{{2}{2}{Compressions using Count Sketch}{section.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \texttt  {CS}\nobreakspace  {}\cite  {DBLP:journals/tcs/CharikarCF04}: Count Sketch of ${\boldsymbol  {x}}\in \mathbb  {R}^{d}$. \relax }}{2}{algorithm.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:csketch}{{1}{2}{\texttt {CS}~\cite {DBLP:journals/tcs/CharikarCF04}: Count Sketch of ${\boldsymbol {x}}\in \mathbb {R}^{d}$. \relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Sketching based Unbiased Compressor}{2}{subsection.2.1}}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{horvath2020better}
\citation{ivkin2019communication}
\citation{ivkin2019communication}
\citation{horvath2020better}
\citation{horvath2020better}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Sketching based Biased Compressor}{3}{subsection.2.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces \texttt  {HEAVYMIX} \relax }}{3}{algorithm.2}}
\newlabel{alg:heavymix}{{2}{3}{\texttt {HEAVYMIX} \relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Sketching based Induced Compressor}{3}{subsection.2.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces \texttt  {HEAPRIX} \relax }}{3}{algorithm.3}}
\newlabel{alg:heaprix}{{3}{3}{\texttt {HEAPRIX} \relax }{algorithm.3}{}}
\newlabel{cor:small}{{1}{3}{}{corollary.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\texttt  {FedSKETCH} and \texttt  {FedSKETCHGATE}}{3}{section.3}}
\newlabel{sec:algos}{{3}{3}{\texttt {FedSKETCH} and \texttt {FedSKETCHGATE}}{section.3}{}}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2019convergence}
\citation{haddadpour2020federated}
\citation{liang2019variance}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Homogeneous Setting}{4}{subsection.3.1}}
\newlabel{rmrk:bidirect}{{3.1}{4}{Comparison with~\cite {haddadpour2020federated}}{section*.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Comparison with\nobreakspace  {}\cite  {haddadpour2020federated}}{4}{section*.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Heterogeneous Setting}{4}{subsection.3.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces \texttt  {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }}{4}{algorithm.4}}
\newlabel{Alg:PFLHom}{{4}{4}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{line:heaprix1}{{5}{4}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{eq:update-rule-alg}{{9}{4}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{line:heaprix2}{{12}{4}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\citation{karimi2016linear}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces \texttt  {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }}{5}{algorithm.5}}
\newlabel{Alg:PFLHet}{{5}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{line:cj_privix}{{4}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{eq:update-rule-alg-heter1}{{10}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{line:tildeS}{{16}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Convergence Analysis}{5}{section.4}}
\newlabel{sec:cnvg-an}{{4}{5}{Convergence Analysis}{section.4}{}}
\newlabel{Assu:1}{{1}{5}{Smoothness and Lower Boundedness}{assumption.1}{}}
\newlabel{assum:pl}{{2}{5}{\pl }{assumption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Convergence of \texttt  {FEDSKETCH} }{5}{subsection.4.1}}
\newlabel{Assu:1.5}{{3}{5}{Bounded Variance}{assumption.3}{}}
\newlabel{thm:homog_case}{{1}{5}{}{theorem.1}{}}
\citation{ivkin2019communication}
\citation{ivkin2019communication}
\citation{ivkin2019communication}
\citation{ivkin2019communication}
\citation{li2019privacy}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{bayoumi2020tighter}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{li2018federated,haddadpour2019convergence}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\@writefile{toc}{\contentsline {paragraph}{Comparison with \cite  {ivkin2019communication}}{6}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Note:}{6}{section*.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Convergence of \texttt  {FedSKETCHGATE}}{6}{subsection.4.2}}
\newlabel{Assu:2}{{4}{6}{Bounded Local Variance}{assumption.4}{}}
\newlabel{thm:hetreg_case}{{2}{6}{}{theorem.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Comparison with Prior Methods}{6}{subsection.4.3}}
\citation{lecun1998gradient}
\citation{ivkin2019communication}
\citation{li2018federated}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of results with compression and periodic averaging in the homogeneous setting. Here, $p$ is the number of devices, $\mu $ is the PL constant, $m$ is the number of bins of hash tables, $d$ is the dimension of the model, $\kappa $ is the condition number, $\epsilon $ is the target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }}{7}{table.caption.5}}
\newlabel{table:1}{{1}{7}{Comparison of results with compression and periodic averaging in the homogeneous setting. Here, $p$ is the number of devices, $\mu $ is the PL constant, $m$ is the number of bins of hash tables, $d$ is the dimension of the model, $\kappa $ is the condition number, $\epsilon $ is the target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical Applications}{7}{section.5}}
\newlabel{sec:experimnt}{{5}{7}{Numerical Applications}{section.5}{}}
\citation{mcmahan2016communication,chen2020toward}
\citation{ivkin2019communication}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of results with compression and periodic averaging in the heterogeneous setting. Here, $p$ is the number of devices, $\mu $ is compression of hash table, $d$ is the dimension of the model, $\kappa $ is condition number, $\epsilon $ is target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }}{8}{table.caption.6}}
\newlabel{table:2}{{2}{8}{Comparison of results with compression and periodic averaging in the heterogeneous setting. Here, $p$ is the number of devices, $\mu $ is compression of hash table, $d$ is the dimension of the model, $\kappa $ is condition number, $\epsilon $ is target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }{table.caption.6}{}}
\bibstyle{plain}
\bibdata{reference}
\bibcite{alistarh2017qsgd}{{1}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Homogeneous case: Comparison of compressed optimization methods on LeNet CNN.\relax }}{9}{figure.caption.7}}
\newlabel{fig:MNIST-iid1}{{1}{9}{Homogeneous case: Comparison of compressed optimization methods on LeNet CNN.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN.\relax }}{9}{figure.caption.8}}
\newlabel{fig:MNIST-iid0}{{2}{9}{Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{9}{section.6}}
\bibcite{alistarh2018convergence}{{2}{}{{}}{{}}}
\bibcite{basu2019qsparse}{{3}{}{{}}{{}}}
\bibcite{bernstein2018signsgd}{{4}{}{{}}{{}}}
\bibcite{bonawitz2017practical}{{5}{}{{}}{{}}}
\bibcite{bottou-bousquet-2008}{{6}{}{{}}{{}}}
\bibcite{carlini2019secret}{{7}{}{{}}{{}}}
\bibcite{DBLP:journals/tcs/CharikarCF04}{{8}{}{{}}{{}}}
\bibcite{chen2020toward}{{9}{}{{}}{{}}}
\bibcite{cormode2005improved}{{10}{}{{}}{{}}}
\bibcite{fergus2006removing}{{11}{}{{}}{{}}}
\bibcite{geyer2017differentially}{{12}{}{{}}{{}}}
\bibcite{gong2014gradient}{{13}{}{{}}{{}}}
\bibcite{haddadpour2019local}{{14}{}{{}}{{}}}
\bibcite{haddadpour2019trading}{{15}{}{{}}{{}}}
\bibcite{haddadpour2020federated}{{16}{}{{}}{{}}}
\bibcite{haddadpour2019convergence}{{17}{}{{}}{{}}}
\bibcite{hardy2017private}{{18}{}{{}}{{}}}
\bibcite{horvath2019stochastic}{{19}{}{{}}{{}}}
\bibcite{horvath2020better}{{20}{}{{}}{{}}}
\bibcite{ivkin2019communication}{{21}{}{{}}{{}}}
\bibcite{karimi2016linear}{{22}{}{{}}{{}}}
\bibcite{karimireddy2019scaffold}{{23}{}{{}}{{}}}
\bibcite{bayoumi2020tighter}{{24}{}{{}}{{}}}
\bibcite{kleinberg2003bursty}{{25}{}{{}}{{}}}
\bibcite{konevcny2016federated}{{26}{}{{}}{{}}}
\bibcite{lecun1998gradient}{{27}{}{{}}{{}}}
\bibcite{levin2007image}{{28}{}{{}}{{}}}
\bibcite{Proc:Li_Church_Hastie_NIPS08}{{29}{}{{}}{{}}}
\bibcite{li2019privacy}{{30}{}{{}}{{}}}
\bibcite{li2019federated}{{31}{}{{}}{{}}}
\bibcite{li2018federated}{{32}{}{{}}{{}}}
\bibcite{li2019convergence}{{33}{}{{}}{{}}}
\bibcite{liang2019variance}{{34}{}{{}}{{}}}
\bibcite{lin2019don}{{35}{}{{}}{{}}}
\bibcite{lin2017deep}{{36}{}{{}}{{}}}
\bibcite{liu2019enhancing}{{37}{}{{}}{{}}}
\bibcite{mcmahan2016communication}{{38}{}{{}}{{}}}
\bibcite{mcmahan2017learning}{{39}{}{{}}{{}}}
\bibcite{parmas2018total}{{40}{}{{}}{{}}}
\bibcite{philippenko2020artemis}{{41}{}{{}}{{}}}
\bibcite{reddi2020adaptive}{{42}{}{{}}{{}}}
\bibcite{reisizadeh2020fedpaq}{{43}{}{{}}{{}}}
\bibcite{robbins1951stochastic}{{44}{}{{}}{{}}}
\bibcite{rothchild2020fetchsgd}{{45}{}{{}}{{}}}
\bibcite{sahu2018convergence}{{46}{}{{}}{{}}}
\bibcite{stich2018sparsified}{{47}{}{{}}{{}}}
\bibcite{stich2019error}{{48}{}{{}}{{}}}
\bibcite{stich2019local}{{49}{}{{}}{{}}}
\bibcite{tang2018communication}{{50}{}{{}}{{}}}
\bibcite{wang2018cooperative}{{51}{}{{}}{{}}}
\bibcite{wen2017terngrad}{{52}{}{{}}{{}}}
\bibcite{wu2018error}{{53}{}{{}}{{}}}
\bibcite{yu2019linear}{{54}{}{{}}{{}}}
\bibcite{yu2019parallel}{{55}{}{{}}{{}}}
\bibcite{zhang2016parallel}{{56}{}{{}}{{}}}
\bibcite{zhou2018convergence}{{57}{}{{}}{{}}}
\citation{li2019convergence,haddadpour2019convergence}
\citation{li2019convergence,haddadpour2019convergence}
\citation{karimireddy2019scaffold,wang2018cooperative,liang2019variance}
\citation{karimireddy2019scaffold}
\@writefile{toc}{\contentsline {paragraph}{Notation.}{13}{section*.10}}
\newlabel{fact:1}{{3}{13}{\cite {li2019convergence,haddadpour2019convergence}}{theorem.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Additional Convergence Analysis}{13}{appendix.A}}
\newlabel{sec:gen-proof}{{A}{13}{Additional Convergence Analysis}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}General convergence for homogeneous setting}{13}{subsection.A.1}}
\newlabel{sec:gen-proof-hom}{{A.1}{13}{General convergence for homogeneous setting}{subsection.A.1}{}}
\newlabel{thm:homog_casee}{{4}{13}{}{theorem.4}{}}
\citation{karimireddy2019scaffold}
\citation{philippenko2020artemis}
\citation{philippenko2020artemis}
\citation{horvath2020better}
\citation{horvath2020better}
\citation{li2019privacy}
\citation{li2019privacy}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}General convergence for heterogeneous setting}{14}{subsection.A.2}}
\newlabel{sec:gen-proof-hettt}{{A.2}{14}{General convergence for heterogeneous setting}{subsection.A.2}{}}
\newlabel{appthm:hetreg_case}{{5}{14}{}{theorem.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Various known algorithms}{15}{subsection.A.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces \texttt  {PRIVIX} \cite  {li2019privacy}: Unbiased compressor based on sketching. \relax }}{15}{algorithm.6}}
\newlabel{Alg:privix}{{6}{15}{\texttt {PRIVIX} \cite {li2019privacy}: Unbiased compressor based on sketching. \relax }{algorithm.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Results for the Homogeneous Setting}{15}{appendix.B}}
\newlabel{sec:app:sgd:undrr-pl}{{B}{15}{Results for the Homogeneous Setting}{appendix.B}{}}
\newlabel{lemma:tasbih1-iid}{{1}{15}{}{lemma.1}{}}
\newlabel{eq:lemma1}{{4}{15}{}{equation.B.4}{}}
\newlabel{eq:lemma111}{{5}{16}{Results for the Homogeneous Setting}{equation.B.5}{}}
\newlabel{eq:100000}{{6}{17}{Results for the Homogeneous Setting}{equation.B.6}{}}
\newlabel{eq:var_b_mid}{{7}{17}{Results for the Homogeneous Setting}{equation.B.7}{}}
\newlabel{eq:lemma112}{{8}{17}{Results for the Homogeneous Setting}{equation.B.8}{}}
\newlabel{eq:mid-bounding-absg}{{9}{17}{Results for the Homogeneous Setting}{equation.B.9}{}}
\newlabel{lemma:cross-inner-bound-unbiased}{{2}{17}{}{lemma.2}{}}
\newlabel{eq:lemma3-thm2}{{11}{17}{}{equation.B.11}{}}
\newlabel{eq:bounding-cross-no-redundancy}{{12}{18}{Results for the Homogeneous Setting}{equation.B.12}{}}
\newlabel{lemma:dif-under-pl-sgd-iid}{{3}{18}{}{lemma.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Main result for the non-convex setting}{19}{subsection.B.1}}
\newlabel{thm:lsgwd-lr}{{6}{19}{non-convex}{theorem.6}{}}
\newlabel{eq:cnd-thm4.3}{{14}{19}{non-convex}{equation.B.14}{}}
\newlabel{eq:thm1-result}{{15}{19}{non-convex}{equation.B.15}{}}
\newlabel{eq:decent-smoothe}{{16}{19}{Main result for the non-convex setting}{equation.B.16}{}}
\newlabel{eq:Lipschitz-c1}{{17}{19}{Main result for the non-convex setting}{equation.B.17}{}}
\newlabel{eq:Lipschitz-c-gd}{{18}{19}{Main result for the non-convex setting}{equation.B.18}{}}
\newlabel{eq:finalll}{{19}{20}{Main result for the non-convex setting}{equation.B.19}{}}
\newlabel{eq:convg-error}{{20}{20}{Linear speed up}{equation.B.20}{}}
\newlabel{rmk:cnd-lr}{{5}{20}{}{remark.5}{}}
\newlabel{eq:lrcnd}{{21}{20}{}{equation.B.21}{}}
\citation{wang2018cooperative}
\citation{wang2018cooperative}
\newlabel{eq:iidexact}{{22}{21}{}{equation.B.22}{}}
\newlabel{eq:lrbnd-homog}{{23}{21}{}{equation.B.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Main result for the PL/Strongly convex setting}{21}{subsection.B.2}}
\newlabel{thm:pl-iid}{{7}{21}{PL or strongly convex}{theorem.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Main result for the general convex setting}{23}{subsection.B.3}}
\newlabel{thm:cvx-iid}{{8}{23}{Convex}{theorem.8}{}}
\newlabel{eq:cvx-iid}{{27}{23}{Convex}{equation.B.27}{}}
\newlabel{eq:mid-cvx}{{28}{23}{Main result for the general convex setting}{equation.B.28}{}}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\@writefile{toc}{\contentsline {section}{\numberline {C}Proof of Main Theorems}{24}{appendix.C}}
\newlabel{Assu:quant}{{5}{24}{\cite {haddadpour2020federated}}{assumption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Proof of Theorem\nobreakspace  {}\ref  {thm:homog_case}}{24}{subsection.C.1}}
\newlabel{thm:fromhaddad}{{9}{24}{\cite {haddadpour2020federated}}{theorem.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Proof of Theorem\nobreakspace  {}\ref  {thm:hetreg_case}}{24}{subsection.C.2}}
\newlabel{assum:009}{{6}{24}{\cite {haddadpour2020federated}}{assumption.6}{}}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\newlabel{thm:fromhaddad-het}{{10}{25}{}{theorem.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Additional Plots for the Numerical Experiments}{25}{appendix.D}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Homogeneous setting}{25}{subsection.D.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Homogeneous case: Comparison of compressed optimization methods on LeNet CNN architecture.\relax }}{25}{figure.caption.11}}
\newlabel{fig:MNIST-iid1-app}{{3}{25}{Homogeneous case: Comparison of compressed optimization methods on LeNet CNN architecture.\relax }{figure.caption.11}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Heterogeneous setting}{26}{subsection.D.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN architecture.\relax }}{26}{figure.caption.12}}
\newlabel{fig:MNIST-iid0-app}{{4}{26}{Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN architecture.\relax }{figure.caption.12}{}}
