\begin{thebibliography}{13}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Deng et~al.(2020)Deng, Bakhtin, Ott, Szlam, and
  Ranzato]{deng2020residual}
Yuntian Deng, Anton Bakhtin, Myle Ott, Arthur Szlam, and Marc'Aurelio Ranzato.
\newblock Residual energy-based models for text generation.
\newblock \emph{arXiv preprint arXiv:2004.11714}, 2020.

\bibitem[Du and Mordatch(2019)]{du2019implicit}
Yilun Du and Igor Mordatch.
\newblock Implicit generation and modeling with energy based models.
\newblock 2019.

\bibitem[Haarnoja et~al.(2017)Haarnoja, Tang, Abbeel, and
  Levine]{haarnoja2017reinforcement}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock In \emph{International Conference on Machine Learning}, pages
  1352--1361. PMLR, 2017.

\bibitem[LeCun et~al.(2006)LeCun, Chopra, Hadsell, Ranzato, and
  Huang]{lecun2006tutorial}
Yann LeCun, Sumit Chopra, Raia Hadsell, M~Ranzato, and F~Huang.
\newblock A tutorial on energy-based learning.
\newblock \emph{Predicting structured data}, 1\penalty0 (0), 2006.

\bibitem[Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean]{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock \emph{arXiv preprint arXiv:1310.4546}, 2013.

\bibitem[Ngiam et~al.(2011)Ngiam, Chen, Koh, and Ng]{ngiam2011learning}
Jiquan Ngiam, Zhenghao Chen, Pang~W Koh, and Andrew~Y Ng.
\newblock Learning deep energy models.
\newblock In \emph{Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 1105--1112, 2011.

\bibitem[Song and Kingma(2021)]{song2021train}
Yang Song and Diederik~P Kingma.
\newblock How to train your energy-based models.
\newblock \emph{arXiv preprint arXiv:2101.03288}, 2021.

\bibitem[Song et~al.(2020)Song, Garg, Shi, and Ermon]{song2020sliced}
Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon.
\newblock Sliced score matching: A scalable approach to density and score
  estimation.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 574--584.
  PMLR, 2020.

\bibitem[Welling and Teh(2011)]{welling2011bayesian}
Max Welling and Yee~W Teh.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In \emph{Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 681--688, 2011.

\bibitem[Wenliang et~al.(2019)Wenliang, Sutherland, Strathmann, and
  Gretton]{wenliang2019learning}
Li~Wenliang, Dougal Sutherland, Heiko Strathmann, and Arthur Gretton.
\newblock Learning deep kernels for exponential family densities.
\newblock In \emph{International Conference on Machine Learning}, pages
  6737--6746. PMLR, 2019.

\bibitem[Xie et~al.(2016)Xie, Lu, Zhu, and Wu]{xie2016theory}
Jianwen Xie, Yang Lu, Song-Chun Zhu, and Yingnian Wu.
\newblock A theory of generative convnet.
\newblock In \emph{International Conference on Machine Learning}, pages
  2635--2644. PMLR, 2016.

\bibitem[Xie et~al.(2020)Xie, Zheng, Gao, Wang, Zhu, and Wu]{xie2020generative}
Jianwen Xie, Zilong Zheng, Ruiqi Gao, Wenguan Wang, Song-Chun Zhu, and
  Ying~Nian Wu.
\newblock Generative voxelnet: Learning energy-based models for 3d shape
  synthesis and analysis.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2020.

\bibitem[Zhu et~al.(1998)Zhu, Wu, and Mumford]{zhu1998filters}
Song~Chun Zhu, Yingnian Wu, and David Mumford.
\newblock Filters, random fields and maximum entropy (frame): Towards a unified
  theory for texture modeling.
\newblock \emph{International Journal of Computer Vision}, 27\penalty0
  (2):\penalty0 107--126, 1998.

\end{thebibliography}
