\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage[colorlinks,linkcolor=blue,filecolor=blue,citecolor=magenta,urlcolor=blue]{hyperref}
\usepackage{bm,amsmath,amsthm,amssymb,multicol,algorithmic,algorithm,enumitem,graphicx,subfigure}
\usepackage{xargs}
\usepackage{natbib}
\usepackage{stmaryrd}


\input{shortcuts}


\begin{document}



\title{AniLA: Anisotropic Langevin Dynamics for training Energy-Based Models}

 \author{\textbf{Belhal Karimi, Jianwen Xie, Ping Li} \\\\
 Cognitive Computing Lab\\
 Baidu Research\\
   10900 NE 8th St. Bellevue, WA 98004, USA
 }

\date{}
\maketitle

\begin{abstract}
We develop in this paper
\end{abstract}

\section{Introduction}
The modeling of a data generating process is critical for many tasks.
A growing interest in generative models within the realm of computer vision has led to multiple interesting solutions.
In particular, Energy Based Models (EBM) \citep{zhu1998filters,lecun2006tutorial}, are a class of generative models that learns high dimensional and complex (in terms of landscape) representation/distribution of the input data.
Since inception, EBMs have been used in several applications including computer vision \citep{ngiam2011learning, xie2016theory,xie2020generative,du2019implicit}, natural language processing \citep{mikolov2013distributed,deng2020residual},  density estimation \citep{wenliang2019learning,song2020sliced} and reinforcement learning \citep{haarnoja2017reinforcement}.

Formally, EBMs are built upon an unnormalized log probability, called the energy function, that is not required to sum to one, as standard log probability functions.
This noticeable feature allows for more freedom in the way one parametrizes the EBM.
For instance, Convolutional Neural Network (CNN) can be employed to parametrize the energy function, see \citep{xie2016theory}.
Note that this choice is highly related to the type of the input data, as mentioned in \citep{song2021train}.

The training procedure of such models consists of finding an energy function that assigns to lower energies to observations than unobserved points.
This phase can be casted into an optimization task and several ways are possible to achieve it.
In this paper, we will focus on training the EBM via Maximum Likelihood Estimation (MLE) and defer the readers to \citep{song2021train} for alternative procedures.
Particularly, while using MLE to fit the EBM on a stream of observed data, the high non-convexity of the loss function leads to a non closed form maximization step. In general, gradient based optimization methods are thus used during that phase.
Besides, given the intractability of the normalizing constant of our model, the aforementioned gradient, which is an intractable integral, needs to be approximated.
A popular and efficient way to conduct such approximation is to use Monte Carlo approximation where the samples are obtained via Markov Chain Monte Carlo (MCMC) \citep{meyn2012markov}.
The goal of this embedded MCMC procedure while training the Energy-based model is to synthesize new examples of the input data and use those new synthetic observations, in our case images, to approximate some expectations that we will describe later.
The sampling phase is thus crucial for both the EBM training speed and its final accuracy in generating new samples.

The computational burden of those MCMC transitions at each iteration of the EBM training procedure is alleviated via different techniques in the literature.
For instance, in \citep{nijkamp2019learning}, the authors develop a short-run MCMC as a flow-based generator mechanism despite its non convergence property.
A large class of solutions aiming at reducing the cost of running MCMC until convergence, which in practice can be unfeasible, is using Contrastive Divergence \citep{hinton2002training} and persistent Contrastive Divergence \citep{tieleman2008training}.
This principled approach keeps in memory the final chain state under the previous global model parameter and uses it as the initialization of the current chain.
The heuristic of such approach is that along the EBM iterations, the conditional distributions, depending on the model parameter, are more and more similar and thus using a good sample from the previous chain is in general a good sample of the current one.
Though, this method can be limited during the first iterations of the EBM training since when the model parameter changes drastically, the conditional distributions do too and samples from two different chains can be quite inconsistent.
Several extensions varying the way the chain is initialized can be found in \citep{welling2002new,gao2018learning,du2019implicit}.

An interesting line of work in the realm of MCMC-based EBM tackles the biases induced by stopping the MCMC runs too early. 
Indeed, it is known, see \citep{meyn2012markov}, that before convergence, MCMC samples are biased and thus correcting this biase while keep a short run and less expensive run is an appealing option.
Several contributions aiming at removing this bias for improved MCMC training include coupling MCMC chains, see \citep{qiu2019unbiased,jacob2020unbiased} or by simply estimating this bias and correct the chain afterwards, see \citep{du2020improved}.


In this work, we consider the case of a short-run MCMC for the training of an Energy-Based Model but rather than focussing on debiasing the chain, we develop a new sampling scheme which purpose is to obtain better samples from the target distribution using less MCMC transitions.
We consider that the shape of the target distribution, which highly inspires our proposed method, is of utmost importance to obtain such negative samples.

The contributions of our paper are as follows:

\begin{itemize}
\item We develop \algo, a EBM training method that embeds a newly proposed \emph{convergent} and \emph{efficient} MCMC sampling scheme, focussing on curvature informed metrics of the target distribution one wants to obtain samples from.
\item Based on a anisotropic stepsize, our method, which is an improvement of the Langevin dynamics, achieves to obtain negative samples from the EBM data distribution.
\item We prove the geometric ergodicity uniformly on any compact set of our method assuming some regularity conditions on the target distribution
\item We empirically verify the relevance of our method on several image generation tasks.
\end{itemize}

The rest of the paper is organized as follows.
We introduce in Section~\ref{sec:mcmc} the important notions of this paper regarding EBM and MCMC procedures.
Section~\ref{sec:main} develops the main algorithmic contribution of this paper, namely \algo.
Section~\ref{sec:theory} introduces the main theoretical results of our paper and focuses on the ergodicity of our propose MCMC sampling method.
Section~\ref{sec:numericals} present several image generation experiments on a toy dataset and baseline deep image datasets.
 Section~\ref{sec:conclusion} concludes our work



\section{On MCMC based Energy Based Models}\label{sec:mcmc}


Given a stream of input data noted $x \in \xset \subset \rset^p$, the energy-based model (EBM) is a Gibbs distribution defined as follows:
\beq\label{eq:ebm}
p(x,\theta) = \frac{1}{Z(\theta)} \mathrm{exp}(f_{\theta}(x))
\eeq

where $\theta \in \Theta \subset \rset^d$ denotes the global vector parameters of our model and $Z(\theta) \eqdef \int_{x} \mathrm{exp}(f_{\theta}(x)) \textrm{d}x$ is the normalizing constant (with respect to $x$).
The natural way of fitting model \eqref{eq:ebm} is to employ Maximum Likelihood Estimation (MLE) to maximize the marginal likelihood $p(\theta)$ and consisting of finding the vector of parameters $\theta^*$ such that for any $x \in \xset$, 
\beq\label{eq:mle}
 \theta^*  = \arg \max \limits_{\theta \in \Theta} \log p(\theta) \eqsp.
 \eeq

The quantity of interest $p(\theta)$ is obtained by marginalizing over the input data $x \in \xset$ and formally reads $p(\theta) = \int_{x \in xset} p(x, \theta) q(x) \textrm{d}x$ where we note $q(x)$ the true distribution of the input data $x$.
The optimization task \eqref{eq:mle} is not tractable in closed form and requires an iterative procedure to be solved.
The standard algorithm used to train EBMs is Stochastic Gradient Descent (SGD), see \citep{robbins1951A,bottou2008}.
SGD requires having access to the gradient of the objective function $\log p(\theta)$. 
This latter requires computing an intractable, due to the high nonlinearity of the parametrized model we use in general $f_\theta(x)$.
Given the general form in \eqref{eq:ebm} we have that:
\beq
\nabla \log p(\theta) = \int_{x \in xset} \nabla \log p(x, \theta) q(x) \textrm{d}x =  \EE_{p(x,\theta)}[\nabla_\theta f_\theta(x)] - \EE_{q(x)}[\nabla_\theta f_\theta(x)] \eqsp,
\eeq
and a simple Monte Carlo approximation of $\nabla \log p(\theta)$ yields

\beq\label{eq:mcapprox}
\nabla \log p(\theta) \approx \frac{1}{m} \sum_{j=1}^m \nabla_\theta f_\theta(x^{p}_j) -  \frac{1}{n} \sum_{i=1}^n \nabla_\theta f_\theta(x^{q}_i) \eqsp,
\eeq
where are $\{x^{p}_j\}_{j=1}^m$ samples obtained from the EBM $p(x,\theta)$ and $\{x^{q}_i\}_{i=1}^n$ are samples obtained from the true data distribution $q(x)$.

While drawing samples from the data distribution is trivial, the challenge during the EBM training phase is to obtain good samples from the EBM distribution $p(x,\theta)$ for any model parameter $\theta \in \Theta$.
This task is generally done using MCMC methods.
State of the arts MCMC used in the EBM literature include Langevin dynamics, see \citep{grenander1994representations,roberts1996exponential} and Hamiltonian Monte Carlo (HMC), see \citep{neal2011mcmc}.
Those methods are detailed in the sequel and are important concepts throughout our paper.

\paragraph{Energy Based Models: }
Energy based models \cite{lecun2006tutorial,ngiam2011learning} are a class of generative models that leverages the power of Gibbs potential and high dimensional sampling techniques to produce high quality synthetic image samples.
Just as Variational Autotencoders (VAE) \citep{kingma2013auto} or Generative Adversarial Networks (GAN) \citep{goodfellow2014generative}, EBMs are powerful tools for generative modeling tasks, as a building block for a wide variety of tasks. 
The main purpose of EBMs is to learn an energy function \eqref{eq:ebm} that assigns low energy to a stream of observation and high energy values to other inputs.
Learning, or Training, of such models is done via Maximum Likelihood (ML) \citep{du2019implicit} or Score Matching \citep{song2020score} or Noise Constrastive Estimation \citep{gao2020flow}.
Yet, unlike VAE or GANn energy-based models enjoy from a single structure requiring training (versus several networks) resulting in more stability.
The use of implicit sampling techniques, such as MCMC, as detailed in the sequel, allows more flexibility trading of quality for computation time.
Overall, the \emph{implicit} property of the EBM, seen as a energy function, makes it a tool of choice as opposed to \emph{explicit} generators that are limited to some design choice (see prior choices for VAE or both networks design in GAN).


\paragraph{MCMC procedures: }
As seen in \eqref{eq:mcapprox}, samples from the EBM are needed to compute its gradient.
We generally have recourse to MCMC methods.
MCMC are a class of inference algorithms

\textcolor{red}{TO COMPLETE, MCMC, Metropolis methods, detail Langevin Dynamics as baseline for our paper, HMC etc}

\section{Gradient Informed Langevin Diffusion}\label{sec:main}

\subsection{Preliminaries and Bottlenecks of Langevin MCMC based EBM}
State of the art MCMC sampling algorithm, particularly used during the training procedure of EBMs, is the discretized Langevin diffusion, casted as Stochastic Gradient Langevin Dynamics (SGLD), see \cite{welling2011bayesian}.

\textcolor{red}{TO COMPLETE with disadvantage of vanilla Langevin}

\subsection{Curvature informed MCMC}

We introduce a new sampler based on the Langevin updates presented above.

\begin{algorithm}[H]
\caption{\algo\ for Energy-Based Model} \label{alg:anila}
\begin{algorithmic}[1]
%\small
\STATE \textbf{Input}: Total number of iterations $T$, number of MCMC transitions $K$ and of samples $M$ learning rate $\eta$, initial values $\theta_0$, initial chain states $\{ z_{0}^m \}_{m=1}^M$ and $n$ observations $\{ x_{i} \}_{i=1}^n$.
\FOR{$t=1$ to $T$}
\STATE Compute the anisotropic stepsize as follows: \label{line:step}
\beq\label{eq:step}
\stepsize_t = \frac{\thresh}{\max(\thresh, | \nabla f_{\theta_t}(z_{t-1}^m) |}
\eeq
\STATE Draw $m$ samples $\{ z_{t}^m \}_{m=1}^M$ from the objective potential \eqref{eq:ebm} via Langevin diffusion:\label{line:langevin}
\beq\label{eq:anila}
z_{t}^{m} = z_{t-1}^m + \stepsize_t/2  \nabla f_{\theta_t}(z_{t-1}^m) + \sqrt{\stepsize_t} \mathsf{B}_t
\eeq
where $\mathsf{B}_t$ is the brownian motion, drawn from a Normal distribution.
\STATE Samples $m$ positive observations $\{ x_{i} \}_{i=1}^m$ from the empirical data distribution.
\STATE Compute the gradient of the empirical log-EBM \eqref{eq:ebm} as follows:
\beq
\nabla \sum_{i=1}^m \log p_{\theta_t}(x_i) = \mathbb{E}_{p_{\text {data }}}\left[\nabla_{\theta} f_{\theta_t}(x)\right]-\mathbb{E}_{p_{\theta}}\left[\nabla_{\theta_t} f_{\theta}(z_t^m)\right] \approx \frac{1}{m} \sum_{i=1}^{m} \nabla_{\theta} f_{\theta_t}\left(x_{i}\right)-\frac{1}{m} \sum_{i=1}^{m} \nabla_{\theta} f_{\theta_t}\left(z_t^m\right)
\eeq
\STATE Update the vector of global parameters of the EBM:
\beq
\theta_{t+1} = \theta_{t+1} + \eta \nabla \sum_{i=1}^m \log p_{\theta_t}(x_i)
\eeq
\ENDFOR
\STATE \textbf{Output:} Generated samples $\{ z_{T}^m \}_{m=1}^M$
\end{algorithmic}
\end{algorithm}


\textbf{Heuristic behind the efficacy of \algo:}
Some past modifications have been proposed in particular to optimize the covariance matrix of the proposal of the general MCMC procedure in order to better stride the support of the target distribution. 
Langevin dynamics is one example of those improvements where the proposal is a Gaussian distribution where the mean depends on the gradient of the log target distribution and the covariance depends on some Brownian motion.
For instance, in \citep{atchade2006adaptive,marshall2012adaptive}, the authors propose adaptive and geometrically ergodic Langevin chains. 
Yet, one important characteristic of our EBM problem, is that for each model parameter through the EBM training iterations, the target distribution moves and the proposal should take that adjustment into account.
The technique in \citep{atchade2006adaptive,marshall2012adaptive} does not take the whole advantage of changing the proposal using the target distribution. 
In particular, the covariance matrix of the proposal is given by a stochastic approximation of the empirical covariance matrix. 
This choice seems completely relevant as soon as the convergence towards the stationary distribution is reached, in other words it would make sense towards the end of the EBM training, as the target distribution from a model parameter to the next one are similar. 
However, it does not provide a good guess of the variability during the first iterations of the chain since it is still very dependent on the initialization. 

Moreover, in  \citep{girolami2011riemann}, the authors consider the approximation of a constant. Even though this simplification leads to ease of implementation, the curvature metric chosen by the authors need to be inverted, step that can be a computational burden if not intractable. 
Especially in the case we are considering in our paper, \ie Convnet-based EBM, where the high nonlinearity would lead to intractable quanities.

Therefore, in \eqref{eq:step} and \eqref{eq:anila} of Algorithm~\ref{alg:anila}, we propose a variant of Langevin, to sample from a target distribution, using a full anisotropic covariance matrix based on the anisotropy and correlations of the target distribution, see the $\sqrt{\stepsize_t} \mathsf{B}_t$ term. 


\section{Geometric ergodicity of AniLA sampler}\label{sec:theory}
We will present in this section, our theoretical analysis for the Markov Chain constructed using Line~\ref{line:step}-\ref{line:langevin}. 

Let $\Theta$ be a subset of $\rset^d$ for some integer $d >0$.
We denote by $\zset$ the measurable space of $\rset^\ell$ for some integer $\ell >0$.
We define a family of stationary distribution $\left(\pi_\theta(z) \right)_{\theta \in \Theta}$, probability density functions with respect to the Lebesgue measure on the measurable space $\zset$. This family of p.d.f. defines the stationary distributions of our newly introduced sampler.

\textbf{Important Note:} The stationary distributions are defined per $\theta \in \Theta$, \ie at each model update during the EBM optimization phase.

For any chain state $z \in \zset$ we denote by $\Pi_\theta(z,\cdot)$ the transition kernel as defined in the \algo update in Line~\ref{line:langevin}.

The objective of this section is to rigorously show that each transition kernel $\pi_\theta$ is uniformly geometrically ergodic and that this result is true uniformly in state $s$ on any compact subset $\mathcal{C} \in \zset$.
As a background note, a Markov chain, as built Line~\ref{line:langevin}, is said to be geometrically ergodic when $k$ iterations of the same transition kernel is converging to the stationary distribution of the chain and this convergence as a geometric dependence on $k$.

We begin with several usual assumptions for such results.
The first one is related to the continuity of the gradient of the log posterior distribution and the unit vector pointing in the direction of the sample $z$ and the unit vector pointing in the direction of the gradient of the log posterior distribution at $z$:
\begin{assumption}\label{ass:bounded}
(Continuity) The stationary distribution is positive and has continuous derivative such that for all $\theta \in \rset^d$:
\begin{equation}
\lim \limits_{z \to \infty} \frac{z}{|z|} \nabla f_{\theta}(z) = - \infty \quad \textrm{and} \quad \lim \sup \limits_{z \to \infty} \frac{z}{|z|} \frac{\nabla f_{\theta}(z) }{|\nabla f_{\theta}(z) |} < 0
\end{equation}
\end{assumption}

We assume also some regularity conditions of the stationary distributions with respect to state $s$:
\begin{assumption}\label{ass:contlogpi}
For all $z \in \zset$, $\theta \to \pi_\theta$ and $\theta \to \nabla \log \pi_\theta$ are continuous on $\Theta$.
\end{assumption}

For a positive and finite function noted $V: \zset \mapsto \rset$, we define the V-norm distance between two arbitrary transition kernels $\Pi_1$ and $\Pi_2$ as follows:

\beq
\| \Pi_1 - \Pi_2 \|_V \eqdef \sup \limits_{z \in \zset} \frac{\| \Pi_1(z, \cdot) - \Pi_2(z, \cdot) \|_V }{V(z)}
\eeq

The definition of this norm will allow us to establish a convergence rate for our sampling method by deriving an upper bound of the quantity $\| \Pi_\theta^k - \pi_\theta \|_V$ where $k$ denotes the number of MCMC transitions.
We also recall that $\Pi_\theta$ is the transition kernel defined by Line~\ref{line:langevin} and $\pi_\theta$ is the stationary distribution of our Markov chain. 
Then, this quantity characterizes how close to the target distribution, our chain is getting after a finite time of iterations and will eventually formalize \emph{V-uniform ergodicity} of our method.
We specify that strictly speaking $\pi_\theta$ is a probability measure, and not a transition kernel. However $\| \Pi_\theta^k - \pi_\theta \|_V$ is well-defined if we consider the the probability $\pi_\theta$ as a kernel by making the definition:

\beq
\pi(z, \mathcal{C}) \eqdef \pi(\mathcal{C}) \quad \textrm{for} \quad \mathcal{C} \in \zset, \quad z \in \zset
\eeq


Here, for some $\beta \in ] 0,1[$ we define the $V_\theta$ function, also know as the \emph{drift}, for all $z \in \zset$ as follows: 
\beq\label{eq:driftfunction}
V_\theta(z) = c_\theta \pi_\theta(z)^{-\beta}
\eeq
where $c_\theta$ is a constant, with respect to the chain state $s$, such that for all $z \in \zset$, $V_\theta(z) \geq 1$.
Again, we note that the V norm is, in our case, function of the chain state noted $z$ \emph{and} of the global model parameter $\theta$, estimated, and thus varying, through the optimization procedure.
The convergence rate will thus be given for a particular model estimate (precisely its supremum).
Define 

\beq\label{eq:vfunctions}
V_1(z) \eqdef \inf \limits_{\theta \in \Theta} V_\theta(z) \quad \textrm{and} \quad V_2(z) \eqdef \sup \limits_{\theta \in \Theta} V_\theta(z) \eqsp,
\eeq
and assume that
\begin{assumption}\label{ass:V2}
There exists a constant $a_0 > 0$ such that for all $\theta \in \Theta $ and $z \in \zset$, $V_2^{a_0}(z)$ is integrable against the kernel $\Pi_\theta(z, \cdot)$ and 
\beq
 \lim \sup  \limits_{a \to 0}  \sup \limits_{\theta \in \Theta, z \in \zset} \Pi_\theta V_2^a(z) = 1
\eeq

\end{assumption}


We will now give the main convergence result of our sampling method in \algo.
The result consists of showing V-uniform ergodicity of the chain, the irreducibility of the transition kernels and their aperiodicity, see \cite{meyn2012markov} for more details. 
We also prove a drift condition which states that the transition kernels tend to bring back elements into a small set from which boils down V-uniform ergodicity of the transition kernels $(\Pi_\theta)_{\theta \in \Theta}$.


\begin{Theorem}\label{thm:thm1}
Assume H\ref{ass:bounded}-H\ref{ass:V2}.
For any $\theta \in \Theta$, there exists a drift function $V_\theta$, a set $\mathcal{O} \subset \zset$, a constant $0 < \epsilon \leq 1$ such that 
\beq\label{thm:main1}
\Pi_\theta(z, \bset) \geq  \epsilon \int_{\bset} \mathsf{1}_\xset(z)  \textrm{d}y \eqsp.
\eeq
Moreover there exists $0 < \mu < 1$, $\delta > 0$ and a drift function $V$, now independent of $\theta$ such that for all $z \zset$:
\beq\label{thm:main2}
\Pi_\theta V(z) \leq \mu V(z) + \delta \mathsf{1}_{\mathcal{O}}(z) \eqsp.
\eeq
\end{Theorem}


\begin{proof}
The proof of our results are divided into two parts.
We first prove the existence of a set noted $\mathcal{O}$ as a small set for our transition kernel $\Pi_\theta$.
Proving a small set is important to show that for any state, the Markov Chain does not stay in the same s
tate, and thus help in proving its irreducibility and aperiodicity.

Then, we will prove the drift condition towards a small set.
This condition is crucial to prove the convergence of the chain since it states that the kernels tend to attract elements into that set. 
finally, uniform ergodicity is established as a consequence of those drift conditions.

\medskip
\noindent \textbf{(i) Existence of small set: }
Let $\mathcal{O}$ be a compact subset of the state space $\zset$.
We also denote the pdf of the Gaussian proposal of Line~\ref{line:step} as $z \to \prop{\theta}(z',z)$ for any current state of the chain $z' \in \zset$ and dependent on the EBM model parameter $\theta$.
Given \algo's MCMC update, at iteration $t$, the proposal is a Gaussian distribution of mean $z_{t-1}^m+ \stepsize_t/2  \nabla f_{\theta_t}(z_{t-1}^m)$ and covariance $\sqrt{\stepsize_t} \mathsf{B}_t$.

We recall the definition of the transition kernel in the case of a Metropolis adjustment and for any model parameter $\theta \in \Theta$ and state $z \in \zset$:

\beq 
\Pi_\theta(z, \bset) = \int_{\bset} \alpha_\theta(z, y) \prop{\theta}(z,y) \textrm{d}y + \mathsf{1}_bset(z)\int_{\zset} (1 - \alpha_\theta(z, y)) \prop{\theta}(z,y) \textrm{d}y
\eeq

where we have defined the Metropolis ratio between two states $z \in \zset$ and $y \in \bset$ as $\alpha_\theta(z, y) = \textrm{min}(1, \frac{\pi_\theta(z)  \prop{\theta}(z,y)}{\prop{\theta}(y,z) \pi_\theta(y)  })$.
Thanks to Assumption H\ref{ass:bounded} and to the fact that the threshold $\thresh$ leads to a symmetric positive definite covariance matrix with bounded non zero eigenvalues implies that the proposal distribution can be bounded by two zero-mean Gaussian distributions as follows:

\beq\label{eq:twogauss}
a n_{\sigma_1}(z - y) \leq \prop{\theta}(z,y)  \leq b n_{\sigma_2}(z - y) \quad \textrm{for all} \quad \theta \in \Theta
\eeq
where $\sigma_1$ and $\sigma_2$ are the corresponding standard deviation of the distributions and $a$ and $b$ are some scaling factors.

We denote by $\rho_\theta$ the ratio $\frac{\pi_\theta(z)  \prop{\theta}(z,y)}{\prop{\theta}(y,z) \pi_\theta(y)  }$ and define the quantity 
\beq\label{eq:delta}
\delta = \textrm{inf}(\rho_\theta(z,y), \theta \in \Theta, \quad z \in \mathcal{O} ) > 0
\eeq
 given the assumptions H\ref{ass:bounded} and H\ref{ass:contlogpi}.
Likewise, the proposal distribution is bounded from below by its some quantity noted $m$.
Then,
\beq
\Pi_\theta(z, \bset) \geq  \int_{\bset \cap \xset} \alpha_\theta(z, y) \prop{\theta}(z,y) \textrm{d}y \geq \textrm{min}(1, \delta) m \int_{\bset} \mathsf{1}_\xset(z)  \textrm{d}y
\eeq

Then, given the definition of \eqref{eq:delta}, we can find a compact set $\mathcal{O}$ such that $\Pi_\theta(z, \bset) \geq \geq \epsilon$ where $\epsilon = \textrm{min}(1, \delta) m \textbf{Z}$ where $\textbf{Z}$ is the normalizing constant of the pdf $\frac{1}{\textbf{Z}}\mathcal{1}_\xset(z)  \textrm{d}y$.
Thus proving \eqref{thm:main1}, \ie the existence of a small set for our family of transition kernels $(\Pi_\theta)_\theta$.

\medskip
\noindent \textbf{(ii) Drift condition and ergodicity: }
We first need to prove the fact that our family of transition kernels $(\Pi_\theta)_\theta$ satisfies a drift property.

For a given EBM model parameter $\theta \in \Theta$, we can see in \citep{jarner2000geometric} that the drift condition boils down to proving that for the drift function noted $V_\theta$ and defined in \eqref{eq:driftfunction}, we have
\beq\label{mainproof}
\sup \limits_{z \in \zset}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} < \infty \quad \textrm{and} \quad \lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} < 1
\eeq

Throughout the proof, the model parameter is set to an arbitrary $\theta \in \Theta$.
Let denote the acceptation set, \ie\ $\rho_\theta \geq 1$ by $\accept(z) \eqdef \{ y \in \zset, \rho_\theta(z,y) \geq 1 \}$ for any state $y \in \bset$ and its complementary set $\compaccept(z)$.

\medskip
\noindent \textsc{Step (1): } Following our definition of the drift function in \eqref{eq:driftfunction} we obtain:

\begin{align}\label{eq:main1}
 \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} & = \int_{\accept(z)}  \prop{\theta}(z,y) \frac{V_\theta(y)}{V_\theta(z)} \textrm{d}y +  \int_{\compaccept(z)} \frac{\pi_\theta(y)\prop{\theta}(y,z)}{\pi_\theta(z)\prop{\theta}(z,y)} \prop{\theta}(z,y) \frac{V_\theta(y)}{V_\theta(z)} \textrm{d}y +  \int_{\compaccept(z)} (1 - \frac{\pi_\theta(y)\prop{\theta}(y,z)}{\pi_\theta(z)\prop{\theta}(z,y)}) \prop{\theta}(z,y)  \textrm{d}y\\
 &  \overset{(a)}{\leq} \int_{\accept(z)}  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  + \int_{\compaccept(z)} \prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}\textrm{d}y +  \int_{\compaccept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}
where (a) is due to \eqref{eq:driftfunction}.

According to \eqref{eq:twogauss}, we thus have that, for any state $z$ in the acceptance set $\accept(z)$:
\beq \label{eq:comp}
\int_{\accept(z)}  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  \leq  b \int_{\accept(z)}  n_{\sigma_2}(y-z)  \textrm{d}y 
\eeq

For any state $z$ in the complementary set of the acceptance set $\compaccept(z)$ we also have the following:
\beq
\int_{\compaccept(z)} \prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}\textrm{d}y \leq \int_{\compaccept(z)} \prop{\theta}(z,y)^{1- \beta} \prop{\theta}(y,z)^{\beta}  \textrm{d}y \leq b \int_{\compaccept(z)} n_{\sigma_2}(z - y)  \textrm{d}y
\eeq


While we can define the level set of the stationary distribution $\pi_\theta$ as $\mathcal{L}_{\pi_\theta(y)} = \{ z \in \zset, \pi_\theta(z) = \pi_\theta(y) \}$ for some state $y \in \bset$, a neighborhood of that level set is defined as $\mathcal{L}_{\pi_\theta(y)}(p) = \{z \in  \mathcal{L}_{\pi_\theta(y)}, z + t \frac{z}{|z|}, |t| \leq p \}$.

H\ref{ass:bounded} ensures the existence of a radial $r$ such that for all $z \in \zset, |z| \geq r$, then $0 \in \mathcal{L}_{\pi_\theta(y)}$ with $\pi_\theta(z) >  \pi_\theta(y)$.

Since the function $y \to n_{\sigma_2}(y - z)$ is smooth, it is known that there exists a constant $a >0$ such that for $\epsilon >0$, we have that 
\beq\label{eq:lowandup}
\int_{B(z,a)}  n_{\sigma_2}(y - z) \textrm{d}y \geq 1 - \epsilon \quad \textrm{and} \quad \int_{B(z,a) \cap \mathcal{L}_{\pi_\theta(y)}(p) }  n_{\sigma_2}(y - z) \textrm{d}y \leq  \epsilon
\eeq
for some $p$ small enough and where $B(z,a)$ denotes the ball around $z \in \zset$ of radius $a$.
Then combining \eqref{eq:comp} and \eqref{eq:lowandup} we have that:

\beq
\int_{\accept(z) \cap B(z,a) \cap \mathcal{L}_{\pi_\theta(y)}(p) }  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  \leq  b \epsilon
\eeq

Conversely, we can define the set  $\mathcal{A} = \accept(z) \cap B(z,a) \cap \mathcal{L}^+$ where $u \in \mathcal{L}^+$ if $u \in \mathcal{L}_{\pi_\theta(y)}(p)$ and $\phi_\theta(u) > \pi_\theta(p)$.

Then using the second part of H\ref{ass:bounded}, there exists a radius $r' > r + a$, such that for $z \in \zset$ with $|z| \geq r'$ we have

\beq
\int_{\mathcal{A}} (\frac{\pi_\theta(y)}{\pi_\theta(z)})^{1-\beta} \prop{\theta}(y,z) \textrm{d}y \leq \mathsf{d}(p, r')^{1-\beta}  b \int_{\accept(z)}  n_{\sigma_2}(y-z)  \textrm{d}y\leq b \mathsf{d}(p, r')^{1-\beta} 
\eeq

where $\mathsf{d}(p, r') = \sup \limits_{|z| > r'} \frac{\pi_\theta(z + p \frac{z}{|z|})}{\pi_\theta(z)}$. 
Note that H\ref{ass:bounded} implies that $\mathsf{d}(p, r') \to 0$ when $r' \to \infty$.

Likewise with  $\mathcal{A} = \accept(z) \cap B(z,a) \cap \mathcal{L}^-$ we have
\beq
\int_{\mathcal{A}} (\frac{\pi_\theta(y)}{\pi_\theta(z)})^{-\beta} \prop{\theta}(z,y) \textrm{d}y  \leq b \mathsf{d}(p, r')^{\beta} 
\eeq

Same arguments can be obtained for the second term of \eqref{eq:main1}, \ie $\prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}$ and we obtain, plugging the above in \eqref{eq:main1} that:

\begin{align}
\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq \lim \sup \limits_{|z| \to \infty}  \int_{\compaccept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}

Since $\compaccept(z)$ is the complementary set of $\accept(z)$, the above inequality yields

\begin{align}
\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq 1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}



\medskip
\noindent \textsc{Step (2): } The final step of our proof consists in proving that $1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \leq 1 - c$ where $c$ is a constant, independent of all the other quantities.


Given that the proposal distribution is a Gaussian and using assumption H\ref{ass:bounded} we have the existence of a constant $c_a$ depending on $a$ as defined above (the radius of the ball $B(z,a)$ such that

\beq
\frac{\pi_\theta(z)}{\pi_\theta(z- \ell \frac{z}{|z|})} \leq  c_a \leq \inf \limits_{y \in B(z,a)} \frac{\prop{\theta}(y, z)}{\prop{\theta}(z, y)} \quad \textrm{for any} \, z \in \zset, |z| \geq r^*
\eeq

Then for any $|z| \geq r^*$, we obtain that $z- \ell \frac{z}{|z|} \in \accept(z)$.
A particular subset of $\accept(z)$ used throughout the rest of the proof is the cone defined as 

\beq\label{eq:defcone}
\mathcal{P}(z) \eqdef \{ z- \ell \frac{z}{|z|} - i \nu , \, \textrm{with} \quad i < a - \ell  , \nu \in \{ \nu \in \rset^d, \| \nu \| < 1\}, |\nu - \frac{z- \ell \frac{z}{|z|} }{|z- \ell \frac{z}{|z|} |} \leq \frac{\epsilon}{2}   \}
\eeq

Using Lemma~\ref{lem:cone}, we have that $\mathcal{P}(z) \subset \accept(z)$

Then,  

\beq 
 \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \overset{(a)}{\geq}  \int_{\accept(z)}a n_{\sigma_1}(y- z)  \textrm{d}y \overset{(b)}{\geq} a \int_{\mathcal{P}(z)}  n_{\sigma_1}(y-z)  \textrm{d}y
 \eeq
where we have used \eqref{eq:twogauss} in (a) and applied Lemma~\ref{lem:cone} in (b).

If we define the translation of vector $z \in \zset$ by the operator $\mathcal{I} \subset \rset^d \to T_z(\mathcal{I})$, then
\beq\label{eq:constant}
 \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \geq a \int_{\mathcal{P}(z)}  n_{\sigma_1}(y-z)  \textrm{d}y =  \int_{T_z(\mathcal{P}(z))}  n_{\sigma_1}(y-z)  \textrm{d}y
\eeq


Recalling the objective of \noindent \textsc{Step (2)} that is to find a constant $c$ such that $1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \leq 1 - c$, we see from \eqref{eq:constant} that since the set $\mathcal{P}(z)$ does not depend on the EBM model parameter $\theta$ and that once translated by $z$ the resulting set $T_z(\mathcal{P}(z))$ is independent of $z$ (but depends on $\ell$, see definition \eqref{eq:defcone}, then the integral $ \int_{T_z(\mathcal{P}(z))}  n_{\sigma_1}(y-z)  \textrm{d}y$ in \eqref{eq:constant} is independent of $z$ thus condluing on the existence of the constant $c$ such that $\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq 1- c$. Thus proving the second part of \eqref{mainproof} which is the main drift condition we ought to demonstrate.
The first part of \eqref{mainproof} can be proved by observing that $  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} $ is smooth on $\zset$ according to H\ref{ass:contlogpi} and by construction of the transition kernel. Smoothness implies boundedness on the compact $\zset$.


\medskip
\noindent \textsc{Step (3): } 
We now use the main proven equations in \eqref{mainproof} to derive the second result \eqref{thm:main2} of Theorem~\ref{thm:thm1}.

We will begin by showing a similar inequality for the drift function $V_\theta$, thus not having uniformity, as an intermediary step.
The Drift property is a consequence of \textsc{Step (2)} and \eqref{eq:constant} shown above.
Thus, there exists $0 < \bar{\mu} < 1$, $\bar{\delta} > 0$ such that for all $z \zset$:
\beq\label{eq:driftvtheta}
\Pi_\theta V_\theta(z) \leq \bar{\mu} V_\theta(z) + \bar{\delta} \mathsf{1}_{\mathcal{O}}(z) \eqsp,
\eeq
where $V_\theta$ is defined by \eqref{eq:driftfunction}.

Using the two functions defined in \eqref{eq:vfunctions}, we define for $z \in \zset$, the $V$ function independent of $\theta$ as follows:
\beq\label{eq:defv}
V(z) = V_1(z)^\alpha V_2(z)^{2\alpha} \eqsp,
\eeq
where $0 < \alpha < \textrm{min}(\frac{1}{2\beta},\frac{a_0}{3})$, $a_0$ is defined in H\ref{ass:V2} and $\beta$ is defined in \eqref{eq:driftfunction}.
Thus for $\theta \in \Theta$, $z \in \zset$ and $\epsilon >0$:
\begin{align}\notag
\Pi_\theta V(z) & = \int_{\zset} \Pi_\theta(z,y) V_1(y)^\alpha V_2(y)^{2\alpha} \textrm{d}y\\ \notag
& \overset{(a)}{\leq} \frac{1}{2} \int_{\zset} \Pi_\theta(z,y) (\frac{1}{\epsilon^2}V_1(y)^{2\alpha} + \epsilon^2 V_2(y)^{4\alpha}) \textrm{d}y\\ 
& \overset{(b)}{\leq} \frac{1}{2\epsilon^2} \int_{\zset} \Pi_\theta(z,y) V_\theta(y)^{2\alpha} + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y \label{eq:uniform1}
\end{align}
where we have used the Young's inequality in (a) and the definition of $V_1$, see \eqref{eq:vfunctions}, in (b).
Then plugging \eqref{eq:driftvtheta} in \eqref{eq:uniform1}, we have
\begin{align}
\Pi_\theta V(z) & \leq \frac{1}{2\epsilon^2} (\bar{\mu} V_\theta(z)^{2\alpha} + \bar{\delta} \mathsf{1}_{\mathcal{O}}(z) ) + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{2} \sup \limits_{\theta \in \Theta, z \in \zset} \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{1 + \bar{\mu}}V(z)\\
& \leq \left(\frac{\bar{\mu}}{2 \epsilon^2} + \frac{\epsilon^2}{1 + \bar{\mu}} \right) V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z) 
\end{align}

where we have used \eqref{eq:defv} and the assumption H\ref{ass:V2} in the last inequality, ensuring the existence of such exponent $\alpha$.

Setting $\epsilon \eqdef \sqrt{\frac{\bar{\mu}(1+\bar{\mu})}{2}}$, $ \mu  \eqdef  \sqrt{\frac{2\bar{\mu}}{1+\bar{\mu}}}$ and $\delta \eqdef \frac{\bar{\delta}}{2 \epsilon^2}$ proves the uniform ergodicity in \eqref{thm:main2} and concludes the proof of our Theorem~\ref{thm:thm1}.
\end{proof}

Theorem~\ref{thm:thm1} shows two important convergence results for our sampling method. 
First, it established the existence of a small set $\mathcal{O}$ leading to the crucially needed aperiodicity of the chain and ensuring that each transition moves toward a better state.
Then, it provide a uniform ergodicity result of our sampling method in \algo, via the so-called \emph{drift condition} providing the guarantee that our user-designed transition kernels $(\Pi_\theta)_{\theta \in \Theta}$ attracts the states into the small set $\mathcal{O}$.

Moreover, the independence on the EBM model parameter $\theta$ of $V$ in \eqref{thm:main2} leads to \emph{uniform} ergodicity as shown in the following Corollary.
\begin{Corollary}\label{coro:coro1}
Assume H\ref{ass:bounded}-H\ref{ass:V2}.
A direct consequence of Theorem~\ref{thm:thm1} is that the family of transition kernels $(\Pi_\theta)_{\theta \in \Theta}$ are uniformly ergodic,\ie for any compact $\mathcal{C} \subset \zset$, there exist constants $\rho \in ]0,1[$ and $e >0$ such for any iteration $t > 0$,we have:
\beq\label{coro:main}
\sup \limits_{z \in \mathcal{C}} \| \Pi_\theta^t f(\cdot) - \pi_\theta f(\cdot) \|_{V} \leq e \rho^k \| f \|_{V_\theta}
\eeq
where $V$ is the drift function used in Theorem~\ref{thm:thm1}.
\end{Corollary}


\subsection{Intermediary Lemmas}

\begin{Lemma}\label{lem:cone}
Define $\mathcal{P}(z) \eqdef \{ z- \ell \frac{z}{|z|} - i \nu , \, \textrm{with} \quad i > a - \ell  , \nu \in \{ \nu \in \rset^d, \| \nu \| < 1\}, |\nu - \frac{z- \ell \frac{z}{|z|} }{|z- \ell \frac{z}{|z|} |} \leq \frac{\epsilon}{2}   \}$ and $\accept(z) \eqdef \{ y \in \zset, \rho_\theta(z,y) \geq 1 \}$. Then for $z \in \zset$, $\mathcal{P}(z) \subset \accept(z)$
\end{Lemma}


\clearpage
\section{Numerical Experiments}\label{sec:numericals}




\subsection{Application on Toy Example: Gaussian Mixture Model}

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.8\textwidth]{figs/rings}
\caption{(Rings Toy Dataset) }
\label{fig:results}
\end{center}
\end{figure}


\subsection{Flowers Dataset}

\begin{figure}[H]
    \begin{center}
        \mbox{
        \includegraphics[width=2in]{figs/flowerslangevin}
        \includegraphics[width=2in]{figs/flowersanila}
        }
    \end{center}
    \vspace{-0.1in}
	\caption{(Flowers Dataset). Left: Langevin Method. Right: AniLA method. After 100k iterations.}
	\label{fig:flowers}
\end{figure}

\subsection{CIFAR Dataset}



\begin{figure}[H]
    \begin{center}
        \mbox{
        \includegraphics[width=2in]{figs/cifarlangevin}
        \includegraphics[width=2in]{figs/cifarlangevin}
        }
    \end{center}
    \vspace{-0.1in}
	\caption{(CIFAR Dataset). Left: Langevin Method. Right: AniLA method. After 100k iterations.}
	\label{fig:cifar}
\end{figure}


\section{Conclusion}\label{sec:conclusion}

\newpage

\bibliographystyle{plainnat}
\bibliography{ref}


\end{document} 