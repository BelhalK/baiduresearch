\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}

\usepackage{bm,amsmath,amsthm,amssymb,algorithmic,algorithm,enumitem,graphicx,subfigure}
\usepackage{xargs}
\usepackage{stmaryrd}
\usepackage{mdframed}
\usepackage{booktabs}

\newmdtheoremenv{theo}{Theorem}
\newmdtheoremenv{lemm}{Lemma}
\newmdtheoremenv{coro}{Corollary}

\input{shortcuts}



% \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{STANLey: \textbf{ST}ochastic gradient \textbf{AN}isotropic \textbf{L}angevin dynamics for learning Energy-Based Models}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}


%\author{First Author\\
%Institution1\\
%Institution1 address\\
%{\tt\small firstauthor@i1.org}
%% For a paper whose authors are all at the same institution,
%% omit the following lines up until the closing ``}''.
%% Additional authors and addresses can be added with ``\and'',
%% just like the second author.
%% To save space, use either the email address or home page, not both
%\and
%Second Author\\
%Institution2\\
%First line of institution2 address\\
%{\tt\small secondauthor@i2.org}
%}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
We propose in this paper, \algo, a \textbf{ST}ochastic gradient \textbf{AN}isotropic \textbf{L}angevin dynamics, for sampling high dimensional data.
With the growing efficacy and potential of Energy-Based Modeling, also known as non-normalized probabilistic modeling, for modeling a generative process of different natures of high dimensional data observations, we present an end-to-end learning algorithm for Energy-Based Models (EBM) with the purpose of improving the quality of the resulting sampled data points.
While the unknown normalizing constant of EBMs makes the training procedure intractable, resorting to Markov Chain Monte Carlo (MCMC) is in general a viable option.
Realizing what MCMC entails for the EBM training, we propose in this paper, a novel high dimensional sampling method, based on an anisotropic stepsize and a gradient-informed covariance matrix, embedded into a discretized Langevin diffusion.
We motivate the necessity for an anisotropic update of the negative samples in the Markov Chain by the nonlinearity of the backbone of the EBM, here a Convolutional Neural Network.
Our resulting method, namely \algo, is an optimization algorithm for training Energy-Based models via our newly introduced MCMC method.
We provide a theoretical understanding of our sampling scheme by proving that the sampler leads to a geometrically uniformly ergodic Markov Chain.
Several image generation experiments are provided in our paper to show the effectiveness of our method.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
The modeling of a data generating process is critical for many tasks.
A growing interest in generative models within the realm of computer vision has led to multiple interesting solutions.
In particular, Energy Based Models (EBM) \cite{zhu1998filters,lecun2006tutorial}, are a class of generative models that learns high dimensional and complex (in terms of landscape) representation/distribution of the input data.
Since inception, EBMs have been used in several applications including computer vision \cite{ngiam2011learning, xie2016theory,xie2020generative,du2019implicit}, natural language processing \cite{mikolov2013distributed,deng2020residual},  density estimation \cite{wenliang2019learning,song2020sliced} and reinforcement learning \cite{haarnoja2017reinforcement}.

Formally, EBMs are built upon an unnormalized log probability, called the energy function, that is not required to sum to one, as standard log probability functions.
This noticeable feature allows for more freedom in the way one parametrizes the EBM.
For instance, Convolutional Neural Network (CNN) can be employed to parametrize the energy function, see \cite{xie2016theory}.
Note that this choice is highly related to the type of the input data, as mentioned in \cite{song2021train}.

The training procedure of such models consists of finding an energy function that assigns to lower energies to observations than unobserved points.
This phase can be casted into an optimization task and several ways are possible to achieve it.
In this paper, we will focus on training the EBM via Maximum Likelihood Estimation (MLE) and defer the readers to \cite{song2021train} for alternative procedures.
Particularly, while using MLE to fit the EBM on a stream of observed data, the high non-convexity of the loss function leads to a non closed form maximization step. In general, gradient based optimization methods are thus used during that phase.
Besides, given the intractability of the normalizing constant of our model, the aforementioned gradient, which is an intractable integral, needs to be approximated.
A popular and efficient way to conduct such approximation is to use Monte Carlo approximation where the samples are obtained via Markov Chain Monte Carlo (MCMC) \cite{meyn2012markov}.
The goal of this embedded MCMC procedure while training the Energy-based model is to synthesize new examples of the input data and use those new synthetic observations, in our case images, to approximate some expectations that we will describe later.
The sampling phase is thus crucial for both the EBM training speed and its final accuracy in generating new samples.

The computational burden of those MCMC transitions at each iteration of the EBM training procedure is alleviated via different techniques in the literature.
For instance, in \cite{nijkamp2019learning}, the authors develop a short-run MCMC as a flow-based generator mechanism despite its non convergence property.
A large class of solutions aiming at reducing the cost of running MCMC until convergence, which in practice can be unfeasible, is using Contrastive Divergence \cite{hinton2002training} and persistent Contrastive Divergence \cite{tieleman2008training}.
This principled approach keeps in memory the final chain state under the previous global model parameter and uses it as the initialization of the current chain.
The heuristic of such approach is that along the EBM iterations, the conditional distributions, depending on the model parameter, are more and more similar and thus using a good sample from the previous chain is in general a good sample of the current one.
Though, this method can be limited during the first iterations of the EBM training since when the model parameter changes drastically, the conditional distributions do too and samples from two different chains can be quite inconsistent.
Several extensions varying the way the chain is initialized can be found in \cite{welling2002new,gao2018learning,du2019implicit}.

An interesting line of work in the realm of MCMC-based EBM tackles the biases induced by stopping the MCMC runs too early. 
Indeed, it is known, see \cite{meyn2012markov}, that before convergence, MCMC samples are biased and thus correcting this biase while keep a short run and less expensive run is an appealing option.
Several contributions aiming at removing this bias for improved MCMC training include coupling MCMC chains, see \cite{qiu2019unbiased,jacob2020unbiased} or by simply estimating this bias and correct the chain afterwards, see \cite{du2020improved}.


In this work, we consider the case of a short-run MCMC for the training of an Energy-Based Model but rather than focussing on debiasing the chain, we develop a new sampling scheme which purpose is to obtain better samples from the target distribution using less MCMC transitions.
We consider that the shape of the target distribution, which highly inspires our proposed method, is of utmost importance to obtain such negative samples.

The contributions of our paper are as follows:

\begin{itemize}
\item We develop \algo, a EBM training method that embeds a newly proposed \emph{convergent} and \emph{efficient} MCMC sampling scheme, focussing on curvature informed metrics of the target distribution one wants to obtain samples from.
\item Based on a anisotropic stepsize, our method, which is an improvement of the Langevin dynamics, achieves to obtain negative samples from the EBM data distribution.
\item We prove the geometric ergodicity uniformly on any compact set of our method assuming some regularity conditions on the target distribution
\item We empirically verify the relevance of our method on several image generation tasks.
\end{itemize}

The rest of the paper is organized as follows.
We introduce in Section~\ref{sec:mcmc} the important notions of this paper regarding EBM and MCMC procedures.
Section~\ref{sec:main} develops the main algorithmic contribution of this paper, namely \algo.
Section~\ref{sec:theory} introduces the main theoretical results of our paper and focuses on the ergodicity of our propose MCMC sampling method.
Section~\ref{sec:numericals} present several image generation experiments on a toy dataset and baseline deep image datasets.
 Section~\ref{sec:conclusion} concludes our work



\section{On MCMC based Energy Based Models}\label{sec:mcmc}


Given a stream of input data noted $x \in \xset \subset \rset^p$, the energy-based model (EBM) is a Gibbs distribution defined as follows:
\beq\label{eq:ebm}
p(x,\theta) = \frac{1}{Z(\theta)} \mathrm{exp}(f_{\theta}(x))
\eeq

where $\theta \in \Theta \subset \rset^d$ denotes the global vector parameters of our model and $Z(\theta) \eqdef \int_{x} \mathrm{exp}(f_{\theta}(x)) \textrm{d}x$ is the normalizing constant (with respect to $x$).
The natural way of fitting model \eqref{eq:ebm} is to employ Maximum Likelihood Estimation (MLE) to maximize the marginal likelihood $p(\theta)$ and consisting of finding the vector of parameters $\theta^*$ such that for any $x \in \xset$, 
\beq\label{eq:mle}
 \theta^*  = \arg \max \limits_{\theta \in \Theta} \log p(\theta) \eqsp.
 \eeq

The quantity of interest $p(\theta)$ is obtained by marginalizing over the input data $x \in \xset$ and formally reads $p(\theta) = \int_{x \in xset} p(x, \theta) q(x) \textrm{d}x$ where we note $q(x)$ the true distribution of the input data $x$.
The optimization task \eqref{eq:mle} is not tractable in closed form and requires an iterative procedure to be solved.
The standard algorithm used to train EBMs is Stochastic Gradient Descent (SGD), see \cite{robbins1951A,bottou2008}.
SGD requires having access to the gradient of the objective function $\log p(\theta)$. 
This latter requires computing an intractable, due to the high nonlinearity of the parametrized model we use in general $f_\theta(x)$.
Given the general form in \eqref{eq:ebm} we have that:
\beq
\begin{split}
\nabla \log p(\theta) & = \int_{x \in xset} \nabla \log p(x, \theta) q(x) \textrm{d}x \\
& =  \EE_{p(x,\theta)}[\nabla_\theta f_\theta(x)] - \EE_{q(x)}[\nabla_\theta f_\theta(x)] \eqsp,
\end{split}
\eeq
and a simple Monte Carlo approximation of $\nabla \log p(\theta)$ yields

\beq\label{eq:mcapprox}
\nabla \log p(\theta) \approx \frac{1}{m} \sum_{j=1}^m \nabla_\theta f_\theta(x^{p}_j) -  \frac{1}{n} \sum_{i=1}^n \nabla_\theta f_\theta(x^{q}_i) \eqsp,
\eeq
where are $\{x^{p}_j\}_{j=1}^m$ samples obtained from the EBM $p(x,\theta)$ and $\{x^{q}_i\}_{i=1}^n$ are samples obtained from the true data distribution $q(x)$.

While drawing samples from the data distribution is trivial, the challenge during the EBM training phase is to obtain good samples from the EBM distribution $p(x,\theta)$ for any model parameter $\theta \in \Theta$.
This task is generally done using MCMC methods.
State of the arts MCMC used in the EBM literature include Langevin dynamics, see \cite{grenander1994representations,roberts1996exponential} and Hamiltonian Monte Carlo (HMC), see \cite{neal2011mcmc}.
Those methods are detailed in the sequel and are important concepts throughout our paper.

\paragraph{Energy Based Models: }
Energy based models \cite{lecun2006tutorial,ngiam2011learning} are a class of generative models that leverages the power of Gibbs potential and high dimensional sampling techniques to produce high quality synthetic image samples.
Just as Variational Autotencoders (VAE) \cite{kingma2013auto} or Generative Adversarial Networks (GAN) \cite{goodfellow2014generative}, EBMs are powerful tools for generative modeling tasks, as a building block for a wide variety of tasks. 
The main purpose of EBMs is to learn an energy function \eqref{eq:ebm} that assigns low energy to a stream of observation and high energy values to other inputs.
Learning, or Training, of such models is done via Maximum Likelihood (ML) \cite{du2019implicit} or Score Matching \cite{song2020score} or Noise Constrastive Estimation \cite{gao2020flow}.
Yet, unlike VAE or GANn energy-based models enjoy from a single structure requiring training (versus several networks) resulting in more stability.
The use of implicit sampling techniques, such as MCMC, as detailed in the sequel, allows more flexibility trading of quality for computation time.
Overall, the \emph{implicit} property of the EBM, seen as a energy function, makes it a tool of choice as opposed to \emph{explicit} generators that are limited to some design choice (see prior choices for VAE or both networks design in GAN).


\paragraph{MCMC procedures: }
Whether for sampling from a posterior distribution \cite{}, or in general intractable likelihoods \cite{}, several inference methods are available.
Approximate inference is a partial solution to the inference problem and include techniques such as Variational Inference (VI) \cite{jordanvi,freitas} or Laplace Approximation \cite{wolfinger,rue2009approximate}. 
Those methods allow simplification of the intractable quantities and result in the collection of "good enough" samples.

As seen in \eqref{eq:mcapprox}, training an EBM requires obtaining samples from the model itself.
Given the nonconvexity of the structural model $f_\theta(\cdot)$ with respect to the model parameter $\theta$, direct sampling is not an option.
Besides, in order to update the model parameter $\theta$, usually through gradient descent type of methods \cite{bottou2008},  exact samples from the EBM are needed in order to compute a good approximation of its (intractable) gradient, see \eqref{eq:mcapprox}.
To do so, we generally have recourse to MCMC methods.
MCMC are a class of inference algorithms that provide a principled iterative approach to obtain samples from any intractable distribution.

While being exact, the samples generally represent a larger computation burden than methods such as VI.
Increasing the efficiency of MCMC methods, by obtaining exact samples, in other words constructing a chain that converges faster, in fewer transitions is thus of utmost importance in the context of optimizing our EBM.

Several attempts have been proposed for the standalone task of posterior sampling through the use of Langevin diffusion, see Unadjusted Langevin in \cite{brosse2017tamed} of MALA algorithm in \cite{roberts,robertsmala,durmus2017fast} or leveraging Hamiltonian Dynamics, see HMC in \cite{girolami}.

We propose in the next section, an improvement of the Langevin diffusion with the ultimate goal of speeding the EBM training procedure.
Our method includes this latter improvement in an end-to-end learning algorithms for Energy-Based Models.

\section{Gradient Informed Langevin Diffusion}\label{sec:main}

We now introduce the main algorithmic contribution of our paper, namely \algo.
\algo\ is a learning algorithm for EBMs, comprising a novel MCMC method for sampling negative samples from the intractable model.
We provide theoretical guarantees of our scheme in Section~\ref{sec:theory}.

\subsection{Preliminaries and Bottlenecks of Langevin MCMC based EBM}
State of the art MCMC sampling algorithm, particularly used during the training procedure of EBMs, is the discretized Langevin diffusion, casted as Stochastic Gradient Langevin Dynamics (SGLD), see \cite{welling2011bayesian}.

In particular, several applications using EBM and SGLD have thrived in image generation, Natural Language Processing or even biology \cite{du2020energy}.
Yet, the choice of the proposal, generally Gaussian, is critical for improving the performances of both the sampling step (inner loop of the whole procedure) and the EBM training.
We recall the vanilla discretized Langevin diffusion used in the related literature as follows:
\beq
z_t = z_{t-1} + \frac{\gamma}{2} \nabla \log \pi_\theta(z_t) + \sqrt{\gamma} B_t
\eeq
where $\pi_\theta(\cdot)$ is the target distribution, $z$ represents the states of the chains, \ie the generated samples in the context of EBM, $t$ is the MCMC iteration index, $\gamma$ is the constant stepsize and $B_t$ is the Brownian motion, usually set as a Gaussian noise and can be written as $B_t \eqdef = \Sigma \xi$ where $\xi$ is a standard Gaussian random variable.
This method directs the proposed moves towards areas of high probability for the stationary distribution $\pi_\theta$, for any $\theta \in \Theta$ , using the gradient of $\log \pi_{theta}$ and has been the object of several studies \cite{girolami,cotter2013mcmc}.
In high dimensional and highly nonlinear settings, the burden of computing this gradient for a certain number of MCMC transitions leads to a natural focus: the improvement on the behaviour of such sampling scheme by assimilating information about the landscape of the target, also called the stationary, distribution, while keeping its ease of implementation.

\subsection{\algo\, an Anisotropic Energy Based Modeling Approach}

Given the drawbacks of current MCMC methods used for training EBMs, we introduce a new sampler based on the Langevin updates presented above in Step~\ref{line:langevin} of Algorithm~\ref{alg:anila}.

\begin{algorithm}[H]
\caption{\algo\ for Energy-Based Model} \label{alg:anila}
\begin{algorithmic}[1]
%\small
\STATE \textbf{Input}: Total number of iterations $T$, number of MCMC transitions $K$ and of samples $M$, sequence of global learning rate ${\eta_t}_{t >0}$ for the EBM model update, sequence of MCMC stepsize ${\gamma_k}_{k >0}$ for the Langevin transitions, initial values $\theta_0$, initial chain states $\{ z_{0}^m \}_{m=1}^M$ and $n$ observations $\{ x_{i} \}_{i=1}^n$.
\FOR{$t=1$ to $T$}
\STATE Compute the anisotropic stepsize as follows: \label{line:step}
\beq\label{eq:step}
\stepsize_t = \frac{\thresh}{\max(\thresh, | \nabla f_{\theta_t}(z_{t-1}^m) |)}
\eeq
\STATE Draw $M$ samples $\{ z_{t}^m \}_{m=1}^M$ from the objective potential \eqref{eq:ebm} via Langevin diffusion:\label{line:langevin}
\FOR{$k=1$ to $K$}
\STATE Construct the Markov Chain as follows:
\beq\label{eq:anila}
z_{k}^{m} = z_{k-1}^m + \stepsize_k/2  \nabla f_{\theta_t}(z_{k-1}^m) + \sqrt{\stepsize_k} \mathsf{B}_k
\eeq
where $\mathsf{B}_t$ is the Brownian motion, drawn from a Normal distribution.
\ENDFOR
\STATE Assign $\{ z_{t}^m \}_{m=1}^M \leftarrow \{ z_{K}^m \}_{m=1}^M$.
\STATE Samples $m$ positive observations $\{ x_{i} \}_{i=1}^m$ from the empirical data distribution.
\STATE Compute the gradient of the empirical log-EBM \eqref{eq:ebm} as follows:
\beq
\begin{split}
&\nabla \sum_{i=1}^m \log p_{\theta_t}(x_i) \\
 =& \mathbb{E}_{p_{\text {data }}}\left[\nabla_{\theta} f_{\theta_t}(x)\right]-\mathbb{E}_{p_{\theta}}\left[\nabla_{\theta_t} f_{\theta}(z_t)\right]\\
 \approx & \frac{1}{m} \sum_{i=1}^{m} \nabla_{\theta} f_{\theta_t}\left(x_{i}\right)-\frac{1}{m} \sum_{i=1}^{m} \nabla_{\theta} f_{\theta_t}\left(z_t^m\right)
\end{split}
\eeq
\STATE Update the vector of global parameters of the EBM:\label{line:gradient}
\beq
\theta_{t+1} = \theta_{t} + \eta_t \nabla \sum_{i=1}^m \log p_{\theta_t}(x_i)
\eeq
\ENDFOR
\STATE \textbf{Output:} Vector of fitted parameters $\theta_{T+1}$
\end{algorithmic}
\end{algorithm}


\textbf{Heuristic behind the efficacy of \algo:}
Some past modifications have been proposed in particular to optimize the covariance matrix of the proposal of the general MCMC procedure in order to better stride the support of the target distribution. 
Langevin dynamics is one example of those improvements where the proposal is a Gaussian distribution where the mean depends on the gradient of the log target distribution and the covariance depends on some Brownian motion.
For instance, in \cite{atchade2006adaptive,marshall2012adaptive}, the authors propose adaptive and geometrically ergodic Langevin chains. 
Yet, one important characteristic of our EBM problem, is that for each model parameter through the EBM training iterations, the target distribution moves and the proposal should take that adjustment into account.
The technique in \cite{atchade2006adaptive,marshall2012adaptive} does not take the whole advantage of changing the proposal using the target distribution. 
In particular, the covariance matrix of the proposal is given by a stochastic approximation of the empirical covariance matrix. 
This choice seems completely relevant as soon as the convergence towards the stationary distribution is reached, in other words it would make sense towards the end of the EBM training, as the target distribution from a model parameter to the next one are similar. 
However, it does not provide a good guess of the variability during the first iterations of the chain since it is still very dependent on the initialization. 

Moreover, in  \cite{girolami2011riemann}, the authors consider the approximation of a constant. Even though this simplification leads to ease of implementation, the curvature metric chosen by the authors need to be inverted, step that can be a computational burden if not intractable. 
Especially in the case we are considering in our paper, \ie Convnet-based EBM, where the high nonlinearity would lead to intractable quantities.

Therefore, in \eqref{eq:step} and \eqref{eq:anila} of Algorithm~\ref{alg:anila}, we propose a variant of Langevin, to sample from a target distribution, using a full anisotropic covariance matrix based on the anisotropy and correlations of the target distribution, see the $\sqrt{\stepsize_t} \mathsf{B}_t$ term. 


\section{Geometric ergodicity of \algo\ sampler}\label{sec:theory}
We will present in this section, our theoretical analysis for the Markov Chain constructed using Line~\ref{line:step}-\ref{line:langevin}. 

Let $\Theta$ be a subset of $\rset^d$ for some integer $d >0$.
We denote by $\zset$ the measurable space of $\rset^\ell$ for some integer $\ell >0$.
We define a family of stationary distribution $\left(\pi_\theta(z) \right)_{\theta \in \Theta}$, probability density functions with respect to the Lebesgue measure on the measurable space $\zset$. This family of p.d.f. defines the stationary distributions of our newly introduced sampler.

\textbf{Important Note:} The stationary distributions are defined per $\theta \in \Theta$, \ie at each model update during the EBM optimization phase.

\subsection{Notations and Assumptions}
For any chain state $z \in \zset$ we denote by $\Pi_\theta(z,\cdot)$ the transition kernel as defined in the \algo\ update in Line~\ref{line:langevin}.

The objective of this section is to rigorously show that each transition kernel $\pi_\theta$ is uniformly geometrically ergodic and that this result is true uniformly in state $s$ on any compact subset $\mathcal{C} \in \zset$.
As a background note, a Markov chain, as built Line~\ref{line:langevin}, is said to be geometrically ergodic when $k$ iterations of the same transition kernel is converging to the stationary distribution of the chain and this convergence as a geometric dependence on $k$.

We begin with several usual assumptions for such results.
The first one is related to the continuity of the gradient of the log posterior distribution and the unit vector pointing in the direction of the sample $z$ and the unit vector pointing in the direction of the gradient of the log posterior distribution at $z$:
\begin{assumption}\label{ass:bounded}
(Continuity) The stationary distribution is positive and has continuous derivative such that for all $\theta \in \rset^d$:
\begin{equation}
\begin{split}
\lim \limits_{z \to \infty} \frac{z}{|z|} \nabla f_{\theta}(z) & = - \infty \\
 \lim \sup \limits_{z \to \infty} \frac{z}{|z|} \frac{\nabla f_{\theta}(z) }{|\nabla f_{\theta}(z) |} &< 0
\end{split}
\end{equation}
\end{assumption}

We assume also some regularity conditions of the stationary distributions with respect to state $s$:
\begin{assumption}\label{ass:contlogpi}
For all $z \in \zset$, $\theta \to \pi_\theta$ and $\theta \to \nabla \log \pi_\theta$ are continuous on $\Theta$.
\end{assumption}

For a positive and finite function noted $V: \zset \mapsto \rset$, we define the V-norm distance between two arbitrary transition kernels $\Pi_1$ and $\Pi_2$ as follows:

\beq
\| \Pi_1 - \Pi_2 \|_V \eqdef \sup \limits_{z \in \zset} \frac{\| \Pi_1(z, \cdot) - \Pi_2(z, \cdot) \|_V }{V(z)}
\eeq

The definition of this norm will allow us to establish a convergence rate for our sampling method by deriving an upper bound of the quantity $\| \Pi_\theta^k - \pi_\theta \|_V$ where $k$ denotes the number of MCMC transitions.
We also recall that $\Pi_\theta$ is the transition kernel defined by Line~\ref{line:langevin} and $\pi_\theta$ is the stationary distribution of our Markov chain. 
Then, this quantity characterizes how close to the target distribution, our chain is getting after a finite time of iterations and will eventually formalize \emph{V-uniform ergodicity} of our method.
We specify that strictly speaking $\pi_\theta$ is a probability measure, and not a transition kernel. However $\| \Pi_\theta^k - \pi_\theta \|_V$ is well-defined if we consider the the probability $\pi_\theta$ as a kernel by making the definition:

\beq
\pi(z, \mathcal{C}) \eqdef \pi(\mathcal{C}) \quad \textrm{for} \quad \mathcal{C} \in \zset, \quad z \in \zset
\eeq


Here, for some $\beta \in ] 0,1[$ we define the $V_\theta$ function, also know as the \emph{drift}, for all $z \in \zset$ as follows: 
\beq\label{eq:driftfunction}
V_\theta(z) \eqdef c_\theta \pi_\theta(z)^{-\beta} \eqsp,
\eeq
where $c_\theta$ is a constant, with respect to the chain state $s$, such that for all $z \in \zset$, $V_\theta(z) \geq 1$.
Again, we note that the V norm is, in our case, function of the chain state noted $z$ \emph{and} of the global model parameter $\theta$, estimated, and thus varying, through the optimization procedure.
The convergence rate will thus be given for a particular model estimate (precisely its supremum).
Define 

\beq\label{eq:vfunctions}
\begin{split}
V_1(z) & \eqdef \inf \limits_{\theta \in \Theta} V_\theta(z) \\
 V_2(z) & \eqdef \sup \limits_{\theta \in \Theta} V_\theta(z) \eqsp,
\end{split}
\eeq
and assume that
\begin{assumption}\label{ass:V2}
There exists a constant $a_0 > 0$ such that for all $\theta \in \Theta $ and $z \in \zset$, $V_2^{a_0}(z)$ is integrable against the kernel $\Pi_\theta(z, \cdot)$ and 
\beq
 \lim \sup  \limits_{a \to 0}  \sup \limits_{\theta \in \Theta, z \in \zset} \Pi_\theta V_2^a(z) = 1
\eeq

\end{assumption}

\subsection{Convergence Results}
We will now give the main convergence result of our sampling method in \algo.
The result consists of showing V-uniform ergodicity of the chain, the irreducibility of the transition kernels and their aperiodicity, see \cite{meyn2012markov} for more details. 
We also prove a drift condition which states that the transition kernels tend to bring back elements into a small set from which boils down V-uniform ergodicity of the transition kernels $(\Pi_\theta)_{\theta \in \Theta}$.


\begin{theo}\label{thm:thm1}
Assume H\ref{ass:bounded}-H\ref{ass:V2}.
For any $\theta \in \Theta$, there exists a drift function $V_\theta$, a set $\mathcal{O} \subset \zset$, a constant $0 < \epsilon \leq 1$ such that 
\beq\label{thm:main1}
\Pi_\theta(z, \bset) \geq  \epsilon \int_{\bset} \mathsf{1}_\xset(z)  \textrm{d}y \eqsp.
\eeq
Moreover there exists $0 < \mu < 1$, $\delta > 0$ and a drift function $V$, now independent of $\theta$ such that for all $z \zset$:
\beq\label{thm:main2}
\Pi_\theta V(z) \leq \mu V(z) + \delta \mathsf{1}_{\mathcal{O}}(z) \eqsp.
\eeq
\end{theo}

Theorem~\ref{thm:thm1} shows two important convergence results for our sampling method. 
First, it established the existence of a small set $\mathcal{O}$ leading to the crucially needed aperiodicity of the chain and ensuring that each transition moves toward a better state.
Then, it provide a uniform ergodicity result of our sampling method in \algo, via the so-called \emph{drift condition} providing the guarantee that our user-designed transition kernels $(\Pi_\theta)_{\theta \in \Theta}$ attracts the states into the small set $\mathcal{O}$.


Moreover, the independence on the EBM model parameter $\theta$ of $V$ in \eqref{thm:main2} leads to \emph{uniform} ergodicity as shown in the following Corollary.
While Theorem~\ref{thm:thm1} is critical for proving the aperiodicity and irreducibility of the chain, we now establish the geometric speed of convergence of the chain.
Not only we show the importance of the \emph{uniform} ergodicity of the chain, which makes it appealing for the EBM training since the model parameter $\theta$ is often updated, but we also derive a geometrical rate in the following:

\begin{coro}\label{coro:coro1}
Assume H\ref{ass:bounded}-H\ref{ass:V2}.
A direct consequence of Theorem~\ref{thm:thm1} is that the family of transition kernels $(\Pi_\theta)_{\theta \in \Theta}$ are uniformly ergodic,\ie for any compact $\mathcal{C} \subset \zset$, there exist constants $\rho \in ]0,1[$ and $e >0$ such for any iteration $t > 0$,we have:
\beq\label{coro:main}
\sup \limits_{z \in \mathcal{C}} \| \Pi_\theta^t f(\cdot) - \pi_\theta f(\cdot) \|_{V} \leq e \rho^k \| f \|_{V_\theta}
\eeq
where $V$ is the drift function used in Theorem~\ref{thm:thm1}.
\end{coro}

We develop in the following a sketch of proof of the main Theorem of our paper.
We give the important details leading to the desired ergodicity results.
Those various techniques are common in the MCMC literature and we refer the readers to several MCMC handbooks such as \cite{neal2011mcmc,meyn2012markov} for more understanding.

\subsection{Sketch of the Proofs}

\textcolor{red}{TO COMPLETE WITH SKETCH OF PROOF}
\begin{lemm}\label{lem:cone}
Define $\mathcal{P}(z) \eqdef \{ z- \ell \frac{z}{|z|} - i \nu , \, \textrm{with} \quad i > a - \ell  , \nu \in \{ \nu \in \rset^d, \| \nu \| < 1\}, |\nu - \frac{z- \ell \frac{z}{|z|} }{|z- \ell \frac{z}{|z|} |} \leq \frac{\epsilon}{2}   \}$ and $\accept(z) \eqdef \{ y \in \zset, \rho_\theta(z,y) \geq 1 \}$. Then for $z \in \zset$, $\mathcal{P}(z) \subset \accept(z)$
\end{lemm}


\section{Numerical Experiments}\label{sec:numericals}


We present in this section a collection of numerical experiments to show the effectiveness of our method.
Both on synthetic and real datasets, we put our EBM to the test of data generation.
After verifying the advantage of \algo\ on a Gaussian Mixture Model (GMM) retrieving the synthetic data observations, we next investigate its performance when learning a distribution over high-dimensional natural images such as pictures of flowers, see the Flowers dataset in \cite{nilsback2008automated}, or general concepts displayed in CIFAR-10 \cite{krizhevsky2009learning}.
For both methods, we use the Frechet Inception Distance (FID), as a reliable performance metrics as detailed in \cite{heusel2017gans}.
In the sequel, we tune the learning rates over a fine grid and report the best result for all methods.
For our method \algo, the threshold parameter $\thresh$, crucial for the implementation of the stepsize \eqref{eq:step} is tuned over a grid search as well.

\subsection{Application on Toy Example: Gaussian Mixture Model}

\textbf{Datasets.}
We first demonstrate the outcomes of both methods including our newly proposed \algo\ for low-dimensional toy distributions.
We generate synthetic 2D rings data points and use an EBM to learn the true data distribution and put it to the test of generating new faithful synthetic samples.

\medskip
\textbf{Methods and Settings.}
We consider two methods. 
Methods are ran with \emph{nonconvergent} MCMC, \ie, we do not necessitate the convergence to the stationary distribution of the Markov chains.
The number of transitions of the MCMC is set to $K= 100$ per EBM iteration. 
We use a standard deviation of $0.15$ as in \cite{nijkamp2020anatomy}.
Both methods have a constant learning rate of $0.14$.
The value of the threshold $\thresh$ for our \algo\ method is set to $\thresh = 0.01$.
The total number of EBM iterations is set to $T = 10\,000$.
The global learning rate $\eta$ is set to a constant equal to $0.0001$.

\medskip
\textbf{Network architectures.} 
For the backbone of the EBM model, noted $f_\theta(\cdot)$ in \eqref{eq:ebm}, we chose a CNN of $5$ 2D convolutional layers and Leaky ReLU activation functions, with the leakage parameter set to $0.05$.
The number of hidden neurons varies between $32$ and $64$.


\begin{figure}[H]
\begin{center}
\includegraphics[width=1.\linewidth]{figs/rings}
\end{center}
   \caption{(Rings Toy Dataset) Top: our method, namely \algo\ Bottom: vanilla Langevin Dynamics. Both methods are used with the same backbone architecture. }
\label{fig:resultstoy}
\end{figure}

\medskip
\textbf{Results.} 
We observe Figure~\ref{fig:resultstoy} the outputs of both methods on the toy dataset.
While both methods achieve a great representation of the truth after a large number of iterations, we notice that \algo\ learns an energy that closely approximates the true density during the first thousands of iterations if the training process.
The sharpness of the data generated by \algo\ in the first iterations shows an empirically better ability to sample from the 2D toy dataset.

\subsection{Flowers Dataset}

\textbf{Datasets.}
We now compare the algorithms on \emph{the Oxford Flowers 102} dataset \cite{nilsback2008automated}.
The dataset is composed of 102 flower categories.
Per request of the authors, the images have large scale, pose and light variations making the task of generating new samples particularly challenging.

\medskip
\textbf{Methods and Settings.}
Nonconvergent MCMC are also used in this experiments and the number of MCMC transitions is set to $K = 50$.
Global learning parameters of the gradient update is set to $0.001$ for both methods.


\medskip
\textbf{Network architectures.} 
The backbone of the energy function for this experiment is a vanilla ConvNet composed of $3 \times 3$ convolution layers with stride $1$.




\begin{figure}[H]
\begin{center}
        \mbox{
        \includegraphics[width=1.5in]{figs/flowerslangevin}
        \includegraphics[width=1.5in]{figs/flowersanila}
        }
\end{center}
	\caption{(Flowers Dataset). Left: Langevin Method. Right: \algo\ method. After 100k iterations.}
	\label{fig:flowers}
\end{figure}

\medskip
\textbf{Results.} We adopt a multi-layer fully connected neural network



\begin{figure}[H]
\begin{center}
        \includegraphics[width=3in]{figs/fid_flowers}
\end{center}
	\caption{(Flowers Dataset). FID values per method through 100k iterations}
	\label{fig:flowersfid}
\end{figure}

%\begin{table}[H]
%\small
%\caption{(Flowers Dataset). FID through the iterations}\label{tab:flowersfid}
%	\resizebox{\columnwidth}{!}{%
%\begin{tabular}{llllllll}
%\toprule[1pt]
% & 1k      & 5k         & 10k      & 20k          \\ \hline
%Vanilla Langevin &  &  &  &   \\
%\algo\ &  &  &  &   \\
%\toprule[1pt]
%\end{tabular}}
%\end{table}


\subsection{CIFAR Dataset}

\textbf{Datasets.}
For this third experiment we use the \textit{CIFAR10} dataset \cite{krizhevsky2009learning}.
\textit{CIFAR10}  is a popular computer-vision dataset of $50\,000$ training images and $10\,000$ test images, of size $32\times 32$. 


\medskip
\textbf{Methods and Settings.}
We employ the same nonconvergent MCMC strategies for this experiment.
The value of the threshold $\thresh$ for our \algo\ method is set to $\thresh = 0.0002$.
The total number of EBM iterations is set to $T = 100\,000$.
The global learning rate $\eta$ is set to a constant equal to $0.0001$.
In this experiment, we slightly change the last step of our method described in Algorithm~\ref{alg:anila}.
Indeed, Step~\ref{line:gradient} is not a plain Stochastic Gradient Descent here but we rather use the \textsc{Adam} optimizer \cite{KB15}.
The scaling factor of the Brownian motion, $\gamma$ is equal to $0.01$.

\medskip
\textbf{Network architectures.} 
We adopt a similar ConvNet as the one used in the Flowers example.



\begin{figure}[H]
\begin{center}
    \mbox{
        \includegraphics[width=1.5in]{figs/cifarlangevin}
        \includegraphics[width=1.5in]{figs/cifaranila}
        }
\end{center}
\caption{(CIFAR Dataset). Left: Langevin Method. Right: \algo\ method. After 100k iterations.}
	\label{fig:cifar}
\end{figure}

\medskip
\textbf{Results.} We adopt a multi-layer fully connected neural network

\begin{figure}[H]
\begin{center}
        \includegraphics[width=3in]{figs/fid_cifar}
\end{center}
	\caption{(CIFAR10 Dataset). FID values per method through 100k iterations}
	\label{fig:cifarfid}
\end{figure}

%\begin{table}[H]
%\small
%\caption{(CIFAR Dataset). FID through the iterations}\label{tab:cifarfid}
%	\resizebox{\columnwidth}{!}{%
%\begin{tabular}{llllllll}
%\toprule[1pt]
% & 1k      & 5k         & 10k      & 20k          \\ \hline
%Vanilla Langevin &  &  &  &   \\
%\algo\ &  &  &  &   \\
%\toprule[1pt]
%\end{tabular}}
%\end{table}


\section{Conclusion}\label{sec:conclusion}

Given the growing interest in self-supervised learning, we propose in this paper, a improvement of the so-called MCMC based Energy-Based Models.
In the particular case of a highly nonlinear structural model of the EBM, more precisely a Convolutional Neural Network in our paper, we tackle the complex task of sampling negative samples from the energy function.
The multi-modal and highly curved surface one must sample from inspire our technique called \algo, and based on a Stochastic Gradient Anisotropic Langevin dynamics, that updates the Markov Chain using an anisotropic stepsize in the vanilla Langevin update.
We provide strong theoretical guarantees for our novel method, including uniform ergodicity of the resulting chain.
Our method is put to test on several benchmarks data and image generation tasks including toy and real datasets such as CIFAR-10.

\clearpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{ref}
}

\newpage

\appendix

\onecolumn

\section{Proofs of Theorem~\ref{thm:thm1}}
\begin{Theorem*}
Assume H\ref{ass:bounded}-H\ref{ass:V2}.
For any $\theta \in \Theta$, there exists a drift function $V_\theta$, a set $\mathcal{O} \subset \zset$, a constant $0 < \epsilon \leq 1$ such that 
\beq
\Pi_\theta(z, \bset) \geq  \epsilon \int_{\bset} \mathsf{1}_\xset(z)  \textrm{d}y \eqsp.
\eeq
Moreover there exists $0 < \mu < 1$, $\delta > 0$ and a drift function $V$, now independent of $\theta$ such that for all $z \zset$:
\beq
\Pi_\theta V(z) \leq \mu V(z) + \delta \mathsf{1}_{\mathcal{O}}(z) \eqsp.
\eeq
\end{Theorem*}


\begin{proof}



\textbf{Notations used throughout this proof:} 

\begin{table}[htbp]
%\caption{Table of Notations}
% between the caption and the table
\begin{tabular}{r c p{17cm} }
\toprule
$\Pi_\theta$ & $\triangleq$ &  Transition kernel of the MCMC defined by \eqref{eq:anila}\\
$\mathcal{O}$ & $\triangleq$ & subset of $\rset^p$ and small set for kernel $\Pi_\theta$\\
& & \textcolor{red}{COMPLETE WITH ALL NOTATIONS USED}\\
\bottomrule
\end{tabular}
\label{tab:notations}
\end{table}



The proof of our results are divided into two parts.
We first prove the existence of a set noted $\mathcal{O}$ as a small set for our transition kernel $\Pi_\theta$.
Proving a small set is important to show that for any state, the Markov Chain does not stay in the same state, and thus help in proving its irreducibility and aperiodicity.

Then, we will prove the drift condition towards a small set.
This condition is crucial to prove the convergence of the chain since it states that the kernels tend to attract elements into that set. 
finally, uniform ergodicity is established as a consequence of those drift conditions.

\medskip
\noindent \textbf{(i) Existence of small set: }
Let $\mathcal{O}$ be a compact subset of the state space $\zset$.
We also denote the pdf of the Gaussian proposal of Line~\ref{line:step} as $z \to \prop{\theta}(z',z)$ for any current state of the chain $z' \in \zset$ and dependent on the EBM model parameter $\theta$.
Given \algo's MCMC update, at iteration $t$, the proposal is a Gaussian distribution of mean $z_{t-1}^m+ \stepsize_t/2  \nabla f_{\theta_t}(z_{t-1}^m)$ and covariance $\sqrt{\stepsize_t} \mathsf{B}_t$.

We recall the definition of the transition kernel in the case of a Metropolis adjustment and for any model parameter $\theta \in \Theta$ and state $z \in \zset$:

\beq 
\Pi_\theta(z, \bset) = \int_{\bset} \alpha_\theta(z, y) \prop{\theta}(z,y) \textrm{d}y + \mathsf{1}_bset(z)\int_{\zset} (1 - \alpha_\theta(z, y)) \prop{\theta}(z,y) \textrm{d}y
\eeq

where we have defined the Metropolis ratio between two states $z \in \zset$ and $y \in \bset$ as $\alpha_\theta(z, y) = \textrm{min}(1, \frac{\pi_\theta(z)  \prop{\theta}(z,y)}{\prop{\theta}(y,z) \pi_\theta(y)  })$.
Thanks to Assumption H\ref{ass:bounded} and to the fact that the threshold $\thresh$ leads to a symmetric positive definite covariance matrix with bounded non zero eigenvalues implies that the proposal distribution can be bounded by two zero-mean Gaussian distributions as follows:

\beq\label{eq:twogauss}
a n_{\sigma_1}(z - y) \leq \prop{\theta}(z,y)  \leq b n_{\sigma_2}(z - y) \quad \textrm{for all} \quad \theta \in \Theta
\eeq
where $\sigma_1$ and $\sigma_2$ are the corresponding standard deviation of the distributions and $a$ and $b$ are some scaling factors.

We denote by $\rho_\theta$ the ratio $\frac{\pi_\theta(z)  \prop{\theta}(z,y)}{\prop{\theta}(y,z) \pi_\theta(y)  }$ and define the quantity 
\beq\label{eq:delta}
\delta = \textrm{inf}(\rho_\theta(z,y), \theta \in \Theta, \quad z \in \mathcal{O} ) > 0
\eeq
 given the assumptions H\ref{ass:bounded} and H\ref{ass:contlogpi}.
Likewise, the proposal distribution is bounded from below by its some quantity noted $m$.
Then,
\beq
\Pi_\theta(z, \bset) \geq  \int_{\bset \cap \xset} \alpha_\theta(z, y) \prop{\theta}(z,y) \textrm{d}y \geq \textrm{min}(1, \delta) m \int_{\bset} \mathsf{1}_\xset(z)  \textrm{d}y
\eeq

Then, given the definition of \eqref{eq:delta}, we can find a compact set $\mathcal{O}$ such that $\Pi_\theta(z, \bset) \geq \geq \epsilon$ where $\epsilon = \textrm{min}(1, \delta) m \textbf{Z}$ where $\textbf{Z}$ is the normalizing constant of the pdf $\frac{1}{\textbf{Z}}\mathcal{1}_\xset(z)  \textrm{d}y$.
Thus proving \eqref{thm:main1}, \ie the existence of a small set for our family of transition kernels $(\Pi_\theta)_\theta$.

\medskip
\noindent \textbf{(ii) Drift condition and ergodicity: }
We first need to prove the fact that our family of transition kernels $(\Pi_\theta)_\theta$ satisfies a drift property.

For a given EBM model parameter $\theta \in \Theta$, we can see in \cite{jarner2000geometric} that the drift condition boils down to proving that for the drift function noted $V_\theta$ and defined in \eqref{eq:driftfunction}, we have
\beq\label{mainproof}
\sup \limits_{z \in \zset}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} < \infty \quad \textrm{and} \quad \lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} < 1
\eeq

Throughout the proof, the model parameter is set to an arbitrary $\theta \in \Theta$.
Let denote the acceptation set, \ie\ $\rho_\theta \geq 1$ by $\accept(z) \eqdef \{ y \in \zset, \rho_\theta(z,y) \geq 1 \}$ for any state $y \in \bset$ and its complementary set $\compaccept(z)$.

\medskip
\noindent \textsc{Step (1): } Following our definition of the drift function in \eqref{eq:driftfunction} we obtain:

\begin{align}\label{eq:main1}
 \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} & = \int_{\accept(z)}  \prop{\theta}(z,y) \frac{V_\theta(y)}{V_\theta(z)} \textrm{d}y +  \int_{\compaccept(z)} \frac{\pi_\theta(y)\prop{\theta}(y,z)}{\pi_\theta(z)\prop{\theta}(z,y)} \prop{\theta}(z,y) \frac{V_\theta(y)}{V_\theta(z)} \textrm{d}y +  \int_{\compaccept(z)} (1 - \frac{\pi_\theta(y)\prop{\theta}(y,z)}{\pi_\theta(z)\prop{\theta}(z,y)}) \prop{\theta}(z,y)  \textrm{d}y\\
 &  \overset{(a)}{\leq} \int_{\accept(z)}  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  + \int_{\compaccept(z)} \prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}\textrm{d}y +  \int_{\compaccept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}
where (a) is due to \eqref{eq:driftfunction}.

According to \eqref{eq:twogauss}, we thus have that, for any state $z$ in the acceptance set $\accept(z)$:
\beq \label{eq:comp}
\int_{\accept(z)}  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  \leq  b \int_{\accept(z)}  n_{\sigma_2}(y-z)  \textrm{d}y 
\eeq

For any state $z$ in the complementary set of the acceptance set $\compaccept(z)$ we also have the following:
\beq
\int_{\compaccept(z)} \prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}\textrm{d}y \leq \int_{\compaccept(z)} \prop{\theta}(z,y)^{1- \beta} \prop{\theta}(y,z)^{\beta}  \textrm{d}y \leq b \int_{\compaccept(z)} n_{\sigma_2}(z - y)  \textrm{d}y
\eeq


While we can define the level set of the stationary distribution $\pi_\theta$ as $\mathcal{L}_{\pi_\theta(y)} = \{ z \in \zset, \pi_\theta(z) = \pi_\theta(y) \}$ for some state $y \in \bset$, a neighborhood of that level set is defined as $\mathcal{L}_{\pi_\theta(y)}(p) = \{z \in  \mathcal{L}_{\pi_\theta(y)}, z + t \frac{z}{|z|}, |t| \leq p \}$.

H\ref{ass:bounded} ensures the existence of a radial $r$ such that for all $z \in \zset, |z| \geq r$, then $0 \in \mathcal{L}_{\pi_\theta(y)}$ with $\pi_\theta(z) >  \pi_\theta(y)$.

Since the function $y \to n_{\sigma_2}(y - z)$ is smooth, it is known that there exists a constant $a >0$ such that for $\epsilon >0$, we have that 
\beq\label{eq:lowandup}
\int_{B(z,a)}  n_{\sigma_2}(y - z) \textrm{d}y \geq 1 - \epsilon \quad \textrm{and} \quad \int_{B(z,a) \cap \mathcal{L}_{\pi_\theta(y)}(p) }  n_{\sigma_2}(y - z) \textrm{d}y \leq  \epsilon
\eeq
for some $p$ small enough and where $B(z,a)$ denotes the ball around $z \in \zset$ of radius $a$.
Then combining \eqref{eq:comp} and \eqref{eq:lowandup} we have that:

\beq
\int_{\accept(z) \cap B(z,a) \cap \mathcal{L}_{\pi_\theta(y)}(p) }  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  \leq  b \epsilon
\eeq

Conversely, we can define the set  $\mathcal{A} = \accept(z) \cap B(z,a) \cap \mathcal{L}^+$ where $u \in \mathcal{L}^+$ if $u \in \mathcal{L}_{\pi_\theta(y)}(p)$ and $\phi_\theta(u) > \pi_\theta(p)$.

Then using the second part of H\ref{ass:bounded}, there exists a radius $r' > r + a$, such that for $z \in \zset$ with $|z| \geq r'$ we have

\beq
\int_{\mathcal{A}} (\frac{\pi_\theta(y)}{\pi_\theta(z)})^{1-\beta} \prop{\theta}(y,z) \textrm{d}y \leq \mathsf{d}(p, r')^{1-\beta}  b \int_{\accept(z)}  n_{\sigma_2}(y-z)  \textrm{d}y\leq b \mathsf{d}(p, r')^{1-\beta} 
\eeq

where $\mathsf{d}(p, r') = \sup \limits_{|z| > r'} \frac{\pi_\theta(z + p \frac{z}{|z|})}{\pi_\theta(z)}$. 
Note that H\ref{ass:bounded} implies that $\mathsf{d}(p, r') \to 0$ when $r' \to \infty$.

Likewise with  $\mathcal{A} = \accept(z) \cap B(z,a) \cap \mathcal{L}^-$ we have
\beq
\int_{\mathcal{A}} (\frac{\pi_\theta(y)}{\pi_\theta(z)})^{-\beta} \prop{\theta}(z,y) \textrm{d}y  \leq b \mathsf{d}(p, r')^{\beta} 
\eeq

Same arguments can be obtained for the second term of \eqref{eq:main1}, \ie $\prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}$ and we obtain, plugging the above in \eqref{eq:main1} that:

\begin{align}
\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq \lim \sup \limits_{|z| \to \infty}  \int_{\compaccept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}

Since $\compaccept(z)$ is the complementary set of $\accept(z)$, the above inequality yields

\begin{align}
\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq 1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}



\medskip
\noindent \textsc{Step (2): } The final step of our proof consists in proving that $1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \leq 1 - c$ where $c$ is a constant, independent of all the other quantities.


Given that the proposal distribution is a Gaussian and using assumption H\ref{ass:bounded} we have the existence of a constant $c_a$ depending on $a$ as defined above (the radius of the ball $B(z,a)$ such that

\beq
\frac{\pi_\theta(z)}{\pi_\theta(z- \ell \frac{z}{|z|})} \leq  c_a \leq \inf \limits_{y \in B(z,a)} \frac{\prop{\theta}(y, z)}{\prop{\theta}(z, y)} \quad \textrm{for any} \, z \in \zset, |z| \geq r^*
\eeq

Then for any $|z| \geq r^*$, we obtain that $z- \ell \frac{z}{|z|} \in \accept(z)$.
A particular subset of $\accept(z)$ used throughout the rest of the proof is the cone defined as 

\beq\label{eq:defcone}
\mathcal{P}(z) \eqdef \{ z- \ell \frac{z}{|z|} - i \nu , \, \textrm{with} \quad i < a - \ell  , \nu \in \{ \nu \in \rset^d, \| \nu \| < 1\}, |\nu - \frac{z- \ell \frac{z}{|z|} }{|z- \ell \frac{z}{|z|} |} \leq \frac{\epsilon}{2}   \}
\eeq

Using Lemma~\ref{lem:cone}, we have that $\mathcal{P}(z) \subset \accept(z)$

Then,  

\beq 
 \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \overset{(a)}{\geq}  \int_{\accept(z)}a n_{\sigma_1}(y- z)  \textrm{d}y \overset{(b)}{\geq} a \int_{\mathcal{P}(z)}  n_{\sigma_1}(y-z)  \textrm{d}y
 \eeq
where we have used \eqref{eq:twogauss} in (a) and applied Lemma~\ref{lem:cone} in (b).

If we define the translation of vector $z \in \zset$ by the operator $\mathcal{I} \subset \rset^d \to T_z(\mathcal{I})$, then
\beq\label{eq:constant}
 \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \geq a \int_{\mathcal{P}(z)}  n_{\sigma_1}(y-z)  \textrm{d}y =  \int_{T_z(\mathcal{P}(z))}  n_{\sigma_1}(y-z)  \textrm{d}y
\eeq


Recalling the objective of \noindent \textsc{Step (2)} that is to find a constant $c$ such that $1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \leq 1 - c$, we see from \eqref{eq:constant} that since the set $\mathcal{P}(z)$ does not depend on the EBM model parameter $\theta$ and that once translated by $z$ the resulting set $T_z(\mathcal{P}(z))$ is independent of $z$ (but depends on $\ell$, see definition \eqref{eq:defcone}, then the integral $ \int_{T_z(\mathcal{P}(z))}  n_{\sigma_1}(y-z)  \textrm{d}y$ in \eqref{eq:constant} is independent of $z$ thus concluding on the existence of the constant $c$ such that $\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq 1- c$. Thus proving the second part of \eqref{mainproof} which is the main drift condition we ought to demonstrate.
The first part of \eqref{mainproof} can be proved by observing that $  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} $ is smooth on $\zset$ according to H\ref{ass:contlogpi} and by construction of the transition kernel. Smoothness implies boundedness on the compact $\zset$.


\medskip
\noindent \textsc{Step (3): } 
We now use the main proven equations in \eqref{mainproof} to derive the second result \eqref{thm:main2} of Theorem~\ref{thm:thm1}.

We will begin by showing a similar inequality for the drift function $V_\theta$, thus not having uniformity, as an intermediary step.
The Drift property is a consequence of \textsc{Step (2)} and \eqref{eq:constant} shown above.
Thus, there exists $0 < \bar{\mu} < 1$, $\bar{\delta} > 0$ such that for all $z \zset$:
\beq\label{eq:driftvtheta}
\Pi_\theta V_\theta(z) \leq \bar{\mu} V_\theta(z) + \bar{\delta} \mathsf{1}_{\mathcal{O}}(z) \eqsp,
\eeq
where $V_\theta$ is defined by \eqref{eq:driftfunction}.

Using the two functions defined in \eqref{eq:vfunctions}, we define for $z \in \zset$, the $V$ function independent of $\theta$ as follows:
\beq\label{eq:defv}
V(z) = V_1(z)^\alpha V_2(z)^{2\alpha} \eqsp,
\eeq
where $0 < \alpha < \textrm{min}(\frac{1}{2\beta},\frac{a_0}{3})$, $a_0$ is defined in H\ref{ass:V2} and $\beta$ is defined in \eqref{eq:driftfunction}.
Thus for $\theta \in \Theta$, $z \in \zset$ and $\epsilon >0$:
\begin{align}\notag
\Pi_\theta V(z) & = \int_{\zset} \Pi_\theta(z,y) V_1(y)^\alpha V_2(y)^{2\alpha} \textrm{d}y\\ \notag
& \overset{(a)}{\leq} \frac{1}{2} \int_{\zset} \Pi_\theta(z,y) (\frac{1}{\epsilon^2}V_1(y)^{2\alpha} + \epsilon^2 V_2(y)^{4\alpha}) \textrm{d}y\\ 
& \overset{(b)}{\leq} \frac{1}{2\epsilon^2} \int_{\zset} \Pi_\theta(z,y) V_\theta(y)^{2\alpha} + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y \label{eq:uniform1}
\end{align}
where we have used the Young's inequality in (a) and the definition of $V_1$, see \eqref{eq:vfunctions}, in (b).
Then plugging \eqref{eq:driftvtheta} in \eqref{eq:uniform1}, we have
\begin{align}
\Pi_\theta V(z) & \leq \frac{1}{2\epsilon^2} (\bar{\mu} V_\theta(z)^{2\alpha} + \bar{\delta} \mathsf{1}_{\mathcal{O}}(z) ) + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{2} \sup \limits_{\theta \in \Theta, z \in \zset} \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{1 + \bar{\mu}}V(z)\\
& \leq \left(\frac{\bar{\mu}}{2 \epsilon^2} + \frac{\epsilon^2}{1 + \bar{\mu}} \right) V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z) 
\end{align}

where we have used \eqref{eq:defv} and the assumption H\ref{ass:V2} in the last inequality, ensuring the existence of such exponent $\alpha$.

Setting $\epsilon \eqdef \sqrt{\frac{\bar{\mu}(1+\bar{\mu})}{2}}$, $ \mu  \eqdef  \sqrt{\frac{2\bar{\mu}}{1+\bar{\mu}}}$ and $\delta \eqdef \frac{\bar{\delta}}{2 \epsilon^2}$ proves the uniform ergodicity in \eqref{thm:main2} and concludes the proof of Theorem~\ref{thm:thm1}.
\end{proof}

\end{document}
