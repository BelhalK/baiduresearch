\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mcmahan2016communication,konevcny2016federated}
\citation{carlini2019secret,mcmahan2017learning}
\citation{zhou2018convergence,stich2019local,yu2019parallel,wang2018cooperative}
\citation{bottou-bousquet-2008}
\citation{lin2019don}
\citation{alistarh2017qsgd,bernstein2018signsgd,tang2018communication,wen2017terngrad,wu2018error}
\citation{alistarh2018convergence,lin2017deep,stich2018sparsified,stich2019error}
\citation{li2019federated,liang2019variance}
\citation{liang2019variance,karimireddy2019scaffold,horvath2019stochastic,haddadpour2020federated}
\citation{geyer2017differentially,hardy2017private}
\citation{mcmahan2017learning}
\citation{bonawitz2017practical}
\citation{DBLP:journals/tcs/CharikarCF04,cormode2005improved,kleinberg2003bursty,Proc:Li_Church_Hastie_NIPS08}
\citation{ivkin2019communication}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{ivkin2019communication}
\citation{rothchild2020fetchsgd}
\citation{ivkin2019communication,rothchild2020fetchsgd}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{zhang2016parallel}
\citation{mcmahan2016communication,konevcny2016federated}
\citation{zhou2018convergence,yu2019parallel,stich2019local,wang2018cooperative}
\citation{haddadpour2019local,haddadpour2019trading,basu2019qsparse,haddadpour2019convergence,bayoumi2020tighter,stich2019error}
\citation{yu2019linear,li2019convergence,sahu2018convergence,liang2019variance,haddadpour2019convergence,karimireddy2019scaffold}
\citation{reddi2020adaptive,chen2020toward}
\citation{ivkin2019communication}
\citation{robbins1951stochastic,bottou-bousquet-2008}
\citation{alistarh2017qsgd,lin2017deep,stich2018sparsified,horvath2019stochastic}
\citation{haddadpour2020federated,reisizadeh2020fedpaq,basu2019qsparse,horvath2019stochastic}
\citation{horvath2020better}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Setting and Related Work}{2}{section.2}}
\newlabel{sec:related}{{2}{2}{Problem Setting and Related Work}{section.2}{}}
\newlabel{eq:main}{{1}{2}{Problem Setting and Related Work}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Related Work}{2}{subsection.2.1}}
\citation{DBLP:journals/tcs/CharikarCF04}
\citation{kleinberg2003bursty}
\citation{kleinberg2003bursty}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{horvath2020better}
\@writefile{toc}{\contentsline {section}{\numberline {3}Count Sketch as a Compression Operation}{3}{section.3}}
\newlabel{sec:compression}{{3}{3}{Count Sketch as a Compression Operation}{section.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \texttt  {CS}\nobreakspace  {}\cite  {kleinberg2003bursty}: Count Sketch to compress ${\boldsymbol  {x}}\in \mathbb  {R}^{d}$. \relax }}{3}{algorithm.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:csketch}{{1}{3}{\texttt {CS}~\cite {kleinberg2003bursty}: Count Sketch to compress ${\boldsymbol {x}}\in \mathbb {R}^{d}$. \relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Sketching Based Unbiased Compressor}{3}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sketching based Biased Compressor}{3}{subsection.3.2}}
\citation{ivkin2019communication}
\citation{ivkin2019communication}
\citation{horvath2020better}
\citation{horvath2020better}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2019convergence}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces \texttt  {HEAVYMIX} \relax }}{4}{algorithm.2}}
\newlabel{alg:heavymix}{{2}{4}{\texttt {HEAVYMIX} \relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Sketching based Induced Compressor}{4}{subsection.3.3}}
\newlabel{lemm:induced_compress}{{3}{4}{Induced Compressor ~\cite {horvath2020better}}{lemma.3}{}}
\newlabel{cor:small}{{1}{4}{}{corollary.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces \texttt  {HEAPRIX} \relax }}{4}{algorithm.3}}
\newlabel{alg:heaprix}{{3}{4}{\texttt {HEAPRIX} \relax }{algorithm.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Algorithms for Homogeneous and Heterogeneous Settings}{4}{section.4}}
\newlabel{sec:algos}{{4}{4}{Algorithms for Homogeneous and Heterogeneous Settings}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Homogeneous Setting}{4}{subsection.4.1}}
\newlabel{rmrk:bidirect}{{4}{4}{Comparision with~\cite {haddadpour2020federated}}{remark.4}{}}
\citation{haddadpour2020federated}
\citation{liang2019variance}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces \texttt  {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }}{5}{algorithm.4}}
\newlabel{Alg:PFLHom}{{4}{5}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{line:heaprix1}{{5}{5}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{eq:update-rule-alg}{{9}{5}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{line:heaprix2}{{12}{5}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Heterogeneous Setting}{5}{subsection.4.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces \texttt  {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }}{5}{algorithm.5}}
\newlabel{Alg:PFLHet}{{5}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{line:cj_privix}{{4}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{eq:update-rule-alg-heter1}{{10}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{line:tildeS}{{16}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\citation{karimi2016linear}
\citation{karimireddy2019scaffold,wang2018cooperative,liang2019variance}
\citation{karimireddy2019scaffold}
\@writefile{toc}{\contentsline {section}{\numberline {5}Convergence Analysis}{6}{section.5}}
\newlabel{sec:cnvg-an}{{5}{6}{Convergence Analysis}{section.5}{}}
\newlabel{Assu:1}{{1}{6}{Smoothness and Lower Boundedness}{assumption.1}{}}
\newlabel{assum:pl}{{2}{6}{\pl }{assumption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Convergence of \texttt  {FEDSKETCH} for Homogeneous Setting}{6}{subsection.5.1}}
\newlabel{Assu:1.5}{{3}{6}{Bounded Variance}{assumption.3}{}}
\newlabel{thm:homog_case}{{1}{6}{}{theorem.1}{}}
\citation{ivkin2019communication}
\citation{karimireddy2019scaffold}
\citation{ivkin2019communication}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Convergence of \texttt  {FedSKETCHGATE} in Data Heterogeneous Setting}{7}{subsection.5.2}}
\newlabel{Assu:2}{{4}{7}{Bounded Local Variance}{assumption.4}{}}
\newlabel{thm:hetreg_case}{{2}{7}{}{theorem.2}{}}
\citation{li2019privacy}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{bayoumi2020tighter}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{li2018federated,haddadpour2019convergence}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of results with compression and periodic averaging in the homogeneous setting. Here, $m$ is the number of devices, $\mu $ is the PL constant, $m$ is the number of bins of hash tables, $d$ is the dimension of the model, $\kappa $ is the condition number, $\epsilon $ is the target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }}{8}{table.caption.2}}
\newlabel{table:1}{{1}{8}{Comparison of results with compression and periodic averaging in the homogeneous setting. Here, $m$ is the number of devices, $\mu $ is the PL constant, $m$ is the number of bins of hash tables, $d$ is the dimension of the model, $\kappa $ is the condition number, $\epsilon $ is the target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Comparison with Prior Methods}{8}{subsection.5.3}}
\citation{lecun1998gradient}
\citation{ivkin2019communication}
\citation{li2018federated}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of results with compression and periodic averaging in the heterogeneous setting. Here, $p$ is the number of devices, $\mu $ is compression of hash table, $d$ is the dimension of the model, $\kappa $ is condition number, $\epsilon $ is target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }}{9}{table.caption.3}}
\newlabel{table:2}{{2}{9}{Comparison of results with compression and periodic averaging in the heterogeneous setting. Here, $p$ is the number of devices, $\mu $ is compression of hash table, $d$ is the dimension of the model, $\kappa $ is condition number, $\epsilon $ is target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }{table.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Numerical Example}{9}{section.6}}
\newlabel{sec:experimnt}{{6}{9}{Numerical Example}{section.6}{}}
\citation{mcmahan2016communication,chen2020toward}
\citation{ivkin2019communication}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Homogeneous case: Comparison of compressed optimization methods on LeNet CNN architecture.\relax }}{10}{figure.caption.4}}
\newlabel{fig:MNIST-iid1}{{1}{10}{Homogeneous case: Comparison of compressed optimization methods on LeNet CNN architecture.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{10}{section.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN architecture.\relax }}{11}{figure.caption.5}}
\newlabel{fig:MNIST-iid0}{{2}{11}{Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN architecture.\relax }{figure.caption.5}{}}
\bibstyle{plain}
\bibdata{reference}
\bibcite{alistarh2017qsgd}{{1}{}{{}}{{}}}
\bibcite{alistarh2018convergence}{{2}{}{{}}{{}}}
\bibcite{basu2019qsparse}{{3}{}{{}}{{}}}
\bibcite{bernstein2018signsgd}{{4}{}{{}}{{}}}
\bibcite{bonawitz2017practical}{{5}{}{{}}{{}}}
\bibcite{bottou-bousquet-2008}{{6}{}{{}}{{}}}
\bibcite{carlini2019secret}{{7}{}{{}}{{}}}
\bibcite{DBLP:journals/tcs/CharikarCF04}{{8}{}{{}}{{}}}
\bibcite{chen2020toward}{{9}{}{{}}{{}}}
\bibcite{cormode2005improved}{{10}{}{{}}{{}}}
\bibcite{fergus2006removing}{{11}{}{{}}{{}}}
\bibcite{geyer2017differentially}{{12}{}{{}}{{}}}
\bibcite{gong2014gradient}{{13}{}{{}}{{}}}
\bibcite{haddadpour2019local}{{14}{}{{}}{{}}}
\bibcite{haddadpour2019trading}{{15}{}{{}}{{}}}
\bibcite{haddadpour2020federated}{{16}{}{{}}{{}}}
\bibcite{haddadpour2019convergence}{{17}{}{{}}{{}}}
\bibcite{hardy2017private}{{18}{}{{}}{{}}}
\bibcite{horvath2019stochastic}{{19}{}{{}}{{}}}
\bibcite{horvath2020better}{{20}{}{{}}{{}}}
\bibcite{ivkin2019communication}{{21}{}{{}}{{}}}
\bibcite{karimi2016linear}{{22}{}{{}}{{}}}
\bibcite{karimireddy2019scaffold}{{23}{}{{}}{{}}}
\bibcite{bayoumi2020tighter}{{24}{}{{}}{{}}}
\bibcite{kleinberg2003bursty}{{25}{}{{}}{{}}}
\bibcite{konevcny2016federated}{{26}{}{{}}{{}}}
\bibcite{lecun1998gradient}{{27}{}{{}}{{}}}
\bibcite{levin2007image}{{28}{}{{}}{{}}}
\bibcite{Proc:Li_Church_Hastie_NIPS08}{{29}{}{{}}{{}}}
\bibcite{li2019privacy}{{30}{}{{}}{{}}}
\bibcite{li2019federated}{{31}{}{{}}{{}}}
\bibcite{li2018federated}{{32}{}{{}}{{}}}
\bibcite{li2019convergence}{{33}{}{{}}{{}}}
\bibcite{liang2019variance}{{34}{}{{}}{{}}}
\bibcite{lin2019don}{{35}{}{{}}{{}}}
\bibcite{lin2017deep}{{36}{}{{}}{{}}}
\bibcite{liu2019enhancing}{{37}{}{{}}{{}}}
\bibcite{mcmahan2016communication}{{38}{}{{}}{{}}}
\bibcite{mcmahan2017learning}{{39}{}{{}}{{}}}
\bibcite{parmas2018total}{{40}{}{{}}{{}}}
\bibcite{philippenko2020artemis}{{41}{}{{}}{{}}}
\bibcite{reddi2020adaptive}{{42}{}{{}}{{}}}
\bibcite{reisizadeh2020fedpaq}{{43}{}{{}}{{}}}
\bibcite{robbins1951stochastic}{{44}{}{{}}{{}}}
\bibcite{rothchild2020fetchsgd}{{45}{}{{}}{{}}}
\bibcite{sahu2018convergence}{{46}{}{{}}{{}}}
\bibcite{stich2018sparsified}{{47}{}{{}}{{}}}
\bibcite{stich2019error}{{48}{}{{}}{{}}}
\bibcite{stich2019local}{{49}{}{{}}{{}}}
\bibcite{tang2018communication}{{50}{}{{}}{{}}}
\bibcite{wang2018cooperative}{{51}{}{{}}{{}}}
\bibcite{wen2017terngrad}{{52}{}{{}}{{}}}
\bibcite{wu2018error}{{53}{}{{}}{{}}}
\bibcite{yu2019linear}{{54}{}{{}}{{}}}
\bibcite{yu2019parallel}{{55}{}{{}}{{}}}
\bibcite{zhang2016parallel}{{56}{}{{}}{{}}}
\bibcite{zhou2018convergence}{{57}{}{{}}{{}}}
\citation{li2019convergence,haddadpour2019convergence}
\citation{li2019convergence,haddadpour2019convergence}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{philippenko2020artemis}
\citation{philippenko2020artemis}
\@writefile{toc}{\contentsline {paragraph}{Notation.}{15}{section*.7}}
\newlabel{fact:1}{{3}{15}{\cite {li2019convergence,haddadpour2019convergence}}{theorem.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Various known algorithms}{15}{appendix.A}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces \texttt  {PRIVIX} \cite  {li2019privacy}: Unbiased compressor based on sketching. \relax }}{15}{algorithm.6}}
\newlabel{Alg:privix}{{6}{15}{\texttt {PRIVIX} \cite {li2019privacy}: Unbiased compressor based on sketching. \relax }{algorithm.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Comparison with\nobreakspace  {}\cite  {philippenko2020artemis}.}{15}{appendix.B}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Results for the Homogeneous Setting}{15}{appendix.C}}
\newlabel{sec:app:sgd:undrr-pl}{{C}{15}{Results for the Homogeneous Setting}{appendix.C}{}}
\newlabel{lemma:tasbih1-iid}{{4}{15}{}{lemma.4}{}}
\newlabel{eq:lemma1}{{4}{15}{}{equation.C.4}{}}
\newlabel{eq:lemma111}{{5}{16}{Results for the Homogeneous Setting}{equation.C.5}{}}
\newlabel{eq:100000}{{6}{17}{Results for the Homogeneous Setting}{equation.C.6}{}}
\newlabel{eq:var_b_mid}{{7}{17}{Results for the Homogeneous Setting}{equation.C.7}{}}
\newlabel{eq:lemma112}{{8}{17}{Results for the Homogeneous Setting}{equation.C.8}{}}
\newlabel{eq:mid-bounding-absg}{{9}{17}{Results for the Homogeneous Setting}{equation.C.9}{}}
\newlabel{lemma:cross-inner-bound-unbiased}{{5}{17}{}{lemma.5}{}}
\newlabel{eq:lemma3-thm2}{{11}{17}{}{equation.C.11}{}}
\newlabel{eq:bounding-cross-no-redundancy}{{12}{18}{Results for the Homogeneous Setting}{equation.C.12}{}}
\newlabel{lemma:dif-under-pl-sgd-iid}{{6}{18}{}{lemma.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Main result for the non-convex setting}{19}{subsection.C.1}}
\newlabel{thm:lsgwd-lr}{{4}{19}{non-convex}{theorem.4}{}}
\newlabel{eq:cnd-thm4.3}{{14}{19}{non-convex}{equation.C.14}{}}
\newlabel{eq:thm1-result}{{15}{19}{non-convex}{equation.C.15}{}}
\newlabel{eq:decent-smoothe}{{16}{19}{Main result for the non-convex setting}{equation.C.16}{}}
\newlabel{eq:Lipschitz-c1}{{17}{19}{Main result for the non-convex setting}{equation.C.17}{}}
\newlabel{eq:Lipschitz-c-gd}{{18}{19}{Main result for the non-convex setting}{equation.C.18}{}}
\newlabel{eq:finalll}{{19}{20}{Main result for the non-convex setting}{equation.C.19}{}}
\newlabel{eq:convg-error}{{20}{20}{Linear speed up}{equation.C.20}{}}
\newlabel{rmk:cnd-lr}{{6}{20}{}{remark.6}{}}
\newlabel{eq:lrcnd}{{21}{20}{}{equation.C.21}{}}
\citation{wang2018cooperative}
\citation{wang2018cooperative}
\newlabel{eq:iidexact}{{22}{21}{}{equation.C.22}{}}
\newlabel{eq:lrbnd-homog}{{23}{21}{}{equation.C.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Main result for the PL/Strongly convex setting}{21}{subsection.C.2}}
\newlabel{thm:pl-iid}{{5}{21}{PL or strongly convex}{theorem.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Main result for the general convex setting}{23}{subsection.C.3}}
\newlabel{thm:cvx-iid}{{6}{23}{Convex}{theorem.6}{}}
\newlabel{eq:cvx-iid}{{27}{23}{Convex}{equation.C.27}{}}
\newlabel{eq:mid-cvx}{{28}{23}{Main result for the general convex setting}{equation.C.28}{}}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\@writefile{toc}{\contentsline {section}{\numberline {D}Proof of Main Theorems}{24}{appendix.D}}
\newlabel{Assu:quant}{{5}{24}{\cite {haddadpour2020federated}}{assumption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Proof of Theorem\nobreakspace  {}\ref  {thm:homog_case}}{24}{subsection.D.1}}
\newlabel{thm:fromhaddad}{{7}{24}{\cite {haddadpour2020federated}}{theorem.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Proof of Theorem\nobreakspace  {}\ref  {thm:hetreg_case}}{24}{subsection.D.2}}
\newlabel{assum:009}{{6}{24}{\cite {haddadpour2020federated}}{assumption.6}{}}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\newlabel{thm:fromhaddad-het}{{8}{25}{}{theorem.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Additional Plots for the Numerical Experiments}{25}{appendix.E}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Homogeneous setting}{25}{subsection.E.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Homogeneous case: Comparison of compressed optimization methods on LeNet CNN architecture.\relax }}{25}{figure.caption.8}}
\newlabel{fig:MNIST-iid1}{{3}{25}{Homogeneous case: Comparison of compressed optimization methods on LeNet CNN architecture.\relax }{figure.caption.8}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {subsection}{\numberline {E.2}Heterogeneous setting}{26}{subsection.E.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN architecture.\relax }}{26}{figure.caption.9}}
\newlabel{fig:MNIST-iid0}{{4}{26}{Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN architecture.\relax }{figure.caption.9}{}}
