\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mcmahan2016communication,konevcny2016federated}
\citation{carlini2019secret,mcmahan2017learning}
\citation{zhou2018convergence,stich2019local,yu2019parallel,wang2018cooperative}
\citation{bottou-bousquet-2008}
\citation{lin2019don}
\citation{mcmahan2016communication,konevcny2016federated}
\citation{zhou2018convergence,yu2019parallel,stich2019local,wang2018cooperative}
\citation{haddadpour2019local,haddadpour2019trading,basu2019qsparse,haddadpour2019convergence,bayoumi2020tighter,stich2019error}
\citation{yu2019linear,li2019convergence,sahu2018convergence,liang2019variance,haddadpour2019convergence,karimireddy2019scaffold}
\citation{reddi2020adaptive,chen2020toward}
\citation{alistarh2017qsgd,bernstein2018signsgd,tang2018communication,wen2017terngrad,wu2018error}
\citation{alistarh2018convergence,lin2017deep,stich2018sparsified,stich2019error}
\citation{li2019federated,liang2019variance}
\citation{liang2019variance,karimireddy2019scaffold,horvath2019stochastic,haddadpour2020federated}
\citation{geyer2017differentially,hardy2017private}
\citation{mcmahan2017learning}
\citation{bonawitz2017practical}
\citation{DBLP:journals/tcs/CharikarCF04,cormode2005improved,kleinberg2003bursty,Proc:Li_Church_Hastie_NIPS08}
\citation{ivkin2019communication}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{ivkin2019communication}
\citation{rothchild2020fetchsgd}
\citation{ivkin2019communication,rothchild2020fetchsgd}
\citation{ivkin2019communication}
\citation{robbins1951stochastic,bottou-bousquet-2008}
\citation{alistarh2017qsgd,lin2017deep,stich2018sparsified,horvath2019stochastic}
\citation{horvath2020better}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{eq:main}{{1}{1}{Introduction}{equation.1.1}{}}
\citation{DBLP:journals/tcs/CharikarCF04}
\citation{kleinberg2003bursty}
\citation{kleinberg2003bursty}
\@writefile{toc}{\contentsline {section}{\numberline {2}Compressions using Count Sketch}{2}{section.2}}
\newlabel{sec:compression}{{2}{2}{Compressions using Count Sketch}{section.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \texttt  {CS}\nobreakspace  {}\cite  {kleinberg2003bursty}: Count Sketch to compress ${\boldsymbol  {x}}\in \mathbb  {R}^{d}$. \relax }}{2}{algorithm.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:csketch}{{1}{2}{\texttt {CS}~\cite {kleinberg2003bursty}: Count Sketch to compress ${\boldsymbol {x}}\in \mathbb {R}^{d}$. \relax }{algorithm.1}{}}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{horvath2020better}
\citation{ivkin2019communication}
\citation{ivkin2019communication}
\citation{horvath2020better}
\citation{horvath2020better}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Sketching based Unbiased Compressor}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Sketching based Biased Compressor}{3}{subsection.2.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces \texttt  {HEAVYMIX} \relax }}{3}{algorithm.2}}
\newlabel{alg:heavymix}{{2}{3}{\texttt {HEAVYMIX} \relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Sketching based Induced Compressor}{3}{subsection.2.3}}
\newlabel{lemm:induced_compress}{{3}{3}{Induced Compressor ~\cite {horvath2020better}}{lemma.3}{}}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2019convergence}
\citation{haddadpour2020federated}
\citation{liang2019variance}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces \texttt  {HEAPRIX} \relax }}{4}{algorithm.3}}
\newlabel{alg:heaprix}{{3}{4}{\texttt {HEAPRIX} \relax }{algorithm.3}{}}
\newlabel{cor:small}{{1}{4}{}{corollary.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Algorithms for Homogeneous and Heterogeneous Settings}{4}{section.3}}
\newlabel{sec:algos}{{3}{4}{Algorithms for Homogeneous and Heterogeneous Settings}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Homogeneous Setting}{4}{subsection.3.1}}
\newlabel{rmrk:bidirect}{{4}{4}{Comparison with~\cite {haddadpour2020federated}}{remark.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Heterogeneous Setting}{4}{subsection.3.2}}
\citation{karimi2016linear}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces \texttt  {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }}{5}{algorithm.4}}
\newlabel{Alg:PFLHom}{{4}{5}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{line:heaprix1}{{5}{5}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{eq:update-rule-alg}{{9}{5}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\newlabel{line:heaprix2}{{12}{5}{\texttt {FedSKETCH}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching. \relax }{algorithm.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Convergence Analysis}{5}{section.4}}
\newlabel{sec:cnvg-an}{{4}{5}{Convergence Analysis}{section.4}{}}
\newlabel{Assu:1}{{1}{5}{Smoothness and Lower Boundedness}{assumption.1}{}}
\newlabel{assum:pl}{{2}{5}{\pl }{assumption.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces \texttt  {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }}{5}{algorithm.5}}
\newlabel{Alg:PFLHet}{{5}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{line:cj_privix}{{4}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{eq:update-rule-alg-heter1}{{10}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\newlabel{line:tildeS}{{16}{5}{\texttt {FedSKETCHGATE}($R$, $\tau , \eta , \gamma $): Private Federated Learning with Sketching and gradient tracking. \relax }{algorithm.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Convergence of \texttt  {FEDSKETCH} }{5}{subsection.4.1}}
\newlabel{Assu:1.5}{{3}{5}{Bounded Variance}{assumption.3}{}}
\newlabel{thm:homog_case}{{1}{5}{}{theorem.1}{}}
\citation{karimireddy2019scaffold,wang2018cooperative,liang2019variance}
\citation{karimireddy2019scaffold}
\citation{ivkin2019communication}
\citation{karimireddy2019scaffold}
\citation{ivkin2019communication}
\citation{li2019privacy}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{bayoumi2020tighter}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{li2018federated,haddadpour2019convergence}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\citation{rothchild2020fetchsgd}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Convergence of \texttt  {FedSKETCHGATE}}{7}{subsection.4.2}}
\newlabel{Assu:2}{{4}{7}{Bounded Local Variance}{assumption.4}{}}
\newlabel{thm:hetreg_case}{{2}{7}{}{theorem.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Comparison with Prior Methods}{7}{subsection.4.3}}
\citation{lecun1998gradient}
\citation{ivkin2019communication}
\citation{li2018federated}
\citation{mcmahan2016communication,chen2020toward}
\citation{ivkin2019communication}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of results with compression and periodic averaging in the homogeneous setting. Here, $m$ is the number of devices, $\mu $ is the PL constant, $m$ is the number of bins of hash tables, $d$ is the dimension of the model, $\kappa $ is the condition number, $\epsilon $ is the target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }}{8}{table.caption.2}}
\newlabel{table:1}{{1}{8}{Comparison of results with compression and periodic averaging in the homogeneous setting. Here, $m$ is the number of devices, $\mu $ is the PL constant, $m$ is the number of bins of hash tables, $d$ is the dimension of the model, $\kappa $ is the condition number, $\epsilon $ is the target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }{table.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical Applications}{8}{section.5}}
\newlabel{sec:experimnt}{{5}{8}{Numerical Applications}{section.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of results with compression and periodic averaging in the heterogeneous setting. Here, $p$ is the number of devices, $\mu $ is compression of hash table, $d$ is the dimension of the model, $\kappa $ is condition number, $\epsilon $ is target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }}{9}{table.caption.3}}
\newlabel{table:2}{{2}{9}{Comparison of results with compression and periodic averaging in the heterogeneous setting. Here, $p$ is the number of devices, $\mu $ is compression of hash table, $d$ is the dimension of the model, $\kappa $ is condition number, $\epsilon $ is target accuracy, $R$ is the number of communication rounds, and $\tau $ is the number of local updates. UG and PP stand for Unbounded Gradient and Privacy Property respectively.\relax }{table.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{9}{section.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Homogeneous case: Comparison of compressed optimization methods on LeNet CNN.\relax }}{10}{figure.caption.4}}
\newlabel{fig:MNIST-iid1}{{1}{10}{Homogeneous case: Comparison of compressed optimization methods on LeNet CNN.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN.\relax }}{10}{figure.caption.5}}
\newlabel{fig:MNIST-iid0}{{2}{10}{Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN.\relax }{figure.caption.5}{}}
\bibstyle{plain}
\bibdata{reference}
\bibcite{alistarh2017qsgd}{{1}{}{{}}{{}}}
\bibcite{alistarh2018convergence}{{2}{}{{}}{{}}}
\bibcite{basu2019qsparse}{{3}{}{{}}{{}}}
\bibcite{bernstein2018signsgd}{{4}{}{{}}{{}}}
\bibcite{bonawitz2017practical}{{5}{}{{}}{{}}}
\bibcite{bottou-bousquet-2008}{{6}{}{{}}{{}}}
\bibcite{carlini2019secret}{{7}{}{{}}{{}}}
\bibcite{DBLP:journals/tcs/CharikarCF04}{{8}{}{{}}{{}}}
\bibcite{chen2020toward}{{9}{}{{}}{{}}}
\bibcite{cormode2005improved}{{10}{}{{}}{{}}}
\bibcite{fergus2006removing}{{11}{}{{}}{{}}}
\bibcite{geyer2017differentially}{{12}{}{{}}{{}}}
\bibcite{gong2014gradient}{{13}{}{{}}{{}}}
\bibcite{haddadpour2019local}{{14}{}{{}}{{}}}
\bibcite{haddadpour2019trading}{{15}{}{{}}{{}}}
\bibcite{haddadpour2020federated}{{16}{}{{}}{{}}}
\bibcite{haddadpour2019convergence}{{17}{}{{}}{{}}}
\bibcite{hardy2017private}{{18}{}{{}}{{}}}
\bibcite{horvath2019stochastic}{{19}{}{{}}{{}}}
\bibcite{horvath2020better}{{20}{}{{}}{{}}}
\bibcite{ivkin2019communication}{{21}{}{{}}{{}}}
\bibcite{karimi2016linear}{{22}{}{{}}{{}}}
\bibcite{karimireddy2019scaffold}{{23}{}{{}}{{}}}
\bibcite{bayoumi2020tighter}{{24}{}{{}}{{}}}
\bibcite{kleinberg2003bursty}{{25}{}{{}}{{}}}
\bibcite{konevcny2016federated}{{26}{}{{}}{{}}}
\bibcite{lecun1998gradient}{{27}{}{{}}{{}}}
\bibcite{levin2007image}{{28}{}{{}}{{}}}
\bibcite{Proc:Li_Church_Hastie_NIPS08}{{29}{}{{}}{{}}}
\bibcite{li2019privacy}{{30}{}{{}}{{}}}
\bibcite{li2019federated}{{31}{}{{}}{{}}}
\bibcite{li2018federated}{{32}{}{{}}{{}}}
\bibcite{li2019convergence}{{33}{}{{}}{{}}}
\bibcite{liang2019variance}{{34}{}{{}}{{}}}
\bibcite{lin2019don}{{35}{}{{}}{{}}}
\bibcite{lin2017deep}{{36}{}{{}}{{}}}
\bibcite{liu2019enhancing}{{37}{}{{}}{{}}}
\bibcite{mcmahan2016communication}{{38}{}{{}}{{}}}
\bibcite{mcmahan2017learning}{{39}{}{{}}{{}}}
\bibcite{parmas2018total}{{40}{}{{}}{{}}}
\bibcite{philippenko2020artemis}{{41}{}{{}}{{}}}
\bibcite{reddi2020adaptive}{{42}{}{{}}{{}}}
\bibcite{reisizadeh2020fedpaq}{{43}{}{{}}{{}}}
\bibcite{robbins1951stochastic}{{44}{}{{}}{{}}}
\bibcite{rothchild2020fetchsgd}{{45}{}{{}}{{}}}
\bibcite{sahu2018convergence}{{46}{}{{}}{{}}}
\bibcite{stich2018sparsified}{{47}{}{{}}{{}}}
\bibcite{stich2019error}{{48}{}{{}}{{}}}
\bibcite{stich2019local}{{49}{}{{}}{{}}}
\bibcite{tang2018communication}{{50}{}{{}}{{}}}
\bibcite{wang2018cooperative}{{51}{}{{}}{{}}}
\bibcite{wen2017terngrad}{{52}{}{{}}{{}}}
\bibcite{wu2018error}{{53}{}{{}}{{}}}
\bibcite{yu2019linear}{{54}{}{{}}{{}}}
\bibcite{yu2019parallel}{{55}{}{{}}{{}}}
\bibcite{zhang2016parallel}{{56}{}{{}}{{}}}
\bibcite{zhou2018convergence}{{57}{}{{}}{{}}}
\citation{li2019convergence,haddadpour2019convergence}
\citation{li2019convergence,haddadpour2019convergence}
\citation{li2019privacy}
\citation{li2019privacy}
\citation{philippenko2020artemis}
\citation{philippenko2020artemis}
\@writefile{toc}{\contentsline {paragraph}{Notation.}{14}{section*.7}}
\newlabel{fact:1}{{3}{14}{\cite {li2019convergence,haddadpour2019convergence}}{theorem.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Various known algorithms}{14}{appendix.A}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces \texttt  {PRIVIX} \cite  {li2019privacy}: Unbiased compressor based on sketching. \relax }}{14}{algorithm.6}}
\newlabel{Alg:privix}{{6}{14}{\texttt {PRIVIX} \cite {li2019privacy}: Unbiased compressor based on sketching. \relax }{algorithm.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Comparison with\nobreakspace  {}\cite  {philippenko2020artemis}.}{14}{appendix.B}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Results for the Homogeneous Setting}{14}{appendix.C}}
\newlabel{sec:app:sgd:undrr-pl}{{C}{14}{Results for the Homogeneous Setting}{appendix.C}{}}
\newlabel{lemma:tasbih1-iid}{{4}{14}{}{lemma.4}{}}
\newlabel{eq:lemma1}{{4}{14}{}{equation.C.4}{}}
\newlabel{eq:lemma111}{{5}{15}{Results for the Homogeneous Setting}{equation.C.5}{}}
\newlabel{eq:100000}{{6}{16}{Results for the Homogeneous Setting}{equation.C.6}{}}
\newlabel{eq:var_b_mid}{{7}{16}{Results for the Homogeneous Setting}{equation.C.7}{}}
\newlabel{eq:lemma112}{{8}{16}{Results for the Homogeneous Setting}{equation.C.8}{}}
\newlabel{eq:mid-bounding-absg}{{9}{16}{Results for the Homogeneous Setting}{equation.C.9}{}}
\newlabel{lemma:cross-inner-bound-unbiased}{{5}{16}{}{lemma.5}{}}
\newlabel{eq:lemma3-thm2}{{11}{16}{}{equation.C.11}{}}
\newlabel{eq:bounding-cross-no-redundancy}{{12}{17}{Results for the Homogeneous Setting}{equation.C.12}{}}
\newlabel{lemma:dif-under-pl-sgd-iid}{{6}{17}{}{lemma.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Main result for the non-convex setting}{18}{subsection.C.1}}
\newlabel{thm:lsgwd-lr}{{4}{18}{non-convex}{theorem.4}{}}
\newlabel{eq:cnd-thm4.3}{{14}{18}{non-convex}{equation.C.14}{}}
\newlabel{eq:thm1-result}{{15}{18}{non-convex}{equation.C.15}{}}
\newlabel{eq:decent-smoothe}{{16}{18}{Main result for the non-convex setting}{equation.C.16}{}}
\newlabel{eq:Lipschitz-c1}{{17}{18}{Main result for the non-convex setting}{equation.C.17}{}}
\newlabel{eq:Lipschitz-c-gd}{{18}{18}{Main result for the non-convex setting}{equation.C.18}{}}
\newlabel{eq:finalll}{{19}{19}{Main result for the non-convex setting}{equation.C.19}{}}
\newlabel{eq:convg-error}{{20}{19}{Linear speed up}{equation.C.20}{}}
\newlabel{rmk:cnd-lr}{{6}{19}{}{remark.6}{}}
\newlabel{eq:lrcnd}{{21}{19}{}{equation.C.21}{}}
\citation{wang2018cooperative}
\citation{wang2018cooperative}
\newlabel{eq:iidexact}{{22}{20}{}{equation.C.22}{}}
\newlabel{eq:lrbnd-homog}{{23}{20}{}{equation.C.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Main result for the PL/Strongly convex setting}{20}{subsection.C.2}}
\newlabel{thm:pl-iid}{{5}{20}{PL or strongly convex}{theorem.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Main result for the general convex setting}{22}{subsection.C.3}}
\newlabel{thm:cvx-iid}{{6}{22}{Convex}{theorem.6}{}}
\newlabel{eq:cvx-iid}{{27}{22}{Convex}{equation.C.27}{}}
\newlabel{eq:mid-cvx}{{28}{22}{Main result for the general convex setting}{equation.C.28}{}}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\@writefile{toc}{\contentsline {section}{\numberline {D}Proof of Main Theorems}{23}{appendix.D}}
\newlabel{Assu:quant}{{5}{23}{\cite {haddadpour2020federated}}{assumption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Proof of Theorem\nobreakspace  {}\ref  {thm:homog_case}}{23}{subsection.D.1}}
\newlabel{thm:fromhaddad}{{7}{23}{\cite {haddadpour2020federated}}{theorem.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Proof of Theorem\nobreakspace  {}\ref  {thm:hetreg_case}}{23}{subsection.D.2}}
\newlabel{assum:009}{{6}{23}{\cite {haddadpour2020federated}}{assumption.6}{}}
\citation{haddadpour2020federated}
\citation{haddadpour2020federated}
\newlabel{thm:fromhaddad-het}{{8}{24}{}{theorem.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Additional Plots for the Numerical Experiments}{24}{appendix.E}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Homogeneous setting}{24}{subsection.E.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Homogeneous case: Comparison of compressed optimization methods on LeNet CNN architecture.\relax }}{24}{figure.caption.8}}
\newlabel{fig:MNIST-iid1}{{3}{24}{Homogeneous case: Comparison of compressed optimization methods on LeNet CNN architecture.\relax }{figure.caption.8}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {subsection}{\numberline {E.2}Heterogeneous setting}{25}{subsection.E.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN architecture.\relax }}{25}{figure.caption.9}}
\newlabel{fig:MNIST-iid0}{{4}{25}{Heterogeneous case: Comparison of compressed optimization algorithms on LeNet CNN architecture.\relax }{figure.caption.9}{}}
