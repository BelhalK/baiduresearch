\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Our motivations}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Our contributions}{section.1}% 3
\BOOKMARK [1][-]{section.2}{Related Work}{}% 4
\BOOKMARK [1][-]{section.3}{On the Decentralization of the EM algorithm}{}% 5
\BOOKMARK [2][-]{subsection.3.1}{Distributed SAEM}{section.3}% 6
\BOOKMARK [2][-]{subsection.3.2}{Federated SAEM with Quantization and Compression}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.3}{Embedded methods to comply with Federated settings}{section.3}% 8
\BOOKMARK [1][-]{section.4}{Theoretical Analysis}{}% 9
\BOOKMARK [2][-]{subsection.4.1}{Finite-time convergence analysis of the d-SAEM}{section.4}% 10
\BOOKMARK [2][-]{subsection.4.2}{Finite-time convergence analysis of the fl-SAEM}{section.4}% 11
\BOOKMARK [1][-]{section.5}{Numerical Experiments}{}% 12
\BOOKMARK [2][-]{subsection.5.1}{Nonlinear Mixed Models under Distributed Settings}{section.5}% 13
\BOOKMARK [2][-]{subsection.5.2}{Probabilistic Latent Dirichlet Allocation}{section.5}% 14
\BOOKMARK [2][-]{subsection.5.3}{Bi-factor models under the Federated Learning settings}{section.5}% 15
\BOOKMARK [1][-]{section.6}{Conclusion}{}% 16
