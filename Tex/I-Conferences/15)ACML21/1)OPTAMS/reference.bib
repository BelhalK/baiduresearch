@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{chilimbi2014project,
  author    = {Trishul M. Chilimbi and
               Yutaka Suzue and
               Johnson Apacible and
               Karthik Kalyanaraman},
  title     = {Project Adam: Building an Efficient and Scalable Deep Learning Training
               System},
  booktitle = {Proceedings of the 11th {USENIX} Symposium on Operating Systems Design and Implementation (OSDI)},
  address = {Broomfield, CO},
  pages     = {571--582},
  year      = {2014},
}


@inproceedings{mcmahan2017communication,
  author    = {Brendan McMahan and
               Eider Moore and
               Daniel Ramage and
               Seth Hampson and
               Blaise Ag{\"{u}}era y Arcas},
  title     = {Communication-Efficient Learning of Deep Networks from Decentralized
               Data},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence
               and Statistics (AISTATS)},
  address = {Fort Lauderdale, FL},
  pages     = {1273--1282},
  year      = {2017},
}

@inproceedings{alistarh2017qsgd,
  author    = {Dan Alistarh and
               Demjan Grubic and
               Jerry Li and
               Ryota Tomioka and
               Milan Vojnovic},
  title     = {{QSGD:} Communication-Efficient {SGD} via Gradient Quantization and
               Encoding},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  address = {Long Beach, CA},
  pages     = {1709--1720},
  year      = {2017},
}

@inproceedings{lin2017deep,
  author    = {Yujun Lin and
               Song Han and
               Huizi Mao and
               Yu Wang and
               Bill Dally},
  title     = {Deep Gradient Compression: Reducing the Communication Bandwidth for
               Distributed Training},
  booktitle = {Proceedings of the 6th International Conference on Learning Representations (ICLR)},
  address = {Vancouver, Canada},
  year      = {2018},
}

@inproceedings{wangni2018gradient,
  author    = {Jianqiao Wangni and
               Jialei Wang and
               Ji Liu and
               Tong Zhang},
  title     = {Gradient Sparsification for Communication-Efficient Distributed Optimization},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  address = {Montr{\'{e}}al, Canada},
  pages     = {1306--1316},
  year      = {2018},
}
@inproceedings{stich2018sparsified,
  author    = {Sebastian U. Stich and
               Jean{-}Baptiste Cordonnier and
               Martin Jaggi},
  title     = {Sparsified {SGD} with Memory},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  address = {Montr{\'{e}}al, Canada},
  pages     = {4452--4463},
  year      = {2018},
}

@inproceedings{wang2018atomo,
  author    = {Hongyi Wang and
               Scott Sievert and
               Shengchao Liu and
               Zachary B. Charles and
               Dimitris S. Papailiopoulos and
               Stephen J. Wright},
  title     = {{ATOMO:} Communication-efficient Learning via Atomic Sparsification},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  address = {Montr{\'{e}}al, Canada},
  pages     = {9872--9883},
  year      = {2018},
}



@inproceedings{tang2019doublesqueeze,
  author    = {Hanlin Tang and
               Chen Yu and
               Xiangru Lian and
               Tong Zhang and
               Ji Liu},
  title     = {DoubleSqueeze: Parallel Stochastic Gradient Descent with Double-pass
               Error-Compensated Compression},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  address = {Long Beach, CA},
  pages     = {6155--6165},
  year      = {2019},
}

@inproceedings{lian2017can,
  author    = {Xiangru Lian and
               Ce Zhang and
               Huan Zhang and
               Cho{-}Jui Hsieh and
               Wei Zhang and
               Ji Liu},
  title     = {Can Decentralized Algorithms Outperform Centralized Algorithms? {A}
               Case Study for Decentralized Parallel Stochastic Gradient Descent},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  address = {Long Beach, CA},
  pages     = {5330--5340},
  year      = {2017},
}

@article{duchi2011dual,
  author    = {John C. Duchi and
               Alekh Agarwal and
               Martin J. Wainwright},
  title     = {Dual Averaging for Distributed Optimization: Convergence Analysis
               and Network Scaling},
  journal   = {{IEEE} Trans. Autom. Control.},
  volume    = {57},
  number    = {3},
  pages     = {592--606},
  year      = {2012},
}

@article{duchi2011adaptive,
  author    = {John C. Duchi and
               Elad Hazan and
               Yoram Singer},
  title     = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal   = {J. Mach. Learn. Res.},
  volume    = {12},
  pages     = {2121--2159},
  year      = {2011},
}

@article{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  journal={http://yann. lecun. com/exdb/mnist/},
  year={1998}
}



@inproceedings{kingma2014adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {Proceedings of the 3rd International Conference on Learning Representations (ICLR)},
  address = {San Diego, CA},
  year      = {2015},
}

@inproceedings{reddi2019convergence,
  author    = {Sashank J. Reddi and
               Satyen Kale and
               Sanjiv Kumar},
  title     = {On the Convergence of {Adam} and Beyond},
  booktitle = {Proceedings of the 6th International Conference on Learning Representations (ICLR)},
  address = {Vancouver, Canada},
  year      = {2018},
}

@article{nazari2019dadam,
  author    = {Parvin Nazari and
               Davoud Ataee Tarzanagh and
               George Michailidis},
  title     = {{DADAM:} {A} Consensus-based Distributed Adaptive Gradient Method
               for Online Optimization},
  journal   = {CoRR},
  volume    = {abs/1901.09109},
  year      = {2019},
  archivePrefix = {arXiv},
}

@article{yuan2016convergence,
  author    = {Kun Yuan and
               Qing Ling and
               Wotao Yin},
  title     = {On the Convergence of Decentralized Gradient Descent},
  journal   = {{SIAM} J. Optim.},
  volume    = {26},
  number    = {3},
  pages     = {1835--1854},
  year      = {2016},
}

@article{nedic2009distributed,
  author    = {Angelia Nedic and
               Asuman E. Ozdaglar},
  title     = {Distributed Subgradient Methods for Multi-Agent Optimization},
  journal   = {{IEEE} Trans. Autom. Control.},
  volume    = {54},
  number    = {1},
  pages     = {48--61},
  year      = {2009},
}

@inproceedings{reddi2020adaptive,
  author    = {Sashank J. Reddi and
               Zachary Charles and
               Manzil Zaheer and
               Zachary Garrett and
               Keith Rush and
               Jakub Kone{\v{c}}n{\'y} and
               Sanjiv Kumar and
               Hugh Brendan McMahan},
  title     = {Adaptive Federated Optimization},
  booktitle = {Proceedings of the 9th International Conference on Learning Representations (ICLR)},
  address = {Virtual Event, Austria},
  year      = {2021},
}

@inproceedings{aji2017sparse,
  author    = {Alham Fikri Aji and
               Kenneth Heafield},
  title     = {Sparse Communication for Distributed Gradient Descent},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural
               Language Processing (EMNLP)},
  address = {Copenhagen, Denmark},
  pages     = {440--445},
  year      = {2017},
}



@article{jegou2010product,
  author    = {Herv{\'{e}} J{\'{e}}gou and
               Matthijs Douze and
               Cordelia Schmid},
  title     = {Product Quantization for Nearest Neighbor Search},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {33},
  number    = {1},
  pages     = {117--128},
  year      = {2011},
}

@inproceedings{ge2013optimized,
  author    = {Tiezheng Ge and
               Kaiming He and
               Qifa Ke and
               Jian Sun},
  title     = {Optimized Product Quantization for Approximate Nearest Neighbor Search},
  booktitle = {Proceedings of the 2013 {IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
  address = {Portland, OR},
  pages     = {2946--2953},
  year      = {2013},
}

@inproceedings{luo2019adaptive,
  author    = {Liangchen Luo and
               Yuanhao Xiong and
               Yan Liu and
               Xu Sun},
  title     = {Adaptive Gradient Methods with Dynamic Bound of Learning Rate},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations (ICLR)},
  address = {New Orleans, LA},
  year      = {2019},
}

@article{chen2010approximate,
  author    = {Yongjian Chen and
               Tao Guan and
               Cheng Wang},
  title     = {Approximate Nearest Neighbor Search by Residual Vector Quantization},
  journal   = {Sensors},
  volume    = {10},
  number    = {12},
  pages     = {11259--11273},
  year      = {2010},
}

@inproceedings{chen2018convergence,
  author    = {Xiangyi Chen and
               Sijia Liu and
               Ruoyu Sun and
               Mingyi Hong},
  title     = {On the Convergence of {A} Class of Adam-Type Algorithms for Non-Convex
               Optimization},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations (ICLR)},
  address = {New Orleans, LA},
  year      = {2019},
}


@inproceedings{ward2019adagrad,
  author    = {Rachel Ward and
               Xiaoxia Wu and
               L{\'{e}}on Bottou},
  title     = {AdaGrad stepsizes: sharp convergence over nonconvex landscapes},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  address = {Long Beach, CA},
  pages     = {6677--6686},
  year      = {2019},
}

@inproceedings{yan2018unified,
  author    = {Yan Yan and
               Tianbao Yang and
               Zhe Li and
               Qihang Lin and
               Yi Yang},
  title     = {A Unified Analysis of Stochastic Momentum Methods for Deep Learning},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence (IJCAI)},
  address = {Stockholm, Sweden},
  pages     = {2955--2961},
  year      = {2018},
}



@inproceedings{li2019convergence,
  author    = {Xiaoyu Li and
               Francesco Orabona},
  title     = {On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes},
  booktitle = {Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)},
  address = {Naha, Japan},
  pages     = {983--992},
  year      = {2019},
}

@inproceedings{agarwal2019efficient,
  author    = {Naman Agarwal and
               Brian Bullins and
               Xinyi Chen and
               Elad Hazan and
               Karan Singh and
               Cyril Zhang and
               Yi Zhang},
  title     = {Efficient Full-Matrix Adaptive Regularization},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  address = {Long Beach, CA},
  pages     = {102--110},
  year      = {2019},
}


@inproceedings{zaheer2018adaptive,
  author    = {Manzil Zaheer and
               Sashank J. Reddi and
               Devendra Singh Sachan and
               Satyen Kale and
               Sanjiv Kumar},
  title     = {Adaptive Methods for Nonconvex Optimization},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  address = {Montr{\'{e}}al, Canada},
  pages     = {9815--9825},
  year      = {2018},
}

@article{boyd2011distributed,
  author    = {Stephen P. Boyd and
               Neal Parikh and
               Eric Chu and
               Borja Peleato and
               Jonathan Eckstein},
  title     = {Distributed Optimization and Statistical Learning via the Alternating
               Direction Method of Multipliers},
  journal   = {Found. Trends Mach. Learn.},
  volume    = {3},
  number    = {1},
  pages     = {1--122},
  year      = {2011},
}

@article{shi2015extra,
  author    = {Wei Shi and
               Qing Ling and
               Gang Wu and
               Wotao Yin},
  title     = {{EXTRA:} An Exact First-Order Algorithm for Decentralized Consensus
               Optimization},
  journal   = {{SIAM} J. Optim.},
  volume    = {25},
  number    = {2},
  pages     = {944--966},
  year      = {2015},
}

@article{di2016next,
  author    = {Paolo Di Lorenzo and
               Gesualdo Scutari},
  title     = {{NEXT:} In-Network Nonconvex Optimization},
  journal   = {{IEEE} Trans. Signal Inf. Process. over Networks},
  volume    = {2},
  number    = {2},
  pages     = {120--136},
  year      = {2016},
}

@inproceedings{hong2017prox,
  author    = {Mingyi Hong and
               Davood Hajinezhad and
               Ming{-}Min Zhao},
  title     = {Prox-PDA: The Proximal Primal-Dual Algorithm for Fast Distributed
               Nonconvex Optimization and Learning Over Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
  address = {Sydney, Australia},
  pages     = {1529--1538},
  year      = {2017},
}

@inproceedings{tang2018d,
  author    = {Hanlin Tang and
               Xiangru Lian and
               Ming Yan and
               Ce Zhang and
               Ji Liu},
  title     = {D\({}^{\mbox{2}}\): Decentralized Training over Decentralized Data},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning (ICML)},
  address = {Stockholmsm{\"{a}}ssan, Sweden},
  pages     = {4855--4863},
  year      = {2018},
}





@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The Annals of Mathematical Statistics},
  pages={400--407},
  year={1951},
}

@inproceedings{assran2019stochastic,
  author    = {Mahmoud Assran and
               Nicolas Loizou and
               Nicolas Ballas and
               Michael G. Rabbat},
  title     = {Stochastic Gradient Push for Distributed Deep Learning},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  address = {Long Beach, CA},
  pages     = {344--353},
  year      = {2019},
}

@inproceedings{lu2019gnsd,
  author    = {Songtao Lu and
               Xinwei Zhang and
               Haoran Sun and
               Mingyi Hong},
  title     = {{GNSD:} a Gradient-Tracking Based Nonconvex Stochastic Algorithm for
               Decentralized Optimization},
  booktitle = {Proceedings of the {IEEE} Data Science Workshop (DSW)},
  address = {Minneapolis, MN},
  pages     = {315--321},
  year      = {2019},
}

@inproceedings{koloskova2019decentralized,
  author    = {Anastasia Koloskova and
               Sebastian U. Stich and
               Martin Jaggi},
  title     = {Decentralized Stochastic Optimization and Gossip Algorithms with Compressed
               Communication},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  address = {Long Beach, CA},
  pages     = {3478--3487},
  year      = {2019},
}


@article{boyd2004fastest,
  author    = {Stephen P. Boyd and
               Persi Diaconis and
               Lin Xiao},
  title     = {Fastest Mixing Markov Chain on a Graph},
  journal   = {{SIAM} Rev.},
  volume    = {46},
  number    = {4},
  pages     = {667--689},
  year      = {2004},
}

@article{boyd2009fastest,
  author    = {Stephen P. Boyd and
               Persi Diaconis and
               Pablo A. Parrilo and
               Lin Xiao},
  title     = {Fastest Mixing Markov Chain on Graphs with Symmetries},
  journal   = {{SIAM} J. Optim.},
  volume    = {20},
  number    = {2},
  pages     = {792--819},
  year      = {2009},
}


@inproceedings{chen2020toward,
  author    = {Xiangyi Chen and
               Xiaoyun Li and
               Ping Li},
  title     = {Toward Communication Efficient Adaptive Gradient Method},
  booktitle = {Proceedings of the {ACM-IMS} Foundations of Data Science Conference (FODS)},
  address = {Virtual Event, USA},
  pages     = {119--128},
  year      = {2020},
}

@inproceedings{Proc:Zhao_MLSys20,
  author    = {Weijie Zhao and
               Deping Xie and
               Ronglai Jia and
               Yulei Qian and
               Ruiquan Ding and
               Mingming Sun and
               Ping Li},
  title     = {Distributed Hierarchical {GPU} Parameter Server for Massive Scale
               Deep Learning Ads Systems},
  booktitle = {Proceedings of Machine Learning and Systems 2020 (MLSys)},
  address   = {Austin,
               TX},
  year      = {2020}
}


@inproceedings{Proc:Xu_SIGMOD21,
  author    = {Zhiqiang Xu and
               Dong Li and
               Weijie Zhao and
               Xing Shen and
               Tianbo Huang and
               Xiaoyun Li and
               Ping Li},
  title     = {Agile and Accurate {CTR} Prediction Model Training for Massive-Scale
               Online Advertising Systems},
  booktitle = {Proceedings of the International Conference on Management of Data (SIGMOD)}, address   = {Virtual
               Event, China},
  pages     = {2404--2409},
  year      = {2021}
}



@inproceedings{mcmahan2017communication,
  author    = {Brendan McMahan and
               Eider Moore and
               Daniel Ramage and
               Seth Hampson and
               Blaise Ag{\"{u}}era y Arcas},
  title     = {Communication-Efficient Learning of Deep Networks from Decentralized
               Data},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence
               and Statistics (AISTATS)},
  address   = {Fort Lauderdale,
               FL},
  pages     = {1273--1282},
  year      = {2017}
}

@article{konevcny2016federated,
  title={Federated learning: Strategies for improving communication efficiency},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Yu, Felix X and Richt{\'a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}

@inproceedings{lin2017deep,
  author    = {Yujun Lin and
               Song Han and
               Huizi Mao and
               Yu Wang and
               Bill Dally},
  title     = {Deep Gradient Compression: Reducing the Communication Bandwidth for
               Distributed Training},
  booktitle = {Proceedings of the 6th International Conference on Learning Representations (ICLR)},
  address   = {
               Vancouver, Canada},
  year      = {2018}
}

@article{chen2021convergent,
  title={On the Convergence of Decentralized Adaptive Gradient Methods},
  author={Chen, Xiangyi and Karimi, Belhal and Zhao, Weijie and Li, Ping},
   journal={arXiv preprint arXiv:2109.03194},
  year={2021}
}

@article{karimi2021fed,
  title={Fed-LAMB: Layerwise and Dimensionwise Locally Adaptive Optimization Algorithm },
  author={Karimi, Belhal and Li, Xiaoyun and Li, Ping},
   journal={arXiv preprint arXiv:2110.00532},
  year={2021}
}


@inproceedings{alistarh2017qsgd,
  author    = {Dan Alistarh and
               Demjan Grubic and
               Jerry Li and
               Ryota Tomioka and
               Milan Vojnovic},
  title     = {{QSGD:} Communication-Efficient {SGD} via Gradient Quantization and
               Encoding},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  address   = {
               Long Beach, CA},
  pages     = {1709--1720},
  year      = {2017}
}

@inproceedings{wangni2018gradient,
  author    = {Jianqiao Wangni and
               Jialei Wang and
               Ji Liu and
               Tong Zhang},
  title     = {Gradient Sparsification for Communication-Efficient Distributed Optimization},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  address   = {Montr{\'{e}}al, Canada},
  pages     = {1306--1316},
  year      = {2018}
}


@inproceedings{you2019large,
  author    = {Yang You and
               Jing Li and
               Sashank J. Reddi and
               Jonathan Hseu and
               Sanjiv Kumar and
               Srinadh Bhojanapalli and
               Xiaodan Song and
               James Demmel and
               Kurt Keutzer and
               Cho{-}Jui Hsieh},
  title     = {Large Batch Optimization for Deep Learning: Training {BERT} in 76
               minutes},
  booktitle = {Proceedings of the 8th International Conference on Learning Representations (ICLR)},
  address   = {Addis Ababa, Ethiopia},
  year      = {2020}
}



@ARTICLE{RKK18,
  title={On the Convergence of Adam and Beyond },
  author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
  journal={ICLR},
  year={2018}
}

@inproceedings{KB15,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {Proceedings of the 3rd International Conference on Learning Representations (ICLR)},
  address   = {
               San Diego, CA},
  year      = {2015}
}
@ARTICLE{TH12,
  title = {RmsProp: Divide the gradient by a running average of its recent magnitude},
  author    = {T. Tieleman and G. Hinton},
  journal = {COURSERA: Neural Networks for Machine Learning},
  year = {2012}
}


@ARTICLE{Z12,
  title={Adadelta: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}


@ARTICLE{DHS11,
  author    = {John C. Duchi and
               Elad Hazan and
               Yoram Singer},
  title     = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal   = {J. Mach. Learn. Res.},
  volume    = {12},
  pages     = {2121--2159},
  year      = {2011}
}


@ARTICLE{N04,
    title = {Introductory Lectures on Convex Optimization:
A Basic Course},
    Author = {Yurii Nesterov},
    journal = {Springer},
    year = {2004},
}


@ARTICLE{P64,
  title = {Some methods of speeding up the convergence of iteration methods},
  author    = {B. T. Polyak},
  journal = {Mathematics and Mathematical Physics},
  year = {1964}
}



@inproceedings{li2014scaling,
  author    = {Mu Li and
               David G. Andersen and
               Jun Woo Park and
               Alexander J. Smola and
               Amr Ahmed and
               Vanja Josifovski and
               James Long and
               Eugene J. Shekita and
               Bor{-}Yiing Su},
  title     = {Scaling Distributed Machine Learning with the Parameter Server},
  booktitle = {Proceedings of the 11th {USENIX} Symposium on Operating Systems Design and Implementation (OSDI)},
  address   = {Broomfield, CO},
  pages     = {583--598},
  year      = {2014}
}

@inproceedings{zhao2020distributed,
  author    = {Weijie Zhao and
               Deping Xie and
               Ronglai Jia and
               Yulei Qian and
               Ruiquan Ding and
               Mingming Sun and
               Ping Li},
  title     = {Distributed Hierarchical {GPU} Parameter Server for Massive Scale
               Deep Learning Ads Systems},
  booktitle = {Proceedings of Machine Learning and Systems (MLSys)},
  address   = {Austin, TX},
  year      = {2020}
}

@article{recht2011hogwild,
  title={Hogwild!: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  journal={Advances in neural information processing systems},
  volume={24},
  pages={693--701},
  year={2011}
}



@inproceedings{zhou2017convergence,
  author    = {Fan Zhou and
               Guojing Cong},
  title     = {On the Convergence Properties of a K-step Averaging Stochastic Gradient
               Descent Algorithm for Nonconvex Optimization},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence (IJCAI)},
  address   = {Stockholm,
               Sweden},
  pages     = {3219--3227},
  year      = {2018}
}

@inproceedings{stich2018local,
  author    = {Sebastian U. Stich},
  title     = {Local {SGD} Converges Fast and Communicates Little},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations (ICLR)},
  address   = {
               New Orleans, LA},
  year      = {2019}
}

@inproceedings{yu2019linear,
  author    = {Hao Yu and
               Rong Jin and
               Sen Yang},
  title     = {On the Linear Speedup Analysis of Communication Efficient Momentum
               {SGD} for Distributed Non-Convex Optimization},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  address   = {Long Beach, CA},
  pages     = {7184--7193},
  year      = {2019}
}
@inproceedings{he2016deep,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {Proceedings of the 2016 {IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
  address   = {Las Vegas, NV},
  pages     = {770--778},
  year      = {2016}
}

@article{ghadimi2013stochastic,
  author    = {Saeed Ghadimi and
               Guanghui Lan},
  title     = {Stochastic First- and Zeroth-Order Methods for Nonconvex Stochastic
               Programming},
  journal   = {{SIAM} J. Optim.},
  volume    = {23},
  number    = {4},
  pages     = {2341--2368},
  year      = {2013}
}
	
@article{karimireddy2019scaffold,
  title={SCAFFOLD: Stochastic Controlled Averaging for On-Device Federated Learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank J and Stich, Sebastian U and Suresh, Ananda Theertha},
  journal={arXiv preprint arXiv:1910.06378},
  year={2019}
}

@inproceedings{reddi2020adaptive,
  author    = {Sashank J. Reddi and
               Zachary Charles and
               Manzil Zaheer and
               Zachary Garrett and
               Keith Rush and
               Jakub Kone{\v{c}}n{\'y} and
               Sanjiv Kumar and
               Hugh Brendan McMahan},
  title     = {Adaptive Federated Optimization},
  booktitle = {Proceedings of the 9th International Conference on Learning Representations (ICLR)},
  address   = {
               Virtual Event, Austria},
  year      = {2021}
}

@article{horvath2019stochastic,
  title={Stochastic distributed learning with gradient quantization and variance reduction},
  author={Horv{\'a}th, Samuel and Kovalev, Dmitry and Mishchenko, Konstantin and Stich, Sebastian and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1904.05115},
  year={2019}
}

@article{li2019federated,
  author    = {Tian Li and
               Anit Kumar Sahu and
               Ameet Talwalkar and
               Virginia Smith},
  title     = {Federated Learning: Challenges, Methods, and Future Directions},
  journal   = {{IEEE} Signal Process. Mag.},
  volume    = {37},
  number    = {3},
  pages     = {50--60},
  year      = {2020}
}


@article{liang2019variance,
  title={Variance Reduced Local SGD with Lower Communication Complexity},
  author={Liang, Xianfeng and Shen, Shuheng and Liu, Jingchang and Pan, Zhen and Chen, Enhong and Cheng, Yifei},
  journal={arXiv preprint arXiv:1912.12844},
  year={2019}
}

@inproceedings{haddadpour2020federated,
  author    = {Farzin Haddadpour and
               Mohammad Mahdi Kamani and
               Aryan Mokhtari and
               Mehrdad Mahdavi},
  title     = {Federated Learning with Compression: Unified Analysis and Sharp Guarantees},
  booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  address   = {Virtual Event},
  pages     = {2350--2358},
  year      = {2021}
}
@article{haddadpour2020fedsketch,
  title={Fedsketch: Communication-efficient and private federated learning via sketching},
  author={Haddadpour, Farzin and Karimi, Belhal and Li, Ping and Li, Xiaoyun},
  journal={arXiv preprint arXiv:2008.04975},
  year={2020}
}

@inproceedings{ivkin2019communication,
  author    = {Nikita Ivkin and
               Daniel Rothchild and
               Enayat Ullah and
               Vladimir Braverman and
               Ion Stoica and
               Raman Arora},
  title     = {Communication-efficient Distributed {SGD} with Sketching},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  address   = {Vancouver,  Canada},
  pages     = {13144--13154},
  year      = {2019}
}

@article{li2019privacy,
  title={Privacy for Free: Communication-Efficient Learning with Differential Privacy Using Sketches},
  author={Li, Tian and Liu, Zaoxing and Sekar, Vyas and Smith, Virginia},
  journal={arXiv preprint arXiv:1911.00972},
  year={2019}
}

@article{lecun1998mnist,
	Author = {LeCun, Yann},
	Journal = {http://yann. lecun. com/exdb/mnist/},
	Title = {The MNIST database of handwritten digits},
	Year = {1998}}
	
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex},
  journal={Master's thesis, Department of Computer Science, University of Toronto},
  year={2009}
}

@inproceedings{mcmahan2010adaptive,
  author    = {H. Brendan McMahan and
               Matthew J. Streeter},
  title     = {Adaptive Bound Optimization for Online Convex Optimization},
  booktitle = {Proceedings of the 23rd Conference on Learning Theory (COLT)}, 
  address   = {Haifa, Israel},
  pages     = {244--256},
  year      = {2010}
}

@article{wang2019optimistic,
  title={An optimistic acceleration of amsgrad for nonconvex optimization},
  author={Wang, Jun-Kun and Li, Xiaoyun and Karimi, Belhal and Li, Ping},
  journal={arXiv preprint arXiv:1903.01435},
  year={2019}
}

@inproceedings{zhou2020towards,
  author    = {Yingxue Zhou and
               Belhal Karimi and
               Jinxing Yu and
               Zhiqiang Xu and
               Ping Li},
  title     = {Towards Better Generalization of Adaptive Gradient Methods},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  address  = {virtual},
  year      = {2020}
}

@article{polyak1964some,
  title={Some methods of speeding up the convergence of iteration methods},
  author={Polyak, Boris T},
  journal={Ussr computational mathematics and mathematical physics},
  volume={4},
  number={5},
  pages={1--17},
  year={1964},
  publisher={Elsevier}
}

@book{nesterov2003introductory,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  volume={87},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@inproceedings{dozat2016incorporating,
  title={Incorporating Nesterov Momentum into Adam},
  author={Timothy Dozat},
  year={2016}
}

@article{tieleman2012rmsprop,
  title={Rmsprop: Divide the gradient by a running average of its recent magnitude. coursera: Neural networks for machine learning},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA Neural Networks Mach. Learn},
  year={2012}
}

@article{zeiler2012adadelta,
  title={Adadelta: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}


@article{levine2016end,
  author    = {Sergey Levine and
               Chelsea Finn and
               Trevor Darrell and
               Pieter Abbeel},
  title     = {End-to-End Training of Deep Visuomotor Policies},
  journal   = {J. Mach. Learn. Res.},
  volume    = {17},
  pages     = {39:1--39:40},
  year      = {2016}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}


@inproceedings{goodfellow2014generative,
  author    = {Ian J. Goodfellow and
               Jean Pouget{-}Abadie and
               Mehdi Mirza and
               Bing Xu and
               David Warde{-}Farley and
               Sherjil Ozair and
               Aaron C. Courville and
               Yoshua Bengio},
  title     = {Generative Adversarial Nets},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  address   = {
               Montreal,  Canada},
  pages     = {2672--2680},
  year      = {2014}
}

@inproceedings{GMH13,
  author    = {Alex Graves and
               Abdel{-}rahman Mohamed and
               Geoffrey E. Hinton},
  title     = {Speech recognition with deep recurrent neural networks},
  booktitle = {Proceedings of the {IEEE} International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  address  = {Vancouver, Canada},
  pages     = {6645--6649},
  year      = {2013}
}

@article{MS10,
title={Adaptive bound optimization for online convex optimization},
  author={McMahan, H Brendan and Streeter, Matthew},
  journal={arXiv preprint arXiv:1002.4908},
  year={2010}
}


@inproceedings{CJ12,
  author    = {Chao{-}Kai Chiang and
               Tianbao Yang and
               Chia{-}Jung Lee and
               Mehrdad Mahdavi and
               Chi{-}Jen Lu and
               Rong Jin and
               Shenghuo Zhu},
  title     = {Online Optimization with Gradual Variations},
  booktitle = {Proceedings of the 25th Annual Conference on Learning Theory (COLT)}, 
  address   = {Edinburgh, Scotland, UK},
  pages     = {6.1--6.20},
  year      = {2012}
}


@inproceedings{RS13b,
  author    = {Alexander Rakhlin and
               Karthik Sridharan},
  title     = {Optimization, Learning, and Games with Predictable Sequences},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  address   = {Lake Tahoe, NV},
  pages     = {3066--3074},
  year      = {2013}
}
@inproceedings{SALS15,
  author    = {Vasilis Syrgkanis and
               Alekh Agarwal and
               Haipeng Luo and
               Robert E. Schapire},
  title     = {Fast Convergence of Regularized Learning in Games},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  address   = {
               Montreal, Canada},
  pages     = {2989--2997},
  year      = {2015}
}

@inproceedings{ALLW18,
  title={Faster rates for convex-concave games},
  author={Abernethy, Jacob and Lai, Kevin A and Levy, Kfir Y and Wang, Jun-Kun},
  booktitle={Conference On Learning Theory},
  pages={1595--1625},
  year={2018},
  organization={PMLR}
}

@inproceedings{mertikopoulos2018optimistic,
  author    = {Panayotis Mertikopoulos and
               Bruno Lecouat and
               Houssam Zenati and
               Chuan{-}Sheng Foo and
               Vijay Chandrasekhar and
               Georgios Piliouras},
  title     = {Optimistic mirror descent in saddle-point problems: Going the extra
               (gradient) mile},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations (ICLR)},
  address   = {
               New Orleans, LA},
  year      = {2019}
}


@article{defossez2020convergence,
  title={On the convergence of adam and adagrad},
  author={D{\'e}fossez, Alexandre and Bottou, L{\'e}on and Bach, Francis and Usunier, Nicolas},
  journal={arXiv e-prints},
  pages={arXiv--2003},
  year={2020}
}



@article{zhou2018convergence,
  title={On the convergence of adaptive gradient methods for nonconvex optimization},
  author={Zhou, Dongruo and Chen, Jinghui and Cao, Yuan and Tang, Yiqi and Yang, Ziyan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1808.05671},
  year={2018}
}

@article{zou2018convergence,
  title={On the convergence of adagrad with momentum for training deep neural networks},
  author={Zou, Fangyu and Shen, Li},
  journal={arXiv preprint arXiv:1808.03408},
  volume={2},
  number={3},
  pages={5},
  year={2018}
}

@inproceedings{daskalakis2018training,
  author    = {Constantinos Daskalakis and
               Andrew Ilyas and
               Vasilis Syrgkanis and
               Haoyang Zeng},
  title     = {Training GANs with Optimism},
  booktitle = {Proceedings of the 6th International Conference on Learning Representations (ICLR)},
  address   = {
               Vancouver, Canada},
  year      = {2018}
}

@article{hazan2019introduction,
  title={Introduction to online convex optimization},
  author={Hazan, Elad},
  journal={arXiv preprint arXiv:1909.05207},
  year={2019}
}



@inproceedings{mohri2015accelerating,
  author    = {Mehryar Mohri and
               Scott Yang},
  title     = {Accelerating Online Convex Optimization via Adaptive Prediction},
  booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence
               and Statistics (AISTATS)},
  address   = {Cadiz, Spain},
  pages     = {848--856},
  year      = {2016}
}
@article{walker2011anderson,
  author    = {Homer F. Walker and
               Peng Ni},
  title     = {Anderson Acceleration for Fixed-Point Iterations},
  journal   = {{SIAM} J. Numer. Anal.},
  volume    = {49},
  number    = {4},
  pages     = {1715--1735},
  year      = {2011}
}

@article{scieur2020regularized,
  author    = {Damien Scieur and
               Alexandre d'Aspremont and
               Francis R. Bach},
  title     = {Regularized nonlinear acceleration},
  journal   = {Math. Program.},
  volume    = {179},
  number    = {1},
  pages     = {47--83},
  year      = {2020}
}

@incollection{eddy1979extrapolating,
  title={Extrapolating to the limit of a vector sequence},
  author={Eddy, RP},
  booktitle={Information linkage between applied mathematics and industry},
  pages={387--396},
  year={1979},
  publisher={Elsevier}
}

@book{brezinski2013extrapolation,
  title={Extrapolation methods: theory and practice},
  author={Brezinski, Claude and Zaglia,  Redivo},
  year={2013},
  publisher={Elsevier}
}


@article{Scieur18,
  author    = {Damien Scieur and
               Edouard Oyallon and
               Alexandre dAspremont and
               Francis Bach},
  title     = {Nonlinear Acceleration of Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1805.09639},
  year      = {2018}
}

@inproceedings{larochelle2007empirical,
  title={An empirical evaluation of deep architectures on problems with many factors of variation},
  author={Larochelle, Hugo and Erhan, Dumitru and Courville, Aaron and Bergstra, James and Bengio, Yoshua},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={473--480},
  year={2007}
}

@article{gers1999learning,
  author    = {Felix A. Gers and
               J{\"{u}}rgen Schmidhuber and
               Fred A. Cummins},
  title     = {Learning to Forget: Continual Prediction with {LSTM}},
  journal   = {Neural Comput.},
  volume    = {12},
  number    = {10},
  pages     = {2451--2471},
  year      = {2000}
}


@article{tseng2008accelerated,
  title={On accelerated proximal gradient methods for convex-concave optimization},
  author={Tseng, Paul},
  journal={submitted to SIAM Journal on Optimization},
  volume={2},
  number={3},
  year={2008}
}

@inproceedings{chen2019universal,
  author    = {Zaiyi Chen and
               Zhuoning Yuan and
               Jinfeng Yi and
               Bowen Zhou and
               Enhong Chen and
               Tianbao Yang},
  title     = {Universal Stagewise Learning for Non-Convex Problems with Convergence
               on Averaged Solutions},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations (ICLR)},
  address  = {New Orleans, LA},
  year      = {2019}
}

@article{cabay1976polynomial,
  title={A polynomial extrapolation method for finding limits and antilimits of vector sequences},
  author={Cabay, Stan and Jackson, LW},
  journal={SIAM Journal on Numerical Analysis},
  volume={13},
  number={5},
  pages={734--752},
  year={1976},
  publisher={SIAM}
}

@inproceedings{Proc:ABC_UAI10,
  author    = {Ping Li},
  title     = {Robust LogitBoost and Adaptive Base Class (ABC) LogitBoost},
  booktitle = {Proceedings of the Twenty-Sixth Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI)},
  year      = {2010},
  address   = {Catalina Island, CA},
  PAGES = {302--311}
}


@inproceedings{Proc:Larochelle_ICML07,
  author    = {Hugo Larochelle and
               Dumitru Erhan and
               Aaron C. Courville and
               James Bergstra and
               Yoshua Bengio},
  title     = {An empirical evaluation of deep architectures on problems
               with many factors of variation},
  booktitle = {Proceedings of the Twenty-Fourth International Conference on Machine Learning (ICML)},
  year      = {2007},
  pages     = {473-480},
  address   = {Corvalis, Oregon}
}

@article{arXiv:Li_2018several,
  title={Several Tunable {GMM} Kernels},
  author={Li, Ping},
  journal={arXiv preprint arXiv:1805.02830},
  year={2018}
}
