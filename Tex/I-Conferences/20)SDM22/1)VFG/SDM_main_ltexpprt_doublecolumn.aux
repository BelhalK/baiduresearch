\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{sanner2012symbolic,kahle2008junction}
\citation{jordan1999introduction,hoffman2013stochastic}
\citation{xing2012generalized}
\citation{bishop2003vibes,winn2005variational}
\citation{jaeger2006learning}
\citation{darwiche2003differential}
\citation{marinescu2005and}
\citation{dechter2007and}
\citation{rahman2014cutset}
\citation{sanchez2021sum}
\citation{kisa2014probabilistic}
\citation{choi2020probabilistic}
\citation{kingma2013auto}
\citation{Goodfellow14}
\citation{Dinh2016DensityEU,dinh2014nice,rezende2015variational,berg2018sylvester}
\citation{sanchez2021sum}
\citation{choi2020probabilistic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{kingma2013auto,rezende2014stochastic}
\citation{Dinh2016DensityEU,dinh2014nice,rezende2015variational,berg2018sylvester}
\citation{rezende2015variational}
\citation{wehenkel2021graphical}
\citation{khemakhem2021causal}
\citation{Dinh2016DensityEU,dinh2014nice,rezende2015variational,berg2018sylvester}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{2}{section.2}}
\newlabel{sec:prelim}{{2}{2}{Preliminaries}{section.2}{}}
\newlabel{eq:vi_elbo}{{2.1}{2}{Preliminaries}{equation.2.1}{}}
\newlabel{eq:vae_recon}{{2.2}{2}{Preliminaries}{equation.2.2}{}}
\newlabel{eq:flow}{{2.3}{2}{Preliminaries}{equation.2.3}{}}
\newlabel{eq:flow2}{{2.4}{2}{Preliminaries}{equation.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Variational Flow Graphical Model}{2}{section.3}}
\newlabel{sec:main}{{3}{2}{Variational Flow Graphical Model}{section.3}{}}
\citation{kingma2013auto,rezende2014stochastic}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (Left) Node $\mathbf  {h}^{2, 1}$ connects its children with invertible functions. Messages from the children are aggregated at the parent node, $\mathbf  {h}^{2,1}$; $\oplus $ is an aggregation node, and circles stand for non-aggregation\nobreakspace  {}nodes.(Right) An illustration of the latent structure from layer $l-1$ to $l+1$. Thin lines are identity functions, and thick lines are flow functions. \relax }}{3}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:tree}{{1}{3}{\small (Left) Node $\mathbf {h}^{2, 1}$ connects its children with invertible functions. Messages from the children are aggregated at the parent node, $\mathbf {h}^{2,1}$; $\oplus $ is an aggregation node, and circles stand for non-aggregation~nodes.(Right) An illustration of the latent structure from layer $l-1$ to $l+1$. Thin lines are identity functions, and thick lines are flow functions. \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Evidence Lower Bound of Variational Flow Graphical Models}{3}{figure.caption.2}}
\newlabel{eq:posterior}{{3.5}{3}{Evidence Lower Bound of Variational Flow Graphical Models}{equation.3.5}{}}
\newlabel{eq:elbo}{{3.6}{3}{Evidence Lower Bound of Variational Flow Graphical Models}{equation.3.6}{}}
\newlabel{eq:kl}{{3.7}{3}{Evidence Lower Bound of Variational Flow Graphical Models}{equation.3.7}{}}
\newlabel{eq:elbo_dag}{{3.8}{3}{Evidence Lower Bound of Variational Flow Graphical Models}{equation.3.8}{}}
\citation{kingma2013auto,rezende2014stochastic}
\citation{kingma2013auto,rezende2014stochastic}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Recognition model consists of froward message from data to approximate the posterior distributions; the generative model is realized by backward message from the root node and generates the samples or reconstructions in each layer.\relax }}{4}{figure.caption.3}}
\newlabel{fig:tree_message}{{2}{4}{Recognition model consists of froward message from data to approximate the posterior distributions; the generative model is realized by backward message from the root node and generates the samples or reconstructions in each layer.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}ELBO Calculation}{4}{subsection.3.2}}
\newlabel{eq:post_smp}{{3.9}{4}{ELBO Calculation}{equation.3.9}{}}
\newlabel{eq:prior_smp}{{3.10}{4}{ELBO Calculation}{equation.3.10}{}}
\newlabel{eq:KL_l}{{3.11}{4}{ELBO Calculation}{equation.3.11}{}}
\newlabel{sec:node_aggr}{{3.3}{4}{Aggregation Nodes}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3} Aggregation Nodes}{4}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (Left) Aggregation node $\mathbf  {h}^{l+1,1}$ has three children, $\mathbf  {h}^{l,1}$, $\mathbf  {h}^{l,2}$, and $\mathbf  {h}^{l,3}$. (Right) A VFG model with one aggregation node, $\mathbf  {h}^{(r)}$. Solid circles are nodes with observed values, and the diamond is the prior for the root node.\relax }}{4}{figure.caption.4}}
\newlabel{fig:node_aggre}{{3}{4}{(Left) Aggregation node $\mathbf {h}^{l+1,1}$ has three children, $\mathbf {h}^{l,1}$, $\mathbf {h}^{l,2}$, and $\mathbf {h}^{l,3}$. (Right) A VFG model with one aggregation node, $\mathbf {h}^{(r)}$. Solid circles are nodes with observed values, and the diamond is the prior for the root node.\relax }{figure.caption.4}{}}
\newlabel{eq:one_agg_node}{{3.12}{5}{Aggregation Nodes}{equation.3.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Algorithms and Implementation}{5}{section.4}}
\newlabel{sec:algrithm}{{4}{5}{Algorithms and Implementation}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Layer-wise Training}{5}{subsection.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Inference model parameters with forward and backward message propagation\relax }}{5}{algorithm.1}}
\newlabel{alg:main}{{1}{5}{Inference model parameters with forward and backward message propagation\relax }{algorithm.1}{}}
\newlabel{line:for2}{{4}{5}{Inference model parameters with forward and backward message propagation\relax }{ALC@unique.4}{}}
\newlabel{line:forward}{{6}{5}{Inference model parameters with forward and backward message propagation\relax }{ALC@unique.6}{}}
\newlabel{line:backward}{{11}{5}{Inference model parameters with forward and backward message propagation\relax }{ALC@unique.11}{}}
\newlabel{line:update}{{15}{5}{Inference model parameters with forward and backward message propagation\relax }{ALC@unique.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Inference on VFG Models }{5}{section.5}}
\newlabel{sec:infer}{{5}{5}{Inference on VFG Models}{section.5}{}}
\newlabel{eq:aggr_obs_ch}{{5.15}{5}{Inference on VFG Models}{equation.5.15}{}}
\newlabel{lm:apprx}{{5.1}{5}{Inference on VFG Models}{lemma.5.1}{}}
\citation{bengio2013representation}
\citation{Zheng2018,wehenkel2021graphical}
\citation{kingma2013auto}
\citation{rezende2015variational}
\citation{kingma2016improving}
\citation{berg2018sylvester}
\citation{Dinh2016DensityEU}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces {\relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (Left) Inference on model with single aggregation node. Node 7 aggregates information from node 1 and 2, and pass down the updated state to node 3 for prediction. (Right) Inference on a tree model. Observed node states are gathered at node 7 to predict the state of node 4. Red and green lines are forward and backward messages, respectively.}\relax }}{6}{figure.caption.5}}
\newlabel{fig:two_layer_infer}{{4}{6}{{\small (Left) Inference on model with single aggregation node. Node 7 aggregates information from node 1 and 2, and pass down the updated state to node 3 for prediction. (Right) Inference on a tree model. Observed node states are gathered at node 7 to predict the state of node 4. Red and green lines are forward and backward messages, respectively.}\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Numerical Experiments}{6}{section.6}}
\newlabel{sec:numerical}{{6}{6}{Numerical Experiments}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Evaluation on Inference with Missing Entries Imputation}{6}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Synthetic datasets: MSE boxplots of VFG and baseline methods.\relax }}{6}{figure.caption.6}}
\newlabel{fig:sim}{{5}{6}{Synthetic datasets: MSE boxplots of VFG and baseline methods.\relax }{figure.caption.6}{}}
\citation{berg2018sylvester}
\citation{rezende2015variational}
\citation{berg2018sylvester}
\citation{Dinh2016DensityEU}
\citation{berg2018sylvester}
\citation{Lecunmnist2010}
\citation{Sorrenson2020}
\citation{maaten2008visualizing}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Negative log-likelihood and free energy (negative evidence lower bound) for static MNIST, Caltech101, and Omniglot.\vspace  {-0.05in}\relax }}{7}{table.caption.7}}
\newlabel{tab:elbo}{{1}{7}{Negative log-likelihood and free energy (negative evidence lower bound) for static MNIST, Caltech101, and Omniglot.\vspace {-0.05in}\relax }{table.caption.7}{}}
\newlabel{sec:exp:elbo}{{6.2}{7}{ELBO and Likelihood}{subsection.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}ELBO and Likelihood}{7}{subsection.6.2}}
\newlabel{eq:elbo_b}{{6.16}{7}{ELBO and Likelihood}{equation.6.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces (Left) Tree structure for MNIST; (Right) MNIST: t-SNE plot of latent variables from VFG learned with labels.\relax }}{7}{figure.caption.8}}
\newlabel{fig:z_tsne}{{6}{7}{(Left) Tree structure for MNIST; (Right) MNIST: t-SNE plot of latent variables from VFG learned with labels.\relax }{figure.caption.8}{}}
\newlabel{sec:exp:mnist}{{6.3}{7}{Latent Representation Learning on MNIST}{subsection.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Latent Representation Learning on MNIST}{7}{subsection.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces (Top) original MNIST digits. (Bottom) reconstructed images using VFG.\relax }}{7}{figure.caption.9}}
\newlabel{fig:reconst}{{7}{7}{(Top) original MNIST digits. (Bottom) reconstructed images using VFG.\relax }{figure.caption.9}{}}
\citation{Zheng2018,wehenkel2021graphical}
\citation{teshima2020coupling}
\bibdata{ref}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces MNIST: Increasing each latent variable from a small value to a larger one.\relax }}{8}{figure.caption.10}}
\newlabel{fig:mnist_dis}{{8}{8}{MNIST: Increasing each latent variable from a small value to a larger one.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{8}{section.7}}
\newlabel{sec:discuss}{{7}{8}{Discussion}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Benefits of Encoder-decoder Parameter Sharing}{8}{subsection.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Structures of VFGs}{8}{subsection.7.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{8}{section.8}}
\newlabel{sec:conclusion}{{8}{8}{Conclusion}{section.8}{}}
\bibcite{bengio2013representation}{{1}{}{{}}{{}}}
\bibcite{berg2018sylvester}{{2}{}{{}}{{}}}
\bibcite{bilmes2005graphical}{{3}{}{{}}{{}}}
\bibcite{bishop2003vibes}{{4}{}{{}}{{}}}
\bibcite{choi2020probabilistic}{{5}{}{{}}{{}}}
\bibcite{darwiche2003differential}{{6}{}{{}}{{}}}
\bibcite{de2020block}{{7}{}{{}}{{}}}
\bibcite{dechter2007and}{{8}{}{{}}{{}}}
\bibcite{dinh2014nice}{{9}{}{{}}{{}}}
\bibcite{Dinh2016DensityEU}{{10}{}{{}}{{}}}
\bibcite{Goodfellow14}{{11}{}{{}}{{}}}
\bibcite{ho2019flow++}{{12}{}{{}}{{}}}
\bibcite{hoffman2013stochastic}{{13}{}{{}}{{}}}
\bibcite{hruschka2007bayesian}{{14}{}{{}}{{}}}
\bibcite{jaeger2006learning}{{15}{}{{}}{{}}}
\bibcite{jordan1999graphical}{{16}{}{{}}{{}}}
\bibcite{jordan1999introduction}{{17}{}{{}}{{}}}
\bibcite{kahle2008junction}{{18}{}{{}}{{}}}
\bibcite{khemakhem2021causal}{{19}{}{{}}{{}}}
\bibcite{kingma2016improving}{{20}{}{{}}{{}}}
\bibcite{kingma2013auto}{{21}{}{{}}{{}}}
\bibcite{kisa2014probabilistic}{{22}{}{{}}{{}}}
\bibcite{Lecunmnist2010}{{23}{}{{}}{{}}}
\bibcite{liu2016stein}{{24}{}{{}}{{}}}
\bibcite{maaten2008visualizing}{{25}{}{{}}{{}}}
\bibcite{madigan1995bayesian}{{26}{}{{}}{{}}}
\bibcite{marinescu2005and}{{27}{}{{}}{{}}}
\bibcite{papamakarios2019normalizing}{{28}{}{{}}{{}}}
\bibcite{poon2011sum}{{29}{}{{}}{{}}}
\bibcite{rahman2014cutset}{{30}{}{{}}{{}}}
\bibcite{rezende2015variational}{{31}{}{{}}{{}}}
\bibcite{rezende2014stochastic}{{32}{}{{}}{{}}}
\bibcite{rippel2013high}{{33}{}{{}}{{}}}
\bibcite{sanchez2021sum}{{34}{}{{}}{{}}}
\bibcite{sanner2012symbolic}{{35}{}{{}}{{}}}
\bibcite{shwe1990probabilistic}{{36}{}{{}}{{}}}
\bibcite{Sorrenson2020}{{37}{}{{}}{{}}}
\bibcite{tabak2010density}{{38}{}{{}}{{}}}
\bibcite{teshima2020coupling}{{39}{}{{}}{{}}}
\bibcite{wehenkel2021graphical}{{40}{}{{}}{{}}}
\bibcite{winn2005variational}{{41}{}{{}}{{}}}
\bibcite{xing2012generalized}{{42}{}{{}}{{}}}
\bibcite{Zheng2018}{{43}{}{{}}{{}}}
\bibstyle{plain}
\citation{Dinh2016DensityEU}
\@writefile{toc}{\contentsline {section}{\numberline {A}Additional Results}{10}{appendix.A}}
\newlabel{sec:exp_supp}{{A}{10}{Additional Results}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}California Housing Dataset}{10}{subsection.A.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces California Housing dataset: Imputation Mean Squared Error (MSE) results.\relax }}{10}{table.caption.11}}
\newlabel{tab:imp_arrhytmia}{{2}{10}{California Housing dataset: Imputation Mean Squared Error (MSE) results.\relax }{table.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}ELBO Calculation}{10}{appendix.B}}
\newlabel{sec:elbo_cal_supp}{{B}{10}{ELBO Calculation}{appendix.B}{}}
\citation{teshima2020coupling}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Distributions of Latent Variables}{11}{subsection.B.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.1.1}Generative Model}{11}{subsubsection.B.1.1}}
\newlabel{sec:generative}{{B.1.1}{11}{Generative Model}{subsubsection.B.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.1.2}Recognition Model}{11}{subsubsection.B.1.2}}
\newlabel{eq:posteriorapp}{{B.1}{11}{Recognition Model}{equation.B.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}$\mathbf  {KL}$ Term}{11}{subsection.B.2}}
\newlabel{eq:KL_lapp}{{B.2}{11}{$\mathbf {KL}$ Term}{equation.B.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Reconstruction Term}{11}{subsection.B.3}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Additional Details on Algorithm}{11}{appendix.C}}
\newlabel{sec:random_mask}{{C}{11}{Additional Details on Algorithm}{appendix.C}{}}
\newlabel{eq:elbo_tree_mask}{{C.3}{12}{Additional Details on Algorithm}{equation.C.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Inference model parameters with random masking\relax }}{12}{algorithm.2}}
\newlabel{alg:rand_mask}{{2}{12}{Inference model parameters with random masking\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Aggregation Node}{12}{appendix.D}}
\newlabel{sec:aggr_supp}{{D}{12}{Aggregation Node}{appendix.D}{}}
\newlabel{eq:child_avg}{{D.4}{12}{Aggregation Node}{equation.D.4}{}}
\newlabel{eq:parent_avg}{{D.5}{12}{Aggregation Node}{equation.D.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  {\relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Aggregation node on a DAG.}\relax }}{12}{figure.caption.12}}
\newlabel{fig:dag_aggr}{{9}{12}{{\small Aggregation node on a DAG.}\relax }{figure.caption.12}{}}
\newlabel{eq:i_child}{{D.6}{12}{Aggregation Node}{equation.D.6}{}}
\newlabel{eq:i_parent}{{D.7}{12}{Aggregation Node}{equation.D.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Derivation of the ELBOs for Trees and DAGs }{13}{appendix.E}}
\newlabel{sec:ebl_deri}{{E}{13}{Derivation of the ELBOs for Trees and DAGs}{appendix.E}{}}
\newlabel{appd:tree_elbo}{{E.1}{13}{ELBO of Tree Models}{subsection.E.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}ELBO of Tree Models}{13}{subsection.E.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A tree VFG with $L=5$ and three aggregation nodes.\relax }}{13}{figure.caption.13}}
\newlabel{fig:tree_vfg}{{10}{13}{A tree VFG with $L=5$ and three aggregation nodes.\relax }{figure.caption.13}{}}
\newlabel{eq:prior}{{E.8}{13}{ELBO of Tree Models}{equation.E.8}{}}
\newlabel{eq:posterior2}{{E.9}{13}{ELBO of Tree Models}{equation.E.9}{}}
\newlabel{eq:chain_post}{{E.10}{13}{ELBO of Tree Models}{equation.E.10}{}}
\newlabel{eq:chain_prior}{{E.11}{13}{ELBO of Tree Models}{equation.E.11}{}}
\citation{rezende2015variational,kingma2016improving,berg2018sylvester}
\citation{rezende2015variational,kingma2016improving,berg2018sylvester}
\newlabel{eq:elbo12L}{{E.12}{14}{ELBO of Tree Models}{equation.E.12}{}}
\newlabel{eq:kl_lL}{{E.14}{14}{ELBO of Tree Models}{equation.E.14}{}}
\newlabel{eq:elbo0}{{E.15}{14}{ELBO of Tree Models}{equation.E.15}{}}
\newlabel{eq:kl_l}{{E.16}{14}{ELBO of Tree Models}{equation.E.16}{}}
\newlabel{eq:elbo1}{{E.17}{14}{ELBO of Tree Models}{equation.E.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.2}Improve ELBO Estimation with Flows}{14}{subsection.E.2}}
\newlabel{appd:dag_elbo}{{E.3}{14}{ELBO of DAG Models}{subsection.E.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.3}ELBO of DAG Models}{14}{subsection.E.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A DAG with inverse topology order {\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\nulldelimiterspace \z@ \left \{\vcenter to\@ne \big@size {}\right .$}\box \z@ } \{1,2,3\}, \{4,5\}, \{6\}, \{7\} {\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\nulldelimiterspace \z@ \left \}\vcenter to\@ne \big@size {}\right .$}\box \z@ }, and they correspond to layers 0 to 3. \relax }}{14}{figure.caption.14}}
\newlabel{fig:dag}{{11}{14}{A DAG with inverse topology order \big \{ \{1,2,3\}, \{4,5\}, \{6\}, \{7\} \big \}, and they correspond to layers 0 to 3. \relax }{figure.caption.14}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{eq:dag_elbo}{{E.18}{15}{ELBO of DAG Models}{equation.E.18}{}}
\newlabel{eq:dag_chain_q}{{E.19}{15}{ELBO of DAG Models}{equation.E.19}{}}
\newlabel{eq:dag_chain_p}{{E.20}{15}{ELBO of DAG Models}{equation.E.20}{}}
\newlabel{eq:dag_kl_lL}{{E.21}{15}{ELBO of DAG Models}{equation.E.21}{}}
