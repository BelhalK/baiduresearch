%\title{LaTeX Portrait Poster Template}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% a0poster Portrait Poster
% LaTeX Template
% Version 1.0 (22/06/13)
%
% The a0poster class was created by:
% Gerlinde Kettl and Matthias Weiser (tex@kettl.de)
% 
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
% PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a0,landscape]{a0poster}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{multicol} % This is so we can have multiple columns of text side-by-side
\usepackage{subfigure}
\columnsep=100pt % This is the amount of white space between the columns in the poster
\columnseprule=3pt % This is the thickness of the black line between the columns in the poster

\usepackage[svgnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors

%\usepackage{empheq}
\usepackage[most]{tcolorbox}

\tcbset{colback=yellow!10!white, colframe=red!50!black, 
        highlight math style= {enhanced, %<-- needed for the ’remember’ options
            colframe=red,colback=red!10!white,boxsep=0pt}
        }

\definecolor{opticlimb}{rgb}{0,0.65,0.65}
\definecolor{blue}{RGB}{0,0,255}
\usepackage{tcolorbox}

% \usepackage[bitstream-charter]{mathdesign}
\usepackage[authoryear,round]{natbib}
\usepackage{bbm}
\usepackage{enumitem} 
\usepackage{xargs} 
\usepackage{amssymb,amsthm,bm}
%\usepackage{mathtools}
%\usepackage{xargs}
%\usepackage{stmaryrd} 

\bibliographystyle{plainnat}
\usepackage{graphicx} % Required for including images
\graphicspath{{figures/}} % Location of the graphics files
\usepackage{booktabs} % Top and bottom rules for table
%\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures
%\usepackage{amsfonts, amsmath, amsthm, amssymb,bm} % For math fonts, symbols and environments
\usepackage{wrapfig} % Allows wrapping text around tables and figures

\usepackage{cmbright}
\usepackage{avant}
%\usepackage{tikz}
%\usepackage[T1]{fontenc}
%\usepackage[utf8]{inputenc}
%\usepackage[font=small,labelfont=bf,tableposition=top]{caption}

\renewcommand{\familydefault}{\sfdefault}

\usepackage{mdframed}
%\theoremstyle{definition}
%\newtheorem{defn}{Definition} % definition numbers are dependent on theorem numbers
%\newtheorem*{exmp}{Example} % same for example numbers
%\usepackage{lipsum}%
%  {
%      \theoremstyle{plain}
%      \newtheorem{assumption}{M}
%      \newtheorem{lemma}{Lemma}
%      \newtheorem{remark}{Remark}
%      \newtheorem{prop}{Proposition}
%      \newtheorem{assumption_saem}{ISAEM}
%      \newtheorem{assumption_rm}{SA}
%      \newtheorem{assumption_iem}{IEM}
%      \newtheorem{assumption_imcem}{IMCEM}
%      \newtheorem{assumption_expo}{E}
%  }
\newmdtheoremenv{theo}{Theorem}
\newmdtheoremenv{coro}{Corollary}
\newmdtheoremenv{lem}{Lemma}

\usepackage{shortcuts_OPT}

\begin{document}

{~\hspace{6cm}\begin{tikzpicture}[remember picture, overlay]
     \node [anchor=north east, inner sep=3cm, yshift=-5.5cm]  at (current page.north east)
     {\includegraphics[height=6cm]{images/logo_baidu.jpeg}
       \includegraphics[height=5cm]{images/logo_cuhk.png}~~
     \includegraphics[height=5cm]{images/logo_x.jpg}};
  \end{tikzpicture}}
  
  \begin{tikzpicture}[remember picture, overlay]
     \node [inner sep=3cm, yshift=2cm]  at (current page.south)
     {\large 32nd Annual Conference on Learning Theory, Phoenix, AZ};
  \end{tikzpicture}
%----------------------------------------------------------------------------------------
% POSTER HEADER 
%----------------------------------------------------------------------------------------

% The header is divided into two boxes:
% The first is 75% wide and houses the title, subtitle, names, university/organization and contact information
% The second is 25% wide and houses a logo for your university/organization or a photo of you
% The widths of these boxes can be easily edited to accommodate your content as you see fit

\begin{minipage}[b]{0.9\linewidth}
\veryHuge \color{Navy} \textbf{Minimization by Incremental Stochastic Surrogate Optimization for Large Scale Nonconvex Problems
}\\[1cm] \color{Black} %\color{Black}\textbf{COLT 2019} \color{Black}\\[1cm] % Title
%\Huge\textit{Identification de système dynamique}\\[2cm] % Subtitle
\huge \textbf{Belhal Karimi$^{1}$, Hoi-To Wai$^{2}$, Eric Moulines$^{3}$ and Ping Li$^{1}$}\\[0.5cm] % Author(s)
\huge Baidu Research$^1$, Chinese University~of Hong Kong$^2$, Ecole Polytechnique$^3$ \\[0.4cm] % University/organization
\large \texttt{belhalkarimi@baidu.com, htwai@se.cuhk.edu.hk, eric.moulines@polytechnique.edu, liping11@baidu.com@gmail.com}
\end{minipage}
%


\vspace{1cm} % A bit of extra whitespace between the header and poster content

%----------------------------------------------------------------------------------------

\begin{multicols}{3} % This is how many columns your poster will be broken into, a portrait poster is generally split into 2 columns

%----------------------------------------------------------------------------------------
% ABSTRACT
%----------------------------------------------------------------------------------------




%----------------------------------------------------------------------------------------
% INTRODUCTION
%----------------------------------------------------------------------------------------

%\color{SaddleBrown} % SaddleBrown color for the introduction
%\color{Navy} % Navy color
%\color{opticlimb}
%\color{Navy} % Navy color for the abstract
\color{DarkSlateGray}


\begin{tcolorbox}[colback=white!5!white,colframe=green!75!black,fonttitle=\sffamily\bfseries\large,title=Stochastic Approximation]
\begin{itemize}
\item \textbf{Objective:} Find a \emph{stationary point} of smooth Lyapunov function $V(\prm)$. 
\item SA scheme \citep{robbins1985stochastic} is a stochastic process: 
{\large\beq \label{eq:sa} 
\prm_{n+1} = \prm_n - \gamma_{n+1} \HX{\prm_n}{\State_{n+1}}, \quad n \in \nset 
\eeq}
where $\prm_n \in \Prm \subseteq \rset^d$ is the $n$th state, $\gamma_n > 0$ is
the step size.
\item The \emph{drift term} $\HX{\prm_n}{\State_{n+1}}$ depends on an \textbf{i.i.d.~random element} $\State_{n+1}$ and
{\large\[
h( \prm_n) = \EE \big[ \HX{\prm_n}{\State_{n+1}} | {\cal F}_n \big] = \grd V( \prm_n ),
\]}
where ${\cal F}_n = \sigma( \prm_0, \{ \State_m \}_{m \leq n})$. In this case, SA is better known as the SGD method. 
\end{itemize}
\vspace{.1cm}
\end{tcolorbox}

\begin{tcolorbox}[colback=white!5!white,colframe=blue!75!black,fonttitle=\sffamily\bfseries\large,title=Biased SA Scheme]
\begin{itemize}
\item The \textbf{mean field} is \textbf{biased} $\Leftarrow$ gradient is sometimes difficult  to compute...

We have $h(\prm) \neq \grd V(\prm)$ and for some $c_0\geq0, c_1 > 0$,
{\large\[
{c_0 + c_1 \pscal{ \grd V( \prm )}{ h( \prm) } \geq \| h( \prm ) \|^2,~\forall~\prm \in \Prm}
\]}
\item The \textbf{drift term} $\{ \HX{\prm_n}{\State_{n+1}} \}_{n \geq 1}$ is \textbf{not i.i.d.}. For example, in reinforcement learning, $\prm_n$ controls the policy in a MDP \& $\HX{\prm_n}{\State_{n+1}}$ is computed from the MDP's state.

The random elements $\{ \State_{n} \}_{n \geq 1}$ form a \textbf{state-dependent Markov chain}:
{\large\[\textstyle
{\EE[ \HX{\prm_n}{\State_{n+1}} | {\cal F}_n ] = \PX{n} \HX{\prm_n}{\State_n} = \int \HX{\prm_n}{x} \PX{n} ( \State_n, \rmd \state ),}
\]}where $\PX{n} : \Xset \times {\cal X} \rightarrow \rset_+$ is Markov kernel with a unique stationary distribution $\pi_{\prm_n}$. 
\item In the latter case, the mean field is given by
$h(\prm) = \int \HX{\prm}{\state} \pi_{\prm} ( \rmd \state ) $.
\item \textbf{Stopping criterion}: fix any $n \geq 1$, we stop the SA at a random iteration $N$ with\vspace{-.3cm}
{\large\beq \notag \textstyle
\PP( N = \ell ) = \big( {\textstyle \sum_{k=0}^n \gamma_{k+1}} \big)^{-1} \gamma_{\ell+1},~~~\text{with}~~~N \in \{1,...,n\}.
\eeq}
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=white!5!white,colframe=blue!75!black,fonttitle=\sffamily\bfseries\large,title=Prior Work]
\begin{itemize}
\item We focus on the \textbf{non-asymptotic convergence} analysis of SA scheme, where the relevant results are rare. Define:
\end{itemize}
{\large\beq \label{eq:en} \be_{n+1} \eqdef \HX{\prm_n}{\State_{n+1}} - h(\prm_n) 
\eeq}\textbf{Case 1: When $\{ \be_{n} \}_{n \geq 1}$ is Martingale difference} --- 
$\EE [ \be_{n+1} | {\cal F}_n ] = 0$
\begin{itemize}
\item \emph{Asymptotic analysis}: {\small \citep{robbins1985stochastic}}; \emph{Non-asymptotic analysis}: {\small \citep{ghadimi2013stochastic}}.
%\item \emph{Asymptotic} {\small \citep{benveniste1990adaptive}, \citep{borkar2009stochastic}}; \emph{Non-asymptotic} {\small\citep{moulines2011non}, \citep{ghadimi2013stochastic}}.
\end{itemize}
\textbf{Case 2: When $\{ \be_{n} \}_{n \geq 1}$ is state-controlled Markov noise} 
{\large\[
\EE [ \be_{n+1} | {\cal F}_n ] = \PX{n} \HX{\prm_n}{\State_n} - h( \prm_n) \neq 0.
\]}
\begin{itemize}
\item \emph{Asymptotic analysis}: {\small\citep{tadic2017asymptotic}}; \emph{Non-asymptotic analysis:} {\small \citep{NIPS2018_8195}, \citep{duchi2012ergodic}, \citep{bhandari2018finite}}
\end{itemize}
\vspace{.1cm}
\end{tcolorbox}


\begin{tcolorbox}[colback=white!5!white,colframe=red!75!black,fonttitle=\sffamily\bfseries\large,title=Analysis For Martingale Difference Noise (Case 1)]
\textbf{Assumption}: $\CPE{ {\bm e}_{n+1}}{\mcf_n} = {\bm 0}$, $\CPE{  \| {\bm e}_{n+1}\|^2}{ \mcf_n } \leq \sigma_0^2  + \sigma_1^2 \| h( \prm_n ) \|^2$. (\eg when \emph{\color{red}$\State_n$ is i.i.d.}~similar to the SGD setting).
\begin{theo} \vspace{-.5cm}
Let $\gamma_{n+1} \leq (2 c_1 L (1+\sigma_1^2) )^{-1}$ and $V_{0,n} \eqdef \EE[ V(\prm_0) - V(\prm_{n+1})]$,
{\large\[
\EE[ \| h( \prm_N ) \|^2 ] \leq \frac{2 c_1 \big( V_{0,n} + \sigma_0^2 L  \sum_{k=0}^n \gamma_{k+1}^2 \big) }{\sum_{k=0}^n \gamma_{k+1}}+ 2 c_0 \eqsp, 
\]}
\end{theo}
Set $\gamma_k = (2 c_1 L (1+\sigma_1^2) \sqrt{k})^{-1}$ $\Longrightarrow$ $\EE[ \| h( \prm_N ) \|^2 ] = {\cal O}( c_0+ \log n /\sqrt{n})$. 
\emph{Remark}: if $h(\prm) = \grd V(\prm)$ (with $c_0=d_0 = 0$), it recovers \emph{\color{red}\citep[Theorem 2.1]{ghadimi2013stochastic}}.

\end{tcolorbox}

\begin{tcolorbox}[colback=white!5!white,colframe=red!75!black,fonttitle=\sffamily\bfseries\large,title=Analysis For State-dependent Markov Noise (Case 2)]
\textbf{Assumptions}: we need a few regularity conditions in this case,
\begin{enumerate}
\item There exists a Borel measurable function $\hat{H}: \Prm \times \Xset \to \Prm$,\vspace{-.1cm}
\beq \notag
\hHX{\prm}{\state} - \PX{}{} \hHX{\prm}{\state} = \HX{\prm}{\state} - h( \prm ),~\forall~\prm \in \Prm, \state \in \Xset. 
\eeq
$\Longrightarrow$ existence of solution to the \emph{\color{red}Poisson equation}. 
\item For all $\prm \in \Prm$ and $\state \in \Xset$, $\| \hHX{\prm}{\state} \|  \leq L^{(0)}_{PH}, \| \PX{} \hHX{\prm}{\state} \| \leq L_{PH}^{(0)}$, and
\begin{equation}\notag
\textstyle \sup_{\state \in \Xset} \| \PX{} \hHX{\prm}{\state} - {P}_{\prm'} \hHX{\prm'}{\state}  \|  \leq  L_{PH}^{(1)} \| \prm - \prm' \|,~\forall~(\prm, \prm') \in \Prm^2.
\end{equation}
$\Longrightarrow$ \emph{\color{red}smoothness} of $\hHX{\prm}{\state}$, satisfied if $\PX{}$, $\HX{\prm}{\State}$ are smooth \wrt $\prm$.
\item It holds that $\sup_{\prm \in \Prm, \state \in \Xset}  \| \HX{\prm}{\state} - h(\prm) \| \leq \sigma$.\vspace{.3cm}

$\Longrightarrow$ requires the noise is \emph{\color{red}uniformly bounded} for all $x \in \Xset$.
\end{enumerate}
\textbf{Example}: assumptions 1 \& 2 are satisfied if the Markov kernel $\PX{\prm}$ is geometrically ergodic + smooth, and the drift term is smooth \wrt $\prm$. 
\begin{theo}\vspace{-.5cm}Suppose that
the step sizes are decreasing and $\gamma_1 \leq 0.5 \big( c_1(L+C_h) \big)^{-1}$ (+other conditions). 
%\beq\notag
%\gamma_{n+1} \leq \gamma_n, ~\gamma_n \leq a \gamma_{n+1},~ \gamma_n - \gamma_{n+1} \leq a' \gamma_n^2,~\gamma_1 \leq 0.5 \big( c_1(L+C_h) \big)^{-1} \eqsp, 
%\eeq
%for $a, a' > 0$ and all $n \geq 0$. 
Let $V_{0,n} \eqdef \EE[ V(\prm_0) - V(\prm_{n+1})]$,
{\large\[
 \EE [\| h( \prm_N ) \|^2 ] \leq
 \frac{ 2c_1 \big( V_{0,n} + C_{0,n} + \big( \sigma^2 L + C_\gamma \big) \sum_{k=0}^{n}
 \gamma_{k+1}^2 \big) }{ \sum_{k=0}^n \gamma_{k+1} } + 2 c_0 \eqsp.\vspace{-.1cm}
\]}
\end{theo}\vspace{-.2cm}
\begin{itemize}
\item Set $\gamma_k = (2 c_1 L (1+C_h) \sqrt{k})^{-1}$ $\Longrightarrow$ 
{\color{red}$\EE [ \|h( \prm_N ) \|^2 ] = {\cal O}( c_0 + \log n / \sqrt{n} )$} (same as Case 1).
\item \textbf{Proof idea:} challenge is that $\be_{n+1}$ is not zero-mean $\Longrightarrow$ bound the sum of $\EE[ \pscal{ \grd V(\prm_n) }{ \be_{n+1} } ]$ w/ Poisson equation + a novel decomposition [cf.~\emph{\color{blue}Lemma 2}].
%{\large\[
%\hHX{\prm}{\state} - \PX{}{} \hHX{\prm}{\state} = \HX{\prm}{\state} - h( \prm ),~\forall~\prm \in \Prm, \state \in \Xset,
%\]}
%where $\hat{H}: \Prm \times \Xset \to \Prm$ is a Borel measurable function.
\end{itemize}
\vspace{.1cm}
\end{tcolorbox}

\begin{tcolorbox}[colback=white!5!white,colframe=blue!75!black,fonttitle=\sffamily\bfseries\large,title=Regularized Online EM Algorithm]
\begin{itemize}
\item \textbf{Special Case of GMM}: we fit the data $\{ Y_n \}_{n \geq 1}$, $Y_n \sim \pi$ into the parametric model with $\param = ( \{ \omega_m \}_{m=1}^{M-1}, \{ \mu_m \}_{m=1}^M )$
{\beq \notag \textstyle
g(y ; \param) \propto \Big(1-\sum_{m=1}^{M-1} \omega_m\Big) \exp\left(- \frac{(y - \mu_M)^2}{2} \right)  + \sum_{m=1}^{M-1}
\omega_m \exp\left(- \frac{(y - \mu_m)^2}{2} \right),
\eeq}
\item Data  arrives in a streaming fashion, \citet{cappe2009line} does:\vspace{-.2cm}
{\large\[
\begin{split}
\textsf{E-step:}~~ & \hat{\bm s}_{n+1} = \hat{\bm s}_n + \gamma_{n+1} \big\{ \overline{\bm s}( Y_{n+1}; \hat{\param}_n ) - \hat{\bm s}_n \big\}, \\
\textsf{M-step:}~~ & \hat{\param}_{n+1} = \overline{\param} ( \hat{\bm s}_{n+1} ).\vspace{-.2cm}
\end{split}
\]}
\item The \textbf{E-step} is a biased SA step on ${\bm s}$ with the drift term \& mean field\vspace{-.2cm}
{\large\[
H_{ \hat{\bm s}_n } (Y_{n+1}) = \hat{\bm s}_n -  \overline{\bm s}(Y_{n+1}; \mstep{ \hat{\bm s}_n } ), \quad h( \hat{\bm s}_n ) = \hat{\bm s}_n - \EE_\pi \big[  \overline{\bm s}(Y_{n+1}; \mstep{ \hat{\bm s}_n } ) \big]
\vspace{.1cm}
\]}
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=white!5!white,colframe=red!75!black,fonttitle=\sffamily\bfseries\large,title=Analysis of the ro-EM Algorithm (Application of Case 1)]
Consider the KL divergence as a function of sufficient statistics ${\bm s}$:
{\large\[
V( {\bm s}) \eqdef {\sf KL} ( \pi | g(\cdot; \mstep{\bm s}) ) + \Pen( \mstep{\bm s}  ) =
\EE_\pi \big[ \log \big( \pi(Y) / g( Y; \mstep{\bm s} ) \big) \big] + \Pen( \mstep{\bm s}  ). \vspace{-.75cm}
\]}
\begin{coro} \vspace{-.5cm}
Set $\gamma_k = (2 c_1 L (1+\sigma_1^2) \sqrt{k})^{-1}$.
Ro-EM method for GMM finds $\hat{\bm s}_N$ such that
{\large\[
\EE [ \| \grd V( \hat{\bm s}_N ) \|^2 ] = {\cal O}( \log n / \sqrt{n} )
\]}
The expectation is taken \wrt $N$ and the observation law $\pi$.
\end{coro}
\begin{itemize}
\item First \emph{\color{red}explicit non-asymptotic} rate given for online EM method.
\item Consider a slightly modified/regularized M-step update for satisfaction of the technical conditions.
%\item Rigorous convergence proof for \emph{\color{red}global convergence} of (online) EM methods are rare. 
\end{itemize}
\vspace{.1cm}
\end{tcolorbox}

\begin{tcolorbox}[colback=white!5!white,colframe=blue!75!black,fonttitle=\sffamily\bfseries\large,title=(Online) Policy Gradient Method]
\begin{itemize}
\item Consider a Markov Decision Process (MDP) $( \Sset, \Aset, \Reward, \transMDP )$:
\begin{itemize}
\item $\Sset$, $\Aset$ is the finite set of  state/action.
\item $\Reward: \Sset \times \Aset \to [0,\Reward_{\max}]$ is a reward function; $\transMDP$ is the transition model.
\end{itemize}
\item A \textbf{policy} is parameterized by $\prm \in \rset^d$ as (e.g., soft-max):
\beq \notag
\Policy_{\prm}( a'; s') = \text{probability of taking action $a'$ in state $s'$}\vspace{-.2cm}
\eeq
\item Update $\prm$ in an online fashion \citep{tadic2017asymptotic} using observed state-action pair:\vspace{-.6cm}
\begin{subequations} \label{eq:policy_grad}
{\large\[
\begin{split}
G_{n+1} & = \lambda G_n + \grd \log \Policy_{\prm_n}( A_{n+1}; S_{n+1}) \eqsp,  \\
\prm_{n+1} & = \prm_n + \gamma_{n+1} G_{n+1} \Reward( S_{n+1}, A_{n+1} ) \eqsp
\end{split}
\]}
\end{subequations}
where $\lambda \in (0,1)$ is a parameter for the variance-bias trade-off.
\item The $\prm$-update is an biased SA step with the drift term:\vspace{-.3cm}
{\large\[
\HX{\prm_n}{\State_{n+1}} = G_{n+1} \Reward(S_{n+1},A_{n+1})\vspace{.1cm}
\]}
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=white!5!white,colframe=red!75!black,fonttitle=\sffamily\bfseries\large,title=Analysis of Policy Gradient Method (Application of Case 2)]
Let $\invarMDP_{\prm}(s,a)$ be the invariant distribution of $\{ (S_t,A_t) \}_{t \geq 1}$, we consider:
{\large\[ \textstyle
J( \prm ) \eqdef \sum_{s \in \Sset,a \in \Aset} \invarMDP_{\prm}(s,a) \Reward(s,a) \eqsp.\vspace{-.75cm}
\]}
\begin{coro} \vspace{-.5cm}
Set $\gamma_k = (2 c_1 L (1+C_h) \sqrt{k})^{-1}$. For any $n \in \NN$,  the policy gradient algorithm \eqref{eq:policy_grad} finds a policy that
{\large\[
\EE \big[ \| \grd J( \prm_N ) \|^2 \big] = {\cal O} \Big( (1-\lambda)^2 \Gamma^2 + c(\lambda) \log n / \sqrt{n} \Big),
\]}
where $c(\lambda) = {\cal O}( \frac{1}{1-\lambda})$. Expectation is taken \wrt $N$ and $(A_n,S_n)$. 
\end{coro}
\begin{itemize}
\item It shows the \emph{\color{red}first convergence rate} for the online PG method.
\item Our result shows the \emph{\color{red} variance-bias trade-off} with $\lambda \in (0,1)$. 
\item Setting $\lambda \rightarrow 1$ reduces the bias, but decreases the convergence speed.
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=white!5!white,colframe=blue!75!black,fonttitle=\sffamily\bfseries\large,title=Conclusion]
\begin{itemize}
\item {\color{blue} Theorem 1 \& 2} show the non-asymptotic convergence rate of biased SA scheme with smooth (possibly non-convex) Lyapunov function. 
\item With appropriate step size, in \emph{n} iterations the SA scheme finds 
$\EE[ \| h( \prm_N ) \|^2 ] = {\cal O}( c_0 + \log n / \sqrt{n} )$, where $c_0$ is the bias and $h(\cdot)$ is the mean field.
\item Applications to online EM and online policy gradient.
\end{itemize}
\end{tcolorbox}
\vspace{-1.3cm}
\small
%\nocite{*} % Print all references regardless of whether they were cited in the poster or not
\bibliography{references.bib}

%----------------------------------------------------------------------------------------
% ACKNOWLEDGEMENTS
%----------------------------------------------------------------------------------------

%\section*{Acknowledgements}

%\includegraphics[width=15cm]{opticlimb.png}\\


%----------------------------------------------------------------------------------------

\end{multicols}
\begin{center}
%\includegraphics[width=10cm]{logo_x.jpg}
%\includegraphics[width=10cm]{logo_inria.png}
%\includegraphics[width=15cm]{opticlimb.png}\\
\end{center}
\end{document}