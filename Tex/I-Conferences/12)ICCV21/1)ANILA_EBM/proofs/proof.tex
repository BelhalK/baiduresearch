\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}

\usepackage{bm,amsmath,amsthm,amssymb,algorithmic,algorithm,enumitem,graphicx,subfigure}
\usepackage{xargs}
\usepackage{stmaryrd}
\usepackage{mdframed}
\usepackage{booktabs}

\newmdtheoremenv{theo}{Theorem}
\newmdtheoremenv{lemm}{Lemma}
\newmdtheoremenv{coro}{Corollary}

\input{shortcuts}



 \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}
\onecolumn
%%%%%%%%% TITLE
\title{STANLey: \textbf{ST}ochastic gradient \textbf{AN}isotropic \textbf{L}angevin dynamics for learning Energy-Based Models}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}


%\author{First Author\\
%Institution1\\
%Institution1 address\\
%{\tt\small firstauthor@i1.org}
%% For a paper whose authors are all at the same institution,
%% omit the following lines up until the closing ``}''.
%% Additional authors and addresses can be added with ``\and'',
%% just like the second author.
%% To save space, use either the email address or home page, not both
%\and
%Second Author\\
%Institution2\\
%First line of institution2 address\\
%{\tt\small secondauthor@i2.org}
%}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi




\section{Geometric ergodicity of \algo\ sampler}\label{sec:theory}
We will present in this section, our theoretical analysis for the Markov Chain constructed using Line~\ref{line:step}-\ref{line:langevin}. 

Let $\Theta$ be a subset of $\rset^d$ for some integer $d >0$.
We denote by $\zset$ the measurable space of $\rset^\ell$ for some integer $\ell >0$.
We define a family of stationary distribution $\left(\pi_\theta(z) \right)_{\theta \in \Theta}$, probability density functions with respect to the Lebesgue measure on the measurable space $\zset$. This family of p.d.f. defines the stationary distributions of our newly introduced sampler.

\textbf{Important Note:} The stationary distributions are defined per $\theta \in \Theta$, \ie at each model update during the EBM optimization phase.

\subsection{Notations and Assumptions}
For any chain state $z \in \zset$ we denote by $\Pi_\theta(z,\cdot)$ the transition kernel as defined in the \algo\ update in Line~\ref{line:langevin}.

The objective of this section is to rigorously show that each transition kernel $\pi_\theta$ is uniformly geometrically ergodic and that this result is true uniformly in state $s$ on any compact subset $\mathcal{C} \in \zset$.
As a background note, a Markov chain, as built Line~\ref{line:langevin}, is said to be geometrically ergodic when $k$ iterations of the same transition kernel is converging to the stationary distribution of the chain and this convergence as a geometric dependence on $k$.

We begin with several usual assumptions for such results.
The first one is related to the continuity of the gradient of the log posterior distribution and the unit vector pointing in the direction of the sample $z$ and the unit vector pointing in the direction of the gradient of the log posterior distribution at $z$:
\begin{assumption}\label{ass:bounded}
(Continuity) The stationary distribution is positive and has continuous derivative such that for all $\theta \in \rset^d$:
\begin{equation}
\begin{split}
\lim \limits_{z \to \infty} \frac{z}{|z|} \nabla f_{\theta}(z) & = - \infty \\
 \lim \sup \limits_{z \to \infty} \frac{z}{|z|} \frac{\nabla f_{\theta}(z) }{|\nabla f_{\theta}(z) |} &< 0
\end{split}
\end{equation}
\end{assumption}

We assume also some regularity conditions of the stationary distributions with respect to state $s$:
\begin{assumption}\label{ass:contlogpi}
For all $z \in \zset$, $\theta \to \pi_\theta$ and $\theta \to \nabla \log \pi_\theta$ are continuous on $\Theta$.
\end{assumption}

For a positive and finite function noted $V: \zset \mapsto \rset$, we define the V-norm distance between two arbitrary transition kernels $\Pi_1$ and $\Pi_2$ as follows:

\beq
\| \Pi_1 - \Pi_2 \|_V \eqdef \sup \limits_{z \in \zset} \frac{\| \Pi_1(z, \cdot) - \Pi_2(z, \cdot) \|_V }{V(z)}
\eeq

The definition of this norm will allow us to establish a convergence rate for our sampling method by deriving an upper bound of the quantity $\| \Pi_\theta^k - \pi_\theta \|_V$ where $k$ denotes the number of MCMC transitions.
We also recall that $\Pi_\theta$ is the transition kernel defined by Line~\ref{line:langevin} and $\pi_\theta$ is the stationary distribution of our Markov chain. 
Then, this quantity characterizes how close to the target distribution, our chain is getting after a finite time of iterations and will eventually formalize \emph{V-uniform ergodicity} of our method.
We specify that strictly speaking $\pi_\theta$ is a probability measure, and not a transition kernel. However $\| \Pi_\theta^k - \pi_\theta \|_V$ is well-defined if we consider the the probability $\pi_\theta$ as a kernel by making the definition:

\beq
\pi(z, \mathcal{C}) \eqdef \pi(\mathcal{C}) \quad \textrm{for} \quad \mathcal{C} \in \zset, \quad z \in \zset
\eeq


Here, for some $\beta \in ] 0,1[$ we define the $V_\theta$ function, also know as the \emph{drift}, for all $z \in \zset$ as follows: 
\beq\label{eq:driftfunction}
V_\theta(z) \eqdef c_\theta \pi_\theta(z)^{-\beta} \eqsp,
\eeq
where $c_\theta$ is a constant, with respect to the chain state $s$, such that for all $z \in \zset$, $V_\theta(z) \geq 1$.
Again, we note that the V norm is, in our case, function of the chain state noted $z$ \emph{and} of the global model parameter $\theta$, estimated, and thus varying, through the optimization procedure.
The convergence rate will thus be given for a particular model estimate (precisely its supremum).
Define 

\beq\label{eq:vfunctions}
\begin{split}
V_1(z) & \eqdef \inf \limits_{\theta \in \Theta} V_\theta(z) \\
 V_2(z) & \eqdef \sup \limits_{\theta \in \Theta} V_\theta(z) \eqsp,
\end{split}
\eeq
and assume that
\begin{assumption}\label{ass:V2}
There exists a constant $a_0 > 0$ such that for all $\theta \in \Theta $ and $z \in \zset$, $V_2^{a_0}(z)$ is integrable against the kernel $\Pi_\theta(z, \cdot)$ and 
\beq
 \lim \sup  \limits_{a \to 0}  \sup \limits_{\theta \in \Theta, z \in \zset} \Pi_\theta V_2^a(z) = 1
\eeq

\end{assumption}

We will now give the main convergence result of our sampling method in \algo.
The result consists of showing V-uniform ergodicity of the chain, the irreducibility of the transition kernels and their aperiodicity, see \cite{meyn2012markov} for more details. 
We also prove a drift condition which states that the transition kernels tend to bring back elements into a small set from which boils down V-uniform ergodicity of the transition kernels $(\Pi_\theta)_{\theta \in \Theta}$.


\begin{theo}\label{thm:thm1}
Assume H\ref{ass:bounded}-H\ref{ass:V2}.
For any $\theta \in \Theta$, there exists a drift function $V_\theta$, a set $\mathcal{O} \subset \zset$, a constant $0 < \epsilon \leq 1$ such that 
\beq\label{thm:main1}
\Pi_\theta(z, \bset) \geq  \epsilon \int_{\bset} \mathsf{1}_\xset(z)  \textrm{d}y \eqsp.
\eeq
Moreover there exists $0 < \mu < 1$, $\delta > 0$ and a drift function $V$, now independent of $\theta$ such that for all $z \zset$:
\beq\label{thm:main2}
\Pi_\theta V(z) \leq \mu V(z) + \delta \mathsf{1}_{\mathcal{O}}(z) \eqsp.
\eeq
\end{theo}








\section{Proofs of the Theoretical Results}

\subsection{Proofs of Theorem~\ref{thm:thm1}}
\begin{Theorem*}
Assume H\ref{ass:bounded}-H\ref{ass:V2}.
For any $\theta \in \Theta$, there exists a drift function $V_\theta$, a set $\mathcal{O} \subset \zset$, a constant $0 < \epsilon \leq 1$ such that 
\beq
\Pi_\theta(z, \bset) \geq  \epsilon \int_{\bset} \mathsf{1}_\xset(z)  \textrm{d}y \eqsp.
\eeq
Moreover there exists $0 < \mu < 1$, $\delta > 0$ and a drift function $V$, now independent of $\theta$ such that for all $z \zset$:
\beq
\Pi_\theta V(z) \leq \mu V(z) + \delta \mathsf{1}_{\mathcal{O}}(z) \eqsp.
\eeq
\end{Theorem*}


\begin{proof}



\textbf{Notations used throughout this proof:} 

\begin{table}[htbp]
%\caption{Table of Notations}
% between the caption and the table
\begin{tabular}{r c p{17cm} }
\toprule
$\Pi_\theta$ & $\triangleq$ &  Transition kernel of the MCMC defined by \eqref{eq:anila}\\
$\mathcal{O}$ & $\triangleq$ & subset of $\rset^p$ and small set for kernel $\Pi_\theta$\\
& & \textcolor{red}{COMPLETE WITH ALL NOTATIONS USED}\\
\bottomrule
\end{tabular}
\label{tab:notations}
\end{table}



The proof of our results are divided into two parts.
We first prove the existence of a set noted $\mathcal{O}$ as a small set for our transition kernel $\Pi_\theta$.
Proving a small set is important to show that for any state, the Markov Chain does not stay in the same state, and thus help in proving its irreducibility and aperiodicity.

Then, we will prove the drift condition towards a small set.
This condition is crucial to prove the convergence of the chain since it states that the kernels tend to attract elements into that set. 
finally, uniform ergodicity is established as a consequence of those drift conditions.

\medskip
\noindent \textbf{(i) Existence of small set: }
Let $\mathcal{O}$ be a compact subset of the state space $\zset$.
We also denote the pdf of the Gaussian proposal of Line~\ref{line:step} as $z \to \prop{\theta}(z',z)$ for any current state of the chain $z' \in \zset$ and dependent on the EBM model parameter $\theta$.
Given \algo's MCMC update, at iteration $t$, the proposal is a Gaussian distribution of mean $z_{t-1}^m+ \stepsize_t/2  \nabla f_{\theta_t}(z_{t-1}^m)$ and covariance $\sqrt{\stepsize_t} \mathsf{B}_t$.

We recall the definition of the transition kernel in the case of a Metropolis adjustment and for any model parameter $\theta \in \Theta$ and state $z \in \zset$:

\beq 
\Pi_\theta(z, \bset) = \int_{\bset} \alpha_\theta(z, y) \prop{\theta}(z,y) \textrm{d}y + \mathsf{1}_bset(z)\int_{\zset} (1 - \alpha_\theta(z, y)) \prop{\theta}(z,y) \textrm{d}y
\eeq

where we have defined the Metropolis ratio between two states $z \in \zset$ and $y \in \bset$ as $\alpha_\theta(z, y) = \textrm{min}(1, \frac{\pi_\theta(z)  \prop{\theta}(z,y)}{\prop{\theta}(y,z) \pi_\theta(y)  })$.
Thanks to Assumption H\ref{ass:bounded} and to the fact that the threshold $\thresh$ leads to a symmetric positive definite covariance matrix with bounded non zero eigenvalues implies that the proposal distribution can be bounded by two zero-mean Gaussian distributions as follows:

\beq\label{eq:twogauss}
a n_{\sigma_1}(z - y) \leq \prop{\theta}(z,y)  \leq b n_{\sigma_2}(z - y) \quad \textrm{for all} \quad \theta \in \Theta
\eeq
where $\sigma_1$ and $\sigma_2$ are the corresponding standard deviation of the distributions and $a$ and $b$ are some scaling factors.

We denote by $\rho_\theta$ the ratio $\frac{\pi_\theta(z)  \prop{\theta}(z,y)}{\prop{\theta}(y,z) \pi_\theta(y)  }$ and define the quantity 
\beq\label{eq:delta}
\delta = \textrm{inf}(\rho_\theta(z,y), \theta \in \Theta, \quad z \in \mathcal{O} ) > 0
\eeq
 given the assumptions H\ref{ass:bounded} and H\ref{ass:contlogpi}.
Likewise, the proposal distribution is bounded from below by its some quantity noted $m$.
Then,
\beq
\Pi_\theta(z, \bset) \geq  \int_{\bset \cap \xset} \alpha_\theta(z, y) \prop{\theta}(z,y) \textrm{d}y \geq \textrm{min}(1, \delta) m \int_{\bset} \mathsf{1}_\xset(z)  \textrm{d}y
\eeq

Then, given the definition of \eqref{eq:delta}, we can find a compact set $\mathcal{O}$ such that $\Pi_\theta(z, \bset) \geq \geq \epsilon$ where $\epsilon = \textrm{min}(1, \delta) m \textbf{Z}$ where $\textbf{Z}$ is the normalizing constant of the pdf $\frac{1}{\textbf{Z}}\mathcal{1}_\xset(z)  \textrm{d}y$.
Thus proving \eqref{thm:main1}, \ie the existence of a small set for our family of transition kernels $(\Pi_\theta)_\theta$.

\medskip
\noindent \textbf{(ii) Drift condition and ergodicity: }
We first need to prove the fact that our family of transition kernels $(\Pi_\theta)_\theta$ satisfies a drift property.

For a given EBM model parameter $\theta \in \Theta$, we can see in \cite{jarner2000geometric} that the drift condition boils down to proving that for the drift function noted $V_\theta$ and defined in \eqref{eq:driftfunction}, we have
\beq\label{mainproof}
\sup \limits_{z \in \zset}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} < \infty \quad \textrm{and} \quad \lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} < 1
\eeq

Throughout the proof, the model parameter is set to an arbitrary $\theta \in \Theta$.
Let denote the acceptation set, \ie\ $\rho_\theta \geq 1$ by $\accept(z) \eqdef \{ y \in \zset, \rho_\theta(z,y) \geq 1 \}$ for any state $y \in \bset$ and its complementary set $\compaccept(z)$.

\medskip
\noindent \textsc{Step (1): } Following our definition of the drift function in \eqref{eq:driftfunction} we obtain:

\begin{align}\label{eq:main1}
 \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} & = \int_{\accept(z)}  \prop{\theta}(z,y) \frac{V_\theta(y)}{V_\theta(z)} \textrm{d}y +  \int_{\compaccept(z)} \frac{\pi_\theta(y)\prop{\theta}(y,z)}{\pi_\theta(z)\prop{\theta}(z,y)} \prop{\theta}(z,y) \frac{V_\theta(y)}{V_\theta(z)} \textrm{d}y +  \int_{\compaccept(z)} (1 - \frac{\pi_\theta(y)\prop{\theta}(y,z)}{\pi_\theta(z)\prop{\theta}(z,y)}) \prop{\theta}(z,y)  \textrm{d}y\\
 &  \overset{(a)}{\leq} \int_{\accept(z)}  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  + \int_{\compaccept(z)} \prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}\textrm{d}y +  \int_{\compaccept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}
where (a) is due to \eqref{eq:driftfunction}.

According to \eqref{eq:twogauss}, we thus have that, for any state $z$ in the acceptance set $\accept(z)$:
\beq \label{eq:comp}
\int_{\accept(z)}  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  \leq  b \int_{\accept(z)}  n_{\sigma_2}(y-z)  \textrm{d}y 
\eeq

For any state $z$ in the complementary set of the acceptance set $\compaccept(z)$ we also have the following:
\beq
\int_{\compaccept(z)} \prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}\textrm{d}y \leq \int_{\compaccept(z)} \prop{\theta}(z,y)^{1- \beta} \prop{\theta}(y,z)^{\beta}  \textrm{d}y \leq b \int_{\compaccept(z)} n_{\sigma_2}(z - y)  \textrm{d}y
\eeq


While we can define the level set of the stationary distribution $\pi_\theta$ as $\mathcal{L}_{\pi_\theta(y)} = \{ z \in \zset, \pi_\theta(z) = \pi_\theta(y) \}$ for some state $y \in \bset$, a neighborhood of that level set is defined as $\mathcal{L}_{\pi_\theta(y)}(p) = \{z \in  \mathcal{L}_{\pi_\theta(y)}, z + t \frac{z}{|z|}, |t| \leq p \}$.

H\ref{ass:bounded} ensures the existence of a radial $r$ such that for all $z \in \zset, |z| \geq r$, then $0 \in \mathcal{L}_{\pi_\theta(y)}$ with $\pi_\theta(z) >  \pi_\theta(y)$.

Since the function $y \to n_{\sigma_2}(y - z)$ is smooth, it is known that there exists a constant $a >0$ such that for $\epsilon >0$, we have that 
\beq\label{eq:lowandup}
\int_{B(z,a)}  n_{\sigma_2}(y - z) \textrm{d}y \geq 1 - \epsilon \quad \textrm{and} \quad \int_{B(z,a) \cap \mathcal{L}_{\pi_\theta(y)}(p) }  n_{\sigma_2}(y - z) \textrm{d}y \leq  \epsilon
\eeq
for some $p$ small enough and where $B(z,a)$ denotes the ball around $z \in \zset$ of radius $a$.
Then combining \eqref{eq:comp} and \eqref{eq:lowandup} we have that:

\beq
\int_{\accept(z) \cap B(z,a) \cap \mathcal{L}_{\pi_\theta(y)}(p) }  \prop{\theta}(z,y) \frac{\pi_\theta(y)^{-\beta}}{\pi_\theta(z)^{-\beta}} \textrm{d}y  \leq  b \epsilon
\eeq

Conversely, we can define the set  $\mathcal{A} = \accept(z) \cap B(z,a) \cap \mathcal{L}^+$ where $u \in \mathcal{L}^+$ if $u \in \mathcal{L}_{\pi_\theta(y)}(p)$ and $\phi_\theta(u) > \pi_\theta(p)$.

Then using the second part of H\ref{ass:bounded}, there exists a radius $r' > r + a$, such that for $z \in \zset$ with $|z| \geq r'$ we have

\beq
\int_{\mathcal{A}} (\frac{\pi_\theta(y)}{\pi_\theta(z)})^{1-\beta} \prop{\theta}(y,z) \textrm{d}y \leq \mathsf{d}(p, r')^{1-\beta}  b \int_{\accept(z)}  n_{\sigma_2}(y-z)  \textrm{d}y\leq b \mathsf{d}(p, r')^{1-\beta} 
\eeq

where $\mathsf{d}(p, r') = \sup \limits_{|z| > r'} \frac{\pi_\theta(z + p \frac{z}{|z|})}{\pi_\theta(z)}$. 
Note that H\ref{ass:bounded} implies that $\mathsf{d}(p, r') \to 0$ when $r' \to \infty$.

Likewise with  $\mathcal{A} = \accept(z) \cap B(z,a) \cap \mathcal{L}^-$ we have
\beq
\int_{\mathcal{A}} (\frac{\pi_\theta(y)}{\pi_\theta(z)})^{-\beta} \prop{\theta}(z,y) \textrm{d}y  \leq b \mathsf{d}(p, r')^{\beta} 
\eeq

Same arguments can be obtained for the second term of \eqref{eq:main1}, \ie $\prop{\theta}(z,y) \frac{\pi_\theta(y)^{1-\beta}}{\pi_\theta(z)^{1-\beta}}$ and we obtain, plugging the above in \eqref{eq:main1} that:

\begin{align}
\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq \lim \sup \limits_{|z| \to \infty}  \int_{\compaccept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}

Since $\compaccept(z)$ is the complementary set of $\accept(z)$, the above inequality yields

\begin{align}
\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq 1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y
\end{align}



\medskip
\noindent \textsc{Step (2): } The final step of our proof consists in proving that $1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \leq 1 - c$ where $c$ is a constant, independent of all the other quantities.


Given that the proposal distribution is a Gaussian and using assumption H\ref{ass:bounded} we have the existence of a constant $c_a$ depending on $a$ as defined above (the radius of the ball $B(z,a)$) such that

\beq\label{eq:gauss}
\frac{\pi_\theta(z)}{\pi_\theta(z- \ell \frac{z}{|z|})} \leq  c_a \leq \inf \limits_{y \in B(z,a)} \frac{\prop{\theta}(y, z)}{\prop{\theta}(z, y)} \quad \textrm{for any} \, z \in \zset, |z| \geq r^*
\eeq

Then for any $|z| \geq r^*$, we obtain that $z- \ell \frac{z}{|z|} \in \accept(z)$.
A particular subset of $\accept(z)$ used throughout the rest of the proof is the cone defined as 

\beq\label{eq:defcone}
\mathcal{P}(z) \eqdef \{ z- \ell \frac{z}{|z|} - \kappa \nu , \, \textrm{with} \quad i < a - \ell  , \nu \in \{ \nu \in \rset^d, \| \nu \| < 1\}, |\nu - \frac{z- \ell \frac{z}{|z|} }{|z- \ell \frac{z}{|z|} |} \leq \frac{\epsilon}{2}   \}
\eeq

Using Lemma~\ref{lem:cone}, we have that $\mathcal{P}(z) \subset \accept(z)$

Then,  

\beq 
 \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \overset{(a)}{\geq}  \int_{\accept(z)}a n_{\sigma_1}(y- z)  \textrm{d}y \overset{(b)}{\geq} a \int_{\mathcal{P}(z)}  n_{\sigma_1}(y-z)  \textrm{d}y
 \eeq
where we have used \eqref{eq:twogauss} in (a) and applied Lemma~\ref{lem:cone} in (b).

If we define the translation of vector $z \in \zset$ by the operator $\mathcal{I} \subset \rset^d \to T_z(\mathcal{I})$, then
\beq\label{eq:constant}
 \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \geq a \int_{\mathcal{P}(z)}  n_{\sigma_1}(y-z)  \textrm{d}y =  \int_{T_z(\mathcal{P}(z))}  n_{\sigma_1}(y-z)  \textrm{d}y
\eeq


Recalling the objective of \noindent \textsc{Step (2)} that is to find a constant $c$ such that $1 - \lim \inf \limits_{|z| \to \infty}  \int_{\accept(z)} \prop{\theta}(z,y)  \textrm{d}y \leq 1 - c$, we see from \eqref{eq:constant} that since the set $\mathcal{P}(z)$ does not depend on the EBM model parameter $\theta$ and that once translated by $z$ the resulting set $T_z(\mathcal{P}(z))$ is independent of $z$ (but depends on $\ell$, see definition \eqref{eq:defcone}, then the integral $ \int_{T_z(\mathcal{P}(z))}  n_{\sigma_1}(y-z)  \textrm{d}y$ in \eqref{eq:constant} is independent of $z$ thus concluding on the existence of the constant $c$ such that $\lim \sup \limits_{|z| \to \infty}  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} \leq 1- c$. Thus proving the second part of \eqref{mainproof} which is the main drift condition we ought to demonstrate.
The first part of \eqref{mainproof} can be proved by observing that $  \frac{\Pi_\theta V_\theta(z)}{V_\theta(z)} $ is smooth on $\zset$ according to H\ref{ass:contlogpi} and by construction of the transition kernel. Smoothness implies boundedness on the compact $\zset$.


\medskip
\noindent \textsc{Step (3): } 
We now use the main proven equations in \eqref{mainproof} to derive the second result \eqref{thm:main2} of Theorem~\ref{thm:thm1}.

We will begin by showing a similar inequality for the drift function $V_\theta$, thus not having uniformity, as an intermediary step.
The Drift property is a consequence of \textsc{Step (2)} and \eqref{eq:constant} shown above.
Thus, there exists $0 < \bar{\mu} < 1$, $\bar{\delta} > 0$ such that for all $z \zset$:
\beq\label{eq:driftvtheta}
\Pi_\theta V_\theta(z) \leq \bar{\mu} V_\theta(z) + \bar{\delta} \mathsf{1}_{\mathcal{O}}(z) \eqsp,
\eeq
where $V_\theta$ is defined by \eqref{eq:driftfunction}.

Using the two functions defined in \eqref{eq:vfunctions}, we define for $z \in \zset$, the $V$ function independent of $\theta$ as follows:
\beq\label{eq:defv}
V(z) = V_1(z)^\alpha V_2(z)^{2\alpha} \eqsp,
\eeq
where $0 < \alpha < \textrm{min}(\frac{1}{2\beta},\frac{a_0}{3})$, $a_0$ is defined in H\ref{ass:V2} and $\beta$ is defined in \eqref{eq:driftfunction}.
Thus for $\theta \in \Theta$, $z \in \zset$ and $\epsilon >0$:
\begin{align}\notag
\Pi_\theta V(z) & = \int_{\zset} \Pi_\theta(z,y) V_1(y)^\alpha V_2(y)^{2\alpha} \textrm{d}y\\ \notag
& \overset{(a)}{\leq} \frac{1}{2} \int_{\zset} \Pi_\theta(z,y) (\frac{1}{\epsilon^2}V_1(y)^{2\alpha} + \epsilon^2 V_2(y)^{4\alpha}) \textrm{d}y\\ 
& \overset{(b)}{\leq} \frac{1}{2\epsilon^2} \int_{\zset} \Pi_\theta(z,y) V_\theta(y)^{2\alpha} + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y \label{eq:uniform1}
\end{align}
where we have used the Young's inequality in (a) and the definition of $V_1$, see \eqref{eq:vfunctions}, in (b).
Then plugging \eqref{eq:driftvtheta} in \eqref{eq:uniform1}, we have
\begin{align}
\Pi_\theta V(z) & \leq \frac{1}{2\epsilon^2} (\bar{\mu} V_\theta(z)^{2\alpha} + \bar{\delta} \mathsf{1}_{\mathcal{O}}(z) ) + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{2}  \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{2} \sup \limits_{\theta \in \Theta, z \in \zset} \int_{\zset} \Pi_\theta(z,y)  V_2(y)^{4\alpha} \textrm{d}y\\
& \leq \frac{\bar{\mu}}{2 \epsilon^2} V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z)  + \frac{\epsilon^2}{1 + \bar{\mu}}V(z)\\
& \leq \left(\frac{\bar{\mu}}{2 \epsilon^2} + \frac{\epsilon^2}{1 + \bar{\mu}} \right) V(z) +\frac{\bar{\delta}}{2 \epsilon^2} \mathsf{1}_{\mathcal{O}}(z) 
\end{align}

where we have used \eqref{eq:defv} and the assumption H\ref{ass:V2} in the last inequality, ensuring the existence of such exponent $\alpha$.

Setting $\epsilon \eqdef \sqrt{\frac{\bar{\mu}(1+\bar{\mu})}{2}}$, $ \mu  \eqdef  \sqrt{\frac{2\bar{\mu}}{1+\bar{\mu}}}$ and $\delta \eqdef \frac{\bar{\delta}}{2 \epsilon^2}$ proves the uniform ergodicity in \eqref{thm:main2} and concludes the proof of Theorem~\ref{thm:thm1}.
\end{proof}


\subsection{Proofs of Lemma~\ref{lem:cone}}

\begin{Lemma*}
Define $\mathcal{P}(z) \eqdef \{ z- \ell \frac{z}{|z|} - \kappa \nu , \, \textrm{with} \quad \kappa < a - \ell  , \nu \in \{ \nu \in \rset^d, \| \nu \| < 1\}, |\nu - \frac{z- \ell \frac{z}{|z|} }{|z- \ell \frac{z}{|z|} |} \leq \frac{\epsilon}{2}   \}$ and $\accept(z) \eqdef \{ y \in \zset, \rho_\theta(z,y) \geq 1 \}$. Then for $z \in \zset$, $\mathcal{P}(z) \subset \accept(z)$
\end{Lemma*}

\begin{proof}

In order to show the inclusion of the set $\mathcal{P}(z)$ in $\accept(z)$ we start by selecting the quantity $y = z- \ell \frac{z}{|z|} - \kappa \nu$ for $z\in \zset$ and $\kappa < a - \ell $ where $a$ is the radius of the ball used in \eqref{eq:lowandup} such that $y \in \mathcal{P}(z)$.
We will now show that $y \in \accept(z)$.

By the generalization of Rolle's theorem applied on the stationary distribution $\pi_\theta$, we guarantee the existence of some $\kappa^*$ such that:

$$
\nabla \pi_\theta( z- \ell \frac{z}{|z|} - \kappa^* \nu) = \frac{\pi_\theta(y) - \pi_\theta(z- \ell \frac{z}{|z|})}{y - (z- \ell \frac{z}{|z|})} = - \frac{\pi_\theta(y) - \pi_\theta(z- \ell \frac{z}{|z|})}{\kappa \nu}
$$

Expanding $\nabla \pi_\theta( z- \ell \frac{z}{|z|} - \kappa^* \nu)$ yields:
\beq\label{eq:interlem}
\pi_\theta(y) - \pi_\theta(z- \ell \frac{z}{|z|}) = - \kappa \nu \frac{z- \ell \frac{z}{|z|} - \kappa^* \nu}{|z- \ell \frac{z}{|z|} - \kappa^* \nu|} |\nabla \pi_\theta( z- \ell \frac{z}{|z|} - \kappa^* \nu)|
\eeq

Yet, under H\ref{ass:bounded}, there exists $\epsilon$ such that 
$$
 \frac{\nabla f_{\theta}(z) }{|\nabla f_{\theta}(z) |}  \frac{z }{|z|} \leq -\epsilon
 $$
 and for any $y \in \mathcal{P}(z)$ we note that $\frac{y }{|y|} - \frac{z }{|z|}|\leq \frac{\epsilon}{2}$, by construction of the set.
 Thus, 
\beq\label{eq:finallem}
  \frac{\nabla f_{\theta}(y) }{|\nabla f_{\theta}(y) |}  \nu  =  \frac{\nabla f_{\theta}(y) }{|\nabla f_{\theta}(y) |} (\nu - \frac{z- \ell \frac{z}{|z|} }{|z- \ell \frac{z}{|z|} |}) +  \frac{\nabla f_{\theta}(y) }{|\nabla f_{\theta}(y) |} (\nu - \frac{z- \ell \frac{z}{|z|} }{|z- \ell \frac{z}{|z|} |} - \frac{y }{|y|} ) + \frac{\nabla f_{\theta}(y) }{|\nabla f_{\theta}(y) |}  \frac{y }{|y |} \leq 0
\eeq
 where $\nu$ is used in the definition of $\mathcal{P}(z)$.
 Also note that $  \frac{\nabla f_{\theta}(y) }{|\nabla f_{\theta}(y) |}  \nu  $ denotes the vector multiplication between the normalized gradient and $\nu$.
 
Then plugging \eqref{eq:finallem} into \eqref{eq:interlem} leads to $\pi_\theta(y) - \pi_\theta(z- \ell \frac{z}{|z|}) \geq 0$.
Then $y \in \mathcal{P}(z)$ implies, using \eqref{eq:gauss}, that $\pi_\theta(y) \geq \pi_\theta(z- \ell \frac{z}{|z|}) \geq \frac{1}{c_a} \pi_\theta(z)$. 
 Finally $y \in \mathcal{P}(z)$ implies that $y \in \accept(z)$, concluding the proof of Lemma~\ref{lem:cone}.
 
\end{proof}



\end{document}
