\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage[colorlinks,linkcolor=blue,filecolor=blue,citecolor=magenta,urlcolor=blue]{hyperref}
\usepackage{bm,amsmath,amsthm,amssymb,multicol,algorithmic,algorithm,enumitem,graphicx,subfigure}
\usepackage{xargs}
\usepackage{stmaryrd}
\usepackage{natbib}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\newtheorem{definition}{Definition}
\newcommand{\algo}{\textsc{eff-EBM}}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}


\def\code#1{\texttt{#1}}

\input{shortcuts.tex}





\begin{document}



\title{Weekly Report KARIMI-2021-09-17}


\date{}
\maketitle

\vspace{-0.5in}

My work this week has mainly been towards
\begin{enumerate}
\item Compressed EBM for memory efficiency
\item Spars AMS code for Imagenet
\item FEDLAMB arxiv paper and Bernoulli journal EM paper formatting and submission
\end{enumerate}



\section{Memory Efficient EBM Training}


\begin{definition}[Top-$k$]\label{def:topk}
For $x\in\mathbb R^d$, denote $\mathcal S$ as the size-$k$ set of $i\in[d]$ with largest $k$ magnitude $|x_i|$. The \textbf{Top-$k$} compressor is defined as $\mathcal C(x)_i=x_i$, if $i\in\mathcal S$; $\mathcal C(x)_i=0$ otherwise.
\end{definition}

\begin{definition}[Block-Sign]\label{def:sign}
For $x\in\mathbb R^d$, define $M$ blocks indexed by $\mathcal B_i$, $i=1,...,M$, with $d_i\eqdef |\mathcal B_i|$. The \textbf{Block-Sign} compressor is defined as $\mathcal C(x)=[sign(x_{\mathcal B_1})\frac{\|x_{\mathcal B_1}\|_1}{d_1},..., sign(x_{\mathcal B_M}) \frac{\|x_{\mathcal B_M}\|_1}{d_M}]$. 
\end{definition}


\begin{algorithm}[H]
\caption{\algo\ } \label{alg:anila}
\begin{algorithmic}[1]
%\small
\STATE \textbf{Input}: Number of iterations $T$, MCMC transitions $K$ and of samples $M$, global learning rate $\{\eta_t\}_{t >0}$,  MCMC stepsizes ${\gamma_k}_{k >0}$, initial value $\theta_0$, MCMC initialization $\{ z_{0}^m \}_{m=1}^M$ and observations $\{ x_{i} \}_{i=1}^n$.
\FOR{$t=1$ to $T$}
\STATE Draw $M$ samples $\{ z_{t}^m \}_{m=1}^M$ from the objective potential via Langevin diffusion:\label{line:langevin}
\FOR{$k=1$ to $K$}
\STATE Use black box compression operators to compress the gradient with respect to $z$:
$$
\tilde{g}_{k-1}^m = \mathcal{C}(\nabla_z f_{\theta_t}(z_{k-1}^m) )
$$
\STATE Construct the Markov Chain as follows:
\beq\label{eq:anila}
z_{k}^{m} = z_{k-1}^m + \frac{\gamma_k}{2} \tilde{g}_{k-1}^m+ \sqrt{\gamma_k} \mathsf{B}_k \eqsp,
\eeq
where $\mathsf{B}_t$ denotes the Brownian motion (Gaussian noise).
\ENDFOR
\STATE Assign $\{ z_{t}^m \}_{m=1}^M \leftarrow \{ z_{K}^m \}_{m=1}^M$.
\STATE Sample $m$ positive observations $\{ x_{i} \}_{i=1}^m$ from the empirical data distribution.
\STATE Compute the gradient of the empirical log-EBM:
\beq\notag
\begin{split}
\nabla \log p(\theta_t) 
 = \mathbb{E}_{p_{\text {data }}}\left[\nabla_{\theta} f_{\theta_t}(x)\right]-\mathbb{E}_{p_{\theta}}\left[\nabla_{\theta_t} f_{\theta}(z_t)\right]\approx  \frac{1}{n} \sum_{i=1}^{n} \nabla_{\theta} f_{\theta_t}\left(x_{i}\right)-\frac{1}{m} \sum_{i=1}^{m} \nabla_{\theta} f_{\theta_t}\left(z_t^m\right)\eqsp.
\end{split}
\eeq
\STATE Update the vector of global parameters of the EBM:\label{line:gradient}
\beq\notag
\theta_{t+1} = \theta_{t} + \eta_t \nabla \log p(\theta_t) \eqsp.
\eeq
\ENDFOR
\STATE \textbf{Output:} Vector of fitted parameters $\theta_{T+1}$.
\end{algorithmic}
\end{algorithm}


\section{Spars AMS Imagenet and 1-bit Adam}


\bibliographystyle{plain}
\bibliography{ref}


\end{document} 