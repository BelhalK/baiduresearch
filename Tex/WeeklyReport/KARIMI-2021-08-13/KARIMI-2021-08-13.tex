\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage[colorlinks,linkcolor=blue,filecolor=blue,citecolor=magenta,urlcolor=blue]{hyperref}
\usepackage{bm,amsmath,amsthm,amssymb,multicol,enumitem,graphicx,subfigure}
\usepackage{xargs}
\usepackage{stmaryrd}
\usepackage{natbib}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}


\def\code#1{\texttt{#1}}


\usepackage{algorithm,algpseudocode}

\algnewcommand{\algorithmicforeach}{\textbf{for each}}
\algdef{SE}[FOR]{ForEach}{EndForEach}[1]
  {\algorithmicforeach\ #1\ \algorithmicdo}% \ForEach{#1}
  {\algorithmicend\ \algorithmicforeach}% \EndForEach




\begin{document}



\title{Weekly Report KARIMI 2021-08-13}


\date{}
\maketitle

\vspace{-0.5in}

My work this week has mainly been towards finishing NeurIPS rebuttals and making progress on the EM paper.
\begin{enumerate}
\item Reviews for NeurIPS papers on Monda and Tuesday.
\item Federated and Distributed EM paper
\item Polishing the Stanley paper for AAAI
\end{enumerate}

\section{NeurIPS 2021 Reviews}

All rebuttals have been posted on OpenReview.


\section{STANLEy paper}

Several typos and modifications resulting from ICCV reviews have been made on overleaf.


\section{EM paper}

Main progress include a clear understanding of what the paper will include.
Both motivations for distributing the E-step (MovieLens data for instance is huge and the E step can be overwhelming so there is a need to parallelize it) and for making it private and efficient (considering sensible data and low bandwidth devices, making the E step private and not heavy computationally is also important).

I have been studying two important references which are \citep{srivastava2019asynchronous} and \citep{morral2012line}.

In the first paper, they develop a simple parallelization of the E-step for a particular class of network models and massive data.
We could argue that massive data can be solved using simple incremental methods since then the complexity of the algorithm would become independent of the number of observations $n$. Yet, when several workers are at our disposal, being able to compute complete gradients/expectations is always better (in terms of variance and accuracy).
They develop an asymptotic convergence result. Working in our case with exponential family will allow us to develop a better theory.
Numerical applications are mainly nonlinear models applied to MovieLens dataset.

In the second reference, the problem is slightly different. Workers only can share information with their neighbours.
This setting will not be the one of our paper but looking at how it works in such a setup is interesting.

In our case, we first develop the basic Decentralized EM for the exponential family. The algorithm is straight forward.
Later, we present its extension to the federated settings where the statistics and quantized and the latent samples, drawn from MCMC for generality, are compressed.

Another important difference in our work is that the expectations are not tractable (making it more flexible to complex models). Hence, the sampling step being costly and in general not private, the need to tackle those issues is important.

Please see the overleaf project for details on these points.


\textbf{TODO:}
\begin{itemize}
\item Develop a theory for the distributed settings first. Then move to the Federated settings (more challenging since quantization and compression in the mix)
\item Plots for at least one nonlinear model and on other type of model (bi-factor or pLSA).
\end{itemize}



\bibliographystyle{plain}
\bibliography{ref}


\end{document} 