\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allassonni{\`e}re et~al.(2007)Allassonni{\`e}re, Amit, and
  Trouv{\'e}]{allassonniere2007towards}
St{\'e}phanie Allassonni{\`e}re, Yali Amit, and Alain Trouv{\'e}.
\newblock Towards a coherent statistical framework for dense deformable
  template estimation.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 69\penalty0 (1):\penalty0 3--29, 2007.

\bibitem[Allassonni{\`e}re et~al.(2010)Allassonni{\`e}re, Kuhn, and
  Trouv{\'e}]{allassonniere2010construction}
St{\'e}phanie Allassonni{\`e}re, Estelle Kuhn, and Alain Trouv{\'e}.
\newblock Construction of bayesian deformable models via a stochastic
  approximation algorithm: a convergence study.
\newblock \emph{Bernoulli}, 16\penalty0 (3):\penalty0 641--678, 2010.

\bibitem[Allassonni{\`e}re et~al.(2013)Allassonni{\`e}re, Bigot, Glaun{\`e}s,
  Maire, and Richard]{allassonniere2013statistical}
St{\'e}phanie Allassonni{\`e}re, J{\'e}r{\'e}mie Bigot, Joan~Alexis
  Glaun{\`e}s, Florian Maire, and Fr{\'e}d{\'e}ric~JP Richard.
\newblock Statistical models for deformable templates in image and shape
  analysis.
\newblock In \emph{Annales math{\'e}matiques Blaise Pascal}, volume~20, pages
  1--35, 2013.

\bibitem[Baey et~al.(2016)Baey, Trevezas, and Courn{\`e}de]{baey2016nonlinear}
Charlotte Baey, Samis Trevezas, and Paul-Henry Courn{\`e}de.
\newblock A non linear mixed effects model of plant growth and estimation via
  stochastic variants of the {EM} algorithm.
\newblock \emph{Communications in Statistics-Theory and Methods}, 45\penalty0
  (6):\penalty0 1643--1669, 2016.

\bibitem[Blei et~al.({2017})Blei, Kucukelbir, and
  McAuliffe]{BleiVariational2017}
David~M. Blei, Alp Kucukelbir, and Jon~D. McAuliffe.
\newblock {Variational Inference: A Review for Statisticians}.
\newblock \emph{{Journal of the American statistical Association}},
  {112}\penalty0 ({518}):\penalty0 {859--877}, {JUN} {2017}.
\newblock ISSN {0162-1459}.
\newblock \doi{10.1080/01621459.2017.1285773}.

\bibitem[Brooks et~al.(2011)Brooks, Gelman, Jones, and
  Meng]{brooks2011handbook}
Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng.
\newblock \emph{Handbook of markov chain monte carlo}.
\newblock CRC press, 2011.

\bibitem[Capp{\'e}(2011)]{cappe2011online}
Olivier Capp{\'e}.
\newblock Online {EM} algorithm for hidden markov models.
\newblock \emph{Journal of Computational and Graphical Statistics}, 20\penalty0
  (3):\penalty0 728--749, 2011.

\bibitem[Capp{\'e} and Moulines(2009)]{cappe2009line}
Olivier Capp{\'e} and Eric Moulines.
\newblock On-line expectation--maximization algorithm for latent data models.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 71\penalty0 (3):\penalty0 593--613, 2009.

\bibitem[Carlin and Chib(1995)]{carlin1995bayesian}
Bradley~P Carlin and Siddhartha Chib.
\newblock Bayesian model choice via markov chain monte carlo methods.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 57\penalty0 (3):\penalty0 473--484, 1995.

\bibitem[Chakraborty and Das(2010)]{das2010Inferences}
Arindom Chakraborty and Kalyan Das.
\newblock Inferences for joint modelling of repeated ordinal scores and time to
  event data.
\newblock \emph{Computational and mathematical methods in medicine},
  11\penalty0 (3):\penalty0 281--295, 2010.

\bibitem[Chen et~al.(2018)Chen, Zhu, Teh, and Zhang]{chen2018stochastic}
Jianfei Chen, Jun Zhu, Yee~Whye Teh, and Tong Zhang.
\newblock Stochastic expectation maximization with variance reduction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  7978--7988, 2018.

\bibitem[Delyon et~al.(1999)Delyon, Lavielle, and Moulines]{delyon1999}
Bernard Delyon, Marc Lavielle, and Eric Moulines.
\newblock Convergence of a stochastic approximation version of the {EM}
  algorithm.
\newblock \emph{Ann. Statist.}, 27\penalty0 (1):\penalty0 94--128, 03 1999.
\newblock \doi{10.1214/aos/1018031103}.

\bibitem[Dempster et~al.(1977)Dempster, Laird, and Rubin]{dempster1977Maximum}
Arthur~P Dempster, Nan~M Laird, and Donald~B Rubin.
\newblock Maximum likelihood from incomplete data via the {EM} algorithm.
\newblock \emph{Journal of the royal statistical society. Series B
  (methodological)}, pages 1--38, 1977.

\bibitem[Efron(1975)]{efron1975defining}
Bradley Efron.
\newblock Defining the curvature of a statistical problem (with applications to
  second order efficiency).
\newblock \emph{The Annals of Statistics}, 3\penalty0 (6):\penalty0 1189--1242,
  1975.

\bibitem[Fort et~al.(2020)Fort, Moulines, and Wai]{fortem2020}
Gersende Fort, Eric Moulines, and Hoi-To Wai.
\newblock A stochastic path integral differential estimator expectation
  maximization algorithm.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 16972--16982. Curran Associates, Inc., 2020.

\bibitem[Fort et~al.(2021)Fort, Moulines, and Wai]{fort2021geom}
Gersende Fort, Eric Moulines, and Hoi-To Wai.
\newblock Geom-spider-em: Faster variance reduced stochastic expectation
  maximization for nonconvex finite-sum optimization.
\newblock In \emph{ICASSP 2021-2021 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 3135--3139. IEEE, 2021.

\bibitem[Ghadimi and Lan(2013)]{ghadimi2013stochastic}
Saeed Ghadimi and Guanghui Lan.
\newblock Stochastic first-and zeroth-order methods for nonconvex stochastic
  programming.
\newblock \emph{SIAM Journal on Optimization}, 23\penalty0 (4):\penalty0
  2341--2368, 2013.

\bibitem[Hughes(1999)]{hughes1999mixed}
James~P Hughes.
\newblock Mixed effects models with censored data with application to hiv rna
  levels.
\newblock \emph{Biometrics}, 55\penalty0 (2):\penalty0 625--629, 1999.

\bibitem[Hull(1994)]{hull1994database}
Jonathan~J. Hull.
\newblock A database for handwritten text recognition research.
\newblock \emph{IEEE Transactions on pattern analysis and machine
  intelligence}, 16\penalty0 (5):\penalty0 550--554, 1994.

\bibitem[Jain and Kar(2017)]{jain2017non}
Prateek Jain and Purushottam Kar.
\newblock Non-convex optimization for machine learning.
\newblock \emph{Found. Trends Mach. Learn.}, 10\penalty0 (3-4):\penalty0
  142--336, 2017.

\bibitem[Johnson and Zhang(2013)]{johnson:zhang:2013}
Rie Johnson and Tong Zhang.
\newblock Accelerating stochastic gradient descent using predictive variance
  reduction.
\newblock In \emph{Advances in neural information processing systems}, pages
  315--323, 2013.

\bibitem[Karimi et~al.(2019)Karimi, Wai, Moulines, and
  Lavielle]{karimi2019global}
Belhal Karimi, Hoi-To Wai, {\'E}ric Moulines, and Marc Lavielle.
\newblock On the global convergence of (fast) incremental expectation
  maximization methods.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2833--2843, 2019.

\bibitem[Kuhn and Lavielle(2004)]{kuhn2004coupling}
Estelle Kuhn and Marc Lavielle.
\newblock Coupling a stochastic approximation version of {EM} with an mcmc
  procedure.
\newblock \emph{ESAIM: Probability and Statistics}, 8:\penalty0 115--131, 2004.

\bibitem[Kuhn et~al.(2020)Kuhn, Matias, and Rebafka]{kuhn2019properties}
Estelle Kuhn, Catherine Matias, and Tabea Rebafka.
\newblock Properties of the stochastic approximation {EM} algorithm with
  mini-batch sampling.
\newblock \emph{Stat. Comput.}, 30\penalty0 (6):\penalty0 1725--1739, 2020.

\bibitem[Liang and Klein(2009)]{liang2009online}
Percy Liang and Dan Klein.
\newblock Online {EM} for unsupervised models.
\newblock In \emph{Proceedings of Human Language Technologies: Conference of
  the North American Chapter of the Association of Computational Linguistics
  (HLT-NAACL)}, pages 611--619, Boulder, CO, 2009.

\bibitem[Maire et~al.(2017)Maire, Moulines, and Lefebvre]{maire2016online}
Florian Maire, Eric Moulines, and Sidonie Lefebvre.
\newblock Online {EM} for functional data.
\newblock \emph{Comput. Stat. Data Anal.}, 111:\penalty0 27--47, 2017.

\bibitem[McCulloch(1997)]{mcculloch1997maximum}
Charles~E McCulloch.
\newblock Maximum likelihood algorithms for generalized linear mixed models.
\newblock \emph{Journal of the American statistical Association}, 92\penalty0
  (437):\penalty0 162--170, 1997.

\bibitem[McLachlan and Krishnan(2007)]{mclachlan2007algorithm}
Geoffrey McLachlan and Thriyambakam Krishnan.
\newblock \emph{The {EM} algorithm and extensions}, volume 382.
\newblock John Wiley \& Sons, 2007.

\bibitem[Meyn and Tweedie(2012)]{meyn2012markov}
Sean~P Meyn and Richard~L Tweedie.
\newblock \emph{Markov chains and stochastic stability}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Neal and Hinton(1998)]{neal1998view}
Radford~M Neal and Geoffrey~E Hinton.
\newblock A view of the {EM} algorithm that justifies incremental, sparse, and
  other variants.
\newblock In \emph{Learning in graphical models}, pages 355--368. Springer,
  1998.

\bibitem[Ng and McLachlan(2003)]{ngChoice2003}
Shu{-}Kay Ng and Geoffrey~J. McLachlan.
\newblock On the choice of the number of blocks with the incremental {EM}
  algorithm for the fitting of normal mixtures.
\newblock \emph{Stat. Comput.}, 13\penalty0 (1):\penalty0 45--55, 2003.

\bibitem[Nguyen et~al.(2020)Nguyen, Forbes, and McLachlan]{nguyen2020mini}
Hien~Duy Nguyen, Florence Forbes, and Geoffrey~J. McLachlan.
\newblock Mini-batch learning of exponential family finite mixture models.
\newblock \emph{Stat. Comput.}, 30\penalty0 (4):\penalty0 731--748, 2020.

\bibitem[Reddi et~al.(2016)Reddi, Sra, P{\'{o}}czos, and Smola]{reddi2016fast}
Sashank~J. Reddi, Suvrit Sra, Barnab{\'{a}}s P{\'{o}}czos, and Alexander~J.
  Smola.
\newblock Fast incremental method for smooth nonconvex optimization.
\newblock In \emph{Proceedings of the 55th {IEEE} Conference on Decision and
  Control (CDC)}, pages 1971--1977, Las Vegas, NV, 2016.

\bibitem[Robbins and Monro(1951)]{robbins1951stochastic}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock \emph{The annals of mathematical statistics}, pages 400--407, 1951.

\bibitem[Wei and Tanner(1990)]{wei1990monte}
Greg~CG Wei and Martin~A Tanner.
\newblock A monte carlo implementation of the {EM} algorithm and the poor man's
  data augmentation algorithms.
\newblock \emph{Journal of the American statistical Association}, 85\penalty0
  (411):\penalty0 699--704, 1990.

\bibitem[Wu(1983)]{wu1983convergence}
CF~Jeff Wu.
\newblock On the convergence properties of the {EM} algorithm.
\newblock \emph{The Annals of statistics}, pages 95--103, 1983.

\bibitem[Zhu et~al.(2017)Zhu, Wang, Zhai, and Gu]{zhu2017high}
Rongda Zhu, Lingxiao Wang, Chengxiang Zhai, and Quanquan Gu.
\newblock High-dimensional variance-reduced stochastic gradient
  expectation-maximization algorithm.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning (ICML)}, pages 4180--4188, Sydney, Australia, 2017.

\end{thebibliography}
