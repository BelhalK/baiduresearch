\documentclass{article}
\usepackage{neurips_2020_author_response,xcolor,bm}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}
\usepackage{lipsum}


\begin{document}

We would like to thank three reviewers for their feedback. Upon acceptance, we will include in the final version \emph{{\sf (a)} improved notations}, \emph{{\sf (b)} an improved presentation of related work} and \emph{{\sf (c)} missing references}. 
We first discuss a few common concerns shared by \textbf{\color{blue}reviewer 1}, \textbf{\color{red} reviewer 2}, \textbf{\color{green!50!black}reviewer 3},\textbf{\color{yellow!50!black}reviewer 4} and \textbf{\color{brown}reviewer 5}.

${\color{blue}\bullet}\!~{\color{red}\bullet}\!~{\color{green!50!black}\bullet}\!~{\color{yellow!50!black}\bullet}\!~{\color{brown}\bullet}$ \textbf{Notations Issue}: 
We acknowledge the cumbersome notations of our paper and will modify them in order to reflect the reviewers remarks. 
Deterministic and Stochastic quantities will be clearly identified in their notations and some less important abstractions will be dismissed.


${\color{blue}\bullet}\!~{\color{red}\bullet}$ \textbf{Originality of the Contribution:}: We agree with the reviewer that our contribution stands as a combination of variance reduction ([Chen+, 2018], [Johnson+, 2013]), EM methods ([Karimi+, 2019], [Kuhn+, 2019]) and Stochastic Approximation ([Delyon+, 1999], [Robbins and Monro, 1951]). 
The diversity of all those contributions into a single framework constitues what we believe to be the originality of this paper both on the algorithmic and theoretical plans.
Adding a layer of noise, due to MC approximation, and a second stepsize to reduce its variance present some added technicalities that need careful consideration.


${\color{green!50!black}\bullet}\!~{\color{brown}\bullet}$ \textbf{Importance of the Assumptions}: 



\textbf{\textcolor{blue}{Reviewer 1:}} We thank the reviewer for valuable comments. We would like to clarify the following points:

\textbf{Potential Applications:} We admit it is a challenging task to present all technical results and obvious applications within the page limit, but we will try our best to improve in the final version, viz.~using a running example to illustrate the assumptions used and implementation of algorithms. For instance, the deformable template analysis or the pharmacokinetics example (which can be found in the Appendix) will be presented throughout the paper with clear motivation for using our scheme.

%\textbf{Originality of the Contribution:} We agree with the reviewer that our contribution stands as a combination of variance reduction ([Chen+, 2018], [Johnson+, 2013]), EM methods ([Karimi+, 2019], [Kuhn+, 2019]) and Stochastic Approximation ([Delyon+, 1999], [Robbins and Monro, 1951]). 
%The diversity of all those contributions into a single framework constitues what we believe to be the originality of this paper both on the algorithmic and theoretical plans.
%Adding a layer of noise, due to MC approximation, and a second stepsize to reduce its variance present some added technicalities that need careful consideration.

\textbf{Exponential Family:} 
The curved exponential family is a classical one in the EM-related literature and holds for most models where  EM is useful [McLachlan\&Krishnan 2007] . 
While remaining general, the advantage of such family is to write the algorithm updates only with respect to the sufficient statistics and not in the space of parameters $\theta$. 
The M-step is thus in general expressed in \emph{closed-form} and not as a black-box optimization ($\arg\max$ operation).
Yet, we would like to clarify to the reviewer that exponential family does not imply tractable posterior. 
The intractability of this posterior sampling step is, in our case, due to the nonconvexity of the loss function. 
Due to Bayes rule and the intractable normalizing constant, a complete likelihood that belongs to the exponential family does not imply a tractable posterior distribution.


\textbf{\textcolor{red}{Reviewer 2:}} We thank the reviewer for the comments and typos. We add the following remarks:

\textbf{Comparison with [Karimi+, 2019]:} 
We would like to clarify to the reviewer that the work in [Karimi+, 2019] can not be directly compared to ours since the problems and models tackled are different. 
While both of these papers are dealing with nonconvex objective functions, the added layer of randomness, due to the sampling step in our method, makes it practically and theoretically different approach.
Yet, as pointed by the reviewer, somme lemmas (Lemma 1 and 2) are recalled in our paper and are needed to characterize the deterministic part of those models. The stochastic part (sampling from the posterior distribution) is new and is the object of our paper.

\textbf{Comparison with gradient-based EM algorithms:} Gradient-based methods have been developed and analyzed in [Zhu+, 2017] but they remain out of the scope of this paper as they tackle the high-dimensionality issue. 
Gradient-EM are also relevant when the M-step can only be solved through a gradient descent method. In our case, the exponential family assumption allows us to leverage the sufficient statistics and the maximization functions $ \overline{\theta}( \overline{\textbf{s}}(\theta) )$ to update the parameters without an inner iterative process.


\textbf{\textcolor{green!50!black}{Reviewer 3:}} We thank the reviewer for insightful comments and typos. Our point-to-point response is as follows:

\textbf{Compacity assumption:}  We agree with the reviewer on the need for random projections in order to stay in a compact set.
For our analysis we assume that the statistics always remain in a defined compact subset of $\mathbb{R}^d$.
While this assumption holds for the GMM example, it is not the case for the deformable template analysis one.
We implemented the \emph{Truncation on random boundaries} techniques found in [Allassonniere+, 2010] based on restart.

\textbf{Comparison of proxies (Table 1):} The advantage between the incremental proxy and the two variance reduction yields from their sublinear convergence rate (see Theorems 2 and 3).
The vrTTEM requires the tuning of the epoch length $m$ but only stores one vector of $n$ parameter and a control variate term while the fiTTEM requires storing two vector of parameters (for the two randomly drawn indices) but does not require any hyper-parameter tuning.

\textbf{\textcolor{yellow!50!black}{Reviewer 4:}} We thank the reviewer for valuable comments and references. Our point-to-point response is as follows:

\textbf{Various questions:} $t_i^k$ is not empty by construction since it stores the iteration at which index $i$ was last drawn. 
They are initialized after a single pass over all indices.
We are not aware of similar algorithms mixing optimization and sampling techniques. The only algorithm we are aware of are the SAEM and the MCEM and none of them have been studied non asymptotically.
The stopping criterion $K_m$ is a purely theoretical consideration. Such a random termination scheme is very common in stochastic non-convex optimization, see [Ghadimi\&Lan,2013]. 



\textbf{\textcolor{brown}{Reviewer 5:}} We thank the reviewer for valuable comments and references. We make the following precision:

\textbf{Comparison to list of EM theory papers:}
We thank the reviewer for the comprehensive list of references.
After careful consideration, the listed references are either related to deterministic EM methods, where no sampling procedure is required since the expectations are always tractable, or to gradient EM method which has been replied to above (see \textcolor{red}{Reviewer 2:}).

They also focus on mixture models which is an instance of the exponential family we are tackling.
We agree that more specific studies depending on the model would lead to more tightened analysis but would lose the generality of our proposed study.


\textbf{Need for two-timescale:}
In Equation (9), the first stepsize $\rho_k$ is crucial for the incremental update (as stated in [Karimi+, 2019]. It makes the variance reduction of the incremental update possible (see SVRG and SAGA papers in the optimization literature).
The second stepsize $\gamma_k$ is crucial for the variance reduction of the MC approximation. In other word the noise induced by sampling a single index at each iteration is tempered by $\rho_k$ while the noise induced by sampling the latent data to compute the Monte Carlo approximation is tempered by $\gamma_k$. Initial experiments without this $\gamma_k$ showed poor convergence properties.
Of course the disadvantage will be the tuning of both stepsizes. But in practice, SA scheme are converging fairly well using a decreasing stepsize of the form $\gamma_k = 1/k^{\alpha}$.


\textbf{Convergence Analysis Presentation:}
The term \emph{Global} is employed in the sense that it does not restrict the initialization, a common assumption for analysis of EM.

\textbf{Convergence in Numerical Example:}
All the methods indeed converge to a reasonable precision (see that the y axis start from 1 and decrease to $10^{-3}$.
This numerical example illustrates how the proposed framework ought to reduce the variance of baseline method in order to reach a higher precision ($10^{-3}$ in this example).


\end{document}

