\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allassonni{\`e}re and Kuhn(2008)]{allassonniere2008stochastic}
St{\'e}phanie Allassonni{\`e}re and Estelle Kuhn.
\newblock Stochastic algorithm for parameter estimation for dense deformable
  template mixture model.
\newblock \emph{arXiv preprint arXiv:0802.1521}, 2008.

\bibitem[Allassonni{\`e}re et~al.(2007)Allassonni{\`e}re, Amit, and
  Trouv{\'e}]{allassonniere2007towards}
St{\'e}phanie Allassonni{\`e}re, Yali Amit, and Alain Trouv{\'e}.
\newblock Towards a coherent statistical framework for dense deformable
  template estimation.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 69\penalty0 (1):\penalty0 3--29, 2007.

\bibitem[Allassonni{\`e}re et~al.(2010)Allassonni{\`e}re, Kuhn, Trouv{\'e},
  et~al.]{allassonniere2010construction}
St{\'e}phanie Allassonni{\`e}re, Estelle Kuhn, Alain Trouv{\'e}, et~al.
\newblock Construction of bayesian deformable models via a stochastic
  approximation algorithm: a convergence study.
\newblock \emph{Bernoulli}, 16\penalty0 (3):\penalty0 641--678, 2010.

\bibitem[Baey et~al.(2016)Baey, Trevezas, and Courn{\`e}de]{baey2016nonlinear}
Charlotte Baey, Samis Trevezas, and Paul-Henry Courn{\`e}de.
\newblock A non linear mixed effects model of plant growth and estimation via
  stochastic variants of the em algorithm.
\newblock \emph{Communications in Statistics-Theory and Methods}, 45\penalty0
  (6):\penalty0 1643--1669, 2016.

\bibitem[Blei et~al.({2017})Blei, Kucukelbir, and
  McAuliffe]{BleiVariational2017}
David~M. Blei, Alp Kucukelbir, and Jon~D. McAuliffe.
\newblock {Variational Inference: A Review for Statisticians}.
\newblock \emph{{Journal of the American statistical Association}},
  {112}\penalty0 ({518}):\penalty0 {859--877}, {JUN} {2017}.
\newblock ISSN {0162-1459}.
\newblock \doi{{10.1080/01621459.2017.1285773}}.

\bibitem[Brooks et~al.(2011)Brooks, Gelman, Jones, and
  Meng]{brooks2011handbook}
Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng.
\newblock \emph{Handbook of markov chain monte carlo}.
\newblock CRC press, 2011.

\bibitem[Capp{\'e}(2011)]{cappe2011online}
Olivier Capp{\'e}.
\newblock Online {EM} algorithm for hidden markov models.
\newblock \emph{Journal of Computational and Graphical Statistics}, 20\penalty0
  (3):\penalty0 728--749, 2011.

\bibitem[Capp{\'e} and Moulines(2009)]{cappe2009line}
Olivier Capp{\'e} and Eric Moulines.
\newblock On-line expectation--maximization algorithm for latent data models.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 71\penalty0 (3):\penalty0 593--613, 2009.

\bibitem[Carlin and Chib(1995)]{carlin1995bayesian}
Bradley~P Carlin and Siddhartha Chib.
\newblock Bayesian model choice via markov chain monte carlo methods.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 57\penalty0 (3):\penalty0 473--484, 1995.

\bibitem[Chakraborty and Das(2010)]{das2010Inferences}
Arindom Chakraborty and Kalyan Das.
\newblock Inferences for joint modelling of repeated ordinal scores and time to
  event data.
\newblock \emph{Computational and mathematical methods in medicine},
  11\penalty0 (3):\penalty0 281--295, 2010.

\bibitem[Chen et~al.(2018)Chen, Zhu, Teh, and Zhang]{chen2018stochastic}
Jianfei Chen, Jun Zhu, Yee~Whye Teh, and Tong Zhang.
\newblock Stochastic expectation maximization with variance reduction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  7978--7988, 2018.

\bibitem[Delyon et~al.(1999)Delyon, Lavielle, and Moulines]{delyon1999}
Bernard Delyon, Marc Lavielle, and Eric Moulines.
\newblock Convergence of a stochastic approximation version of the em
  algorithm.
\newblock \emph{Ann. Statist.}, 27\penalty0 (1):\penalty0 94--128, 03 1999.
\newblock \doi{10.1214/aos/1018031103}.
\newblock URL \url{https://doi.org/10.1214/aos/1018031103}.

\bibitem[Dempster et~al.(1977)Dempster, Laird, and Rubin]{dempster1977Maximum}
Arthur~P Dempster, Nan~M Laird, and Donald~B Rubin.
\newblock Maximum likelihood from incomplete data via the {EM} algorithm.
\newblock \emph{Journal of the royal statistical society. Series B
  (methodological)}, pages 1--38, 1977.

\bibitem[Efron et~al.(1975)]{efron1975defining}
Bradley Efron et~al.
\newblock Defining the curvature of a statistical problem (with applications to
  second order efficiency).
\newblock \emph{The Annals of Statistics}, 3\penalty0 (6):\penalty0 1189--1242,
  1975.

\bibitem[Hughes(1999)]{hughes1999mixed}
James~P Hughes.
\newblock Mixed effects models with censored data with application to hiv rna
  levels.
\newblock \emph{Biometrics}, 55\penalty0 (2):\penalty0 625--629, 1999.

\bibitem[Hull(1994)]{hull1994database}
Jonathan~J. Hull.
\newblock A database for handwritten text recognition research.
\newblock \emph{IEEE Transactions on pattern analysis and machine
  intelligence}, 16\penalty0 (5):\penalty0 550--554, 1994.

\bibitem[Johnson and Zhang(2013)]{johnson:zhang:2013}
Rie Johnson and Tong Zhang.
\newblock Accelerating stochastic gradient descent using predictive variance
  reduction.
\newblock In \emph{Advances in neural information processing systems}, pages
  315--323, 2013.

\bibitem[Karimi et~al.(2019)Karimi, Wai, Moulines, and
  Lavielle]{karimi2019global}
Belhal Karimi, Hoi-To Wai, {\'E}ric Moulines, and Marc Lavielle.
\newblock On the global convergence of (fast) incremental expectation
  maximization methods.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2833--2843, 2019.

\bibitem[Kuhn et~al.(2019)Kuhn, Matias, and Rebafka]{kuhn2019properties}
Estelle Kuhn, Catherine Matias, and Tabea Rebafka.
\newblock Properties of the stochastic approximation em algorithm with
  mini-batch sampling.
\newblock \emph{arXiv preprint arXiv:1907.09164}, 2019.

\bibitem[Liang and Klein(2009)]{liang2009online}
Percy Liang and Dan Klein.
\newblock Online em for unsupervised models.
\newblock In \emph{Proceedings of human language technologies: The 2009 annual
  conference of the North American chapter of the association for computational
  linguistics}, pages 611--619, 2009.

\bibitem[Maire et~al.(2016)Maire, Moulines, and Lefebvre]{maire2016online}
Florian Maire, Eric Moulines, and Sidonie Lefebvre.
\newblock Online em for functional data, 2016.
\newblock URL \url{http://arxiv.org/abs/1604.00570}.
\newblock cite arxiv:1604.00570v1.pdf.

\bibitem[McCulloch(1997)]{mcculloch1997maximum}
Charles~E McCulloch.
\newblock Maximum likelihood algorithms for generalized linear mixed models.
\newblock \emph{Journal of the American statistical Association}, 92\penalty0
  (437):\penalty0 162--170, 1997.

\bibitem[McLachlan and Krishnan(2007)]{mclachlan2007algorithm}
Geoffrey McLachlan and Thriyambakam Krishnan.
\newblock \emph{The {EM} algorithm and extensions}, volume 382.
\newblock John Wiley \& Sons, 2007.

\bibitem[Meyn and Tweedie(2012)]{meyn2012markov}
Sean~P Meyn and Richard~L Tweedie.
\newblock \emph{Markov chains and stochastic stability}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Neal and Hinton(1998)]{neal1998view}
Radford~M Neal and Geoffrey~E Hinton.
\newblock A view of the {EM} algorithm that justifies incremental, sparse, and
  other variants.
\newblock In \emph{Learning in graphical models}, pages 355--368. Springer,
  1998.

\bibitem[Ng and McLachlan({2003})]{ngChoice2003}
SK~Ng and GJ~McLachlan.
\newblock {On the choice of the number of blocks with the incremental {EM}
  algorithm for the fitting of normal mixtures}.
\newblock \emph{{Statistics and Computing}}, {13}\penalty0 ({1}):\penalty0
  {45--55}, {FEB} {2003}.
\newblock ISSN {0960-3174}.
\newblock \doi{{10.1023/A:1021987710829}}.

\bibitem[Nguyen et~al.(2020)Nguyen, Forbes, and McLachlan]{nguyen2020mini}
Hien~D Nguyen, Florence Forbes, and Geoffrey~J McLachlan.
\newblock Mini-batch learning of exponential family finite mixture models.
\newblock \emph{Statistics and Computing}, pages 1--18, 2020.

\bibitem[Reddi et~al.(2016)Reddi, Sra, P{\'o}czos, and Smola]{reddi2016fast}
Sashank~J Reddi, Suvrit Sra, Barnab{\'a}s P{\'o}czos, and Alex Smola.
\newblock Fast incremental method for nonconvex optimization.
\newblock \emph{arXiv preprint arXiv:1603.06159}, 2016.

\bibitem[Robbins and Monro(1951)]{robbins1951stochastic}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock \emph{The annals of mathematical statistics}, pages 400--407, 1951.

\bibitem[Wei and Tanner(1990)]{wei1990monte}
Greg~CG Wei and Martin~A Tanner.
\newblock A monte carlo implementation of the em algorithm and the poor man's
  data augmentation algorithms.
\newblock \emph{Journal of the American statistical Association}, 85\penalty0
  (411):\penalty0 699--704, 1990.

\bibitem[Wu et~al.(1983)]{wu1983convergence}
CF~Jeff Wu et~al.
\newblock On the convergence properties of the {EM} algorithm.
\newblock \emph{The Annals of statistics}, 11\penalty0 (1):\penalty0 95--103,
  1983.

\end{thebibliography}
