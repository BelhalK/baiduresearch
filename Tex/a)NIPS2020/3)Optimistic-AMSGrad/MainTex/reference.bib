

@article{mertikopoulos2018optimistic,
  title={Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile},
  author={Mertikopoulos, Panayotis and Lecouat, Bruno and Zenati, Houssam and Foo, Chuan-Sheng and Chandrasekhar, Vijay and Piliouras, Georgios},
  journal={arXiv preprint arXiv:1807.02629},
  year={2018}
}

@inproceedings{chiang2012online,
  title={Online optimization with gradual variations},
  author={Chiang, Chao-Kai and Yang, Tianbao and Lee, Chia-Jung and Mahdavi, Mehrdad and Lu, Chi-Jen and Jin, Rong and Zhu, Shenghuo},
  booktitle={Conference on Learning Theory},
  pages={6--1},
  year={2012}
}

@article{defossez2020convergence,
  title={On the Convergence of Adam and Adagrad},
  author={D{\'e}fossez, Alexandre and Bottou, L{\'e}on and Bach, Francis and Usunier, Nicolas},
  journal={arXiv preprint arXiv:2003.02395},
  year={2020}
}

@article{ghadimi2013stochastic,
	Author = {Ghadimi, Saeed and Lan, Guanghui},
	Date-Added = {2018-10-27 15:50:56 -0400},
	Date-Modified = {2018-10-27 15:50:56 -0400},
	Journal = {SIAM Journal on Optimization},
	Number = {4},
	Pages = {2341--2368},
	Publisher = {SIAM},
	Title = {Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
	Volume = {23},
	Year = {2013}}

@article{yan2018unified,
  title={A unified analysis of stochastic momentum methods for deep learning},
  author={Yan, Yan and Yang, Tianbao and Li, Zhe and Lin, Qihang and Yang, Yi},
  journal={arXiv preprint arXiv:1808.10396},
  year={2018}
}

@article{zhou2018convergence,
  title={On the convergence of adaptive gradient methods for nonconvex optimization},
  author={Zhou, Dongruo and Tang, Yiqi and Yang, Ziyan and Cao, Yuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1808.05671},
  year={2018}
}

@ARTICLE{LH19,
  title={Decoupled Weight Decay Regularization.},
  author={Ilya Loshchilov and Frank Hutter},
  journal   = {ICLR},
  year      = {2019}
}

@ARTICLE{LJHCLGH19,
  title={On the Variance of the Adaptive Learning Rate and Beyond.},
  author={Liyuan Liu and Haoming Jiang and Pengcheng He and Weizhu Chen and Xiaodong Liu and Jianfeng Gao and Jiawei Han},
  journal   = {arXiv:1908.03265},
  year      = {2019}
}

@ARTICLE{HHS17,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks.},
  author={Elad Hoffer and Itay Hubara and Daniel Soudry.},
  journal   = {NPIS},
  year      = {2017}
}

@ARTICLE{KS17,
  title={Improving generalization performance by switching from adam to sgd.},
  author={Nitish Shirish Keskar and Richard Socher.},
  journal   = {arXiv:1712.07628},
  year      = {2017}
}

@ARTICLE{KS17,
  title={Improving generalization performance by switching from adam to sgd.},
  author={Nitish Shirish Keskar and Richard Socher.},
  journal   = {arXiv:1712.07628},
  year      = {2017}
}


@ARTICLE{WRSSR17,
  title={The marginal value of adaptive gradient methods in machine learning.},
  author={Ashia C Wilson and Rebecca Roelofs and Mitchell Stern and Nati Srebro and Benjamin Recht.},
  journal   = {NIPS},
  year      = {2017}
}


@ARTICLE{CG18,
  title={Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks.},
  author={Jinghui Chen and Quanquan Gu},
  journal   = {arXiv:1806.06763},
  year      = {2018}
}


@ARTICLE{SRKKS19,
  title={Escaping Saddle Points with Adaptive Gradient Methods.},
  author={Matthew Staib and Sashank J. Reddi and Satyen Kale and Sanjiv Kumar and Suvrit Sra},
  journal   = {ICML},
  year      = {2019}
}

@ARTICLE{AGKS19,
  title={Memory Efficient Adaptive Optimization.},
  author={Rohan Anil and Vineet Gupta and Tomer Koren and Yoram Singer},
  journal   = {NeurIPS},
  year      = {2019}
}

@ARTICLE{GKS19,
  title={Shampoo: Preconditioned Stochastic Tensor Optimization.},
  author={Vineet Gupta and Tomer Koren and Yoram Singer},
  journal   = {ICML},
  year      = {2018}
}

@ARTICLE{LXLS19,
  title={Adaptive Gradient Methods with Dynamic Bound of Learning Rate.},
  author={Liangchen Luo and Yuanhao Xiong and Yan Liu and Xu Sun},
  journal   = {ICLR},
  year      = {2019}
}


@ARTICLE{ZZLWZY19,
  title={AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods.},
  author={Zhiming Zhou and Qingru Zhang and Guansong Lu and Hongwei Wang and Weinan Zhang and Yong Yu},
  journal   = {ICLR},
  year      = {2019}
}

@ARTICLE{BG19,
  title={Riemannian Adaptive Optimization Methods.},
  author={Gary Becigneul and Octavian-Eugen Ganea},
  journal   = {ICLR},
  year      = {2019}
}


@ARTICLE{DBXCR19,
  title={Direct Nonlinear Acceleration},
  author={Aritra Dutta and El Houcine Bergou and Yunming Xiao and Marco Canini and Peter Richtarik},
  journal   = {arXiv:1905.11692},
  year      = {2019}
}


@ARTICLE{MG15,
  title={Optimizing Neural Networks with Kronecker-factored Approximate Curvature},
  author={James Martens and Roger Grosse},
  journal   = {ICML},
  year      = {2015}
}

@ARTICLE{LSGB11,
  title={One shot learning of simple visual concepts},
  author={Brenden M. Lake and Ruslan Salakhutdinov and Jason Gross and Joshua B. Tenenbaum},
  journal   = {CogSci},
  year      = {2011}
}


@ARTICLE{VBLKW16,
  title={Matching networks for one shot learning},
  author={Oriol Vinyals and Charles Blundell and Timothy Lillicrap and Koray Kavukcuoglu and Daan Wierstra},
  journal   = {NIPS},
  year      = {2016}
}


@ARTICLE{DCSP18,
  title={Learning To Learn Around A Common Mean.},
  author={Giulia Denevi and Carlo Ciliberto and Dimitris Stamos and Massimiliano Pontil},
  journal   = {NeurIPS},
  year      = {2018}
}

@ARTICLE{KFT19,
  title={Provable Guarantees for Gradient-Based Meta-Learning.},
  author={Mikhail Khodak and Maria-Florina Balcan and Ameet Talwalkar},
  journal   = {arXiv:1902.10644},
  year      = {2019}
}


@ARTICLE{CLR14,
  title={Sparse Multi-Task Reinforcement Learning.},
  author={Daniele Calandriello and Alessandro Lazaric and Marcello Restelli},
  journal   = {NIPS},
  year      = {2014}
}

@ARTICLE{FAL17,
  title={Model-agnostic meta-learning for fast adaptation of deep
networks.},
  author={Chelsea Finn and Pieter Abbeel and Sergey Levine},
  journal   = {ICML},
  year      = {2017}
}

@ARTICLE{M05,
  title={Algorithmic stability and meta-learning.},
  author={Andreas Maurer},
  journal   = {Journal of Machine Learning Research},
  year      = {2005}
}


@ARTICLE{RS13b,
    title = {Online Learning with Predictable Sequence},
    Author = {Alexander Rakhlin and Karthik Sridharan},
    journal={COLT},
    year = {2013},
}

@ARTICLE{WWB18,
    title = {Adagrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
    Author = {Rachel Ward and Xiaoxia Wu and Leon Bottou.},
    journal={ICML},
    year = {2019},
}

@ARTICLE{ZTYCG18,
    title = {On the convergence of adaptive gradient methods for nonconvex optimization.},
    Author = {Dongruo Zhou and Yiqi Tang and Ziyan Yang and Yuan Cao and Quanquan Gu},
    journal={arXiv:1808.05671},
    year = {2018},
}

@ARTICLE{ZS18,
    title = {On the convergence of adagrad with momentum for training deep neural
networks.},
    Author = {Fangyu Zou and Li Shen},
    journal={arXiv:1808.03408},
    year = {2018},
}

@ARTICLE{LO18,
    title = {On the convergence of stochastic gradient descent with adaptive
stepsizes.},
    Author = {Xiaoyu Li and Francesco Orabona.},
    journal={AISTAT},
    year = {2019},
}

@ARTICLE{CYYZC19,
    title = {Universal Stagewise Learning for Non-Convex Problems with Convergence on Averaged Solutions},
    Author = {Zaiyi Chen and Zhuoning Yuan and Jinfeng Yi and Bowen Zhou and Enhong Chen and Tianbao Yang},
    journal={ICLR},
    year = {2019},
}



%%%%%%%%%%%%%%%%%%%%%%%

@ARTICLE{MY16,
    title = {Accelerating Optimization via Adaptive Prediction},
    Author = {Mehryar Mohri and Scott Yang},
    journal={AISTATS},
    year = {2016},
}


@ARTICLE{LLM11,
  title={Primal-dual first-order methods with $${\mathcal {O}(1/\epsilon)}$$iteration-complexity for cone programming},
  author={Guanghui Lan and Zhaosong Lu and Renato D. C. Monteiro},
  journal   = {Mathematical Programming},
  year      = {2011}
}

@ARTICLE{T08,
  title={On accelerated proximal gradient methods for convex-concave optimization},
  author={Paul Tseng},
  year      = {2008}
}

@ARTICLE{ZRSKK18,
  title = {Adaptive Methods for Nonconvex Optimization},
  author = {Manzil Zaheer and Sashank Reddi and Devendra Sachan and Satyen Kale and Sanjiv Kumar},
  journal={NeurIPS},
  year = {2018},

}

@ARTICLE{CLSH19,
    title = {On the Convergence of A Class of Adam-Type Algorithms for Non-Convex Optimization},
    Author = {Xiangyi Chen and Sijia Liu and Ruoyu Sun and Mingyi Hong},
    journal={ICLR},
    year = {2019},
}


@ARTICLE{DISZ18,
    title = {Training GANs with Optimism},
    Author = {Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
    journal={ICLR},
    year = {2018},
}

@ARTICLE{H14,
    title = {Introduction to Online Convex Optimization },
    Author = {Elad Hazan},
    journal = {Foundations and Trends in Optimization},
    year = {2016},
}


@ARTICLE{CCG04,
  title = {On the generalization ability of on-line learning algorithms},
  author    = {Nicol{\'o'} Cesa-Bianchi and Alex Conconi and Claudio Gentile},
  journal = {Information Theory, IEEE Transactions},
  year = {2004}
}


@ARTICLE{P64,
  title = {Some methods of speeding up the convergence of iteration methods},
  author    = {B. T. Polyak},
  journal = {Mathematics and Mathematical Physics},
  year = {1964}
}


@ARTICLE{SALS15,
Author={Vasilis Syrgkanis and Alekh Agarwal and Haipeng Luo and Robert E. Schapire},
title={Fast Convergence of Regularized Learning in Games},
journal={NIPS},
year = {2015}
}


@ARTICLE{rakhlin2013online,
Author={Alexander Rakhlin and Karthik Sridharan},
title={Optimization, Learning, and Games with Predictable Sequences},
journal={NIPS},
year = {2013}
}


@ARTICLE{CJ12,
Author={Chao-Kai Chiang and Tianbao Yang and Chia-Jung Lee and Mehrdad Mahdavi and Chi-Jen Lu and Rong Jin and Shenghuo Zhu},
title={Online optimization with gradual variations.},
journal={COLT},
year = {2012}
}


@ARTICLE{N04,
    title = {Introductory Lectures on Convex Optimization:
A Basic Course},
    Author = {Yurii Nesterov},
    journal = {Springer},
    year = {2004},
}


@ARTICLE{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={NIPS},
  year={2014}
}


@ARTICLE{DHS11,
title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
author = {John Duchi and Elad Hazan and Yoram Singer},
journal = { Journal of Machine Learning Research (JMLR)},
year = {2011},
}


@ARTICLE{SAB16,
  title = {Regularized Nonlinear Acceleration},
  author    = {Damien Scieur and Alexandre d'Aspremont and Francis Bach},
  journal = {NIPS},
  year = {2016}
}


@ARTICLE{Princeton18,
  title = {Efficient Full-Matrix Adaptive Regularization},
  author    = {Naman Agarwal and Brian Bullins and Xinyi Chen and Elad Hazan and Karan Singh and Cyril Zhang and Yi Zhang},
  journal = {ICML},
  year = {2019}
}

@ARTICLE{BZ13,
  title = {Extrapolation methods: theory and practice},
  author    = {C. Brezinski and M. R. Zaglia},
  journal = {Elsevier},
  year = {2013}
}

@ARTICLE{CJ76,
  title = {A polynomial extrapolation method for finding limits and antilimits of vector sequences},
  author    = {S. Cabay and L. Jackson},
  journal = {SIAM Journal on Numerical Analysis},
  year = {1976}
}

@ARTICLE{WN11,
  title = {Anderson acceleration for fixed-point iterations},
  author    = {H. F. Walker and P. Ni.},
  journal = {SIAM Journal on Numerical Analysis},
  year = {2011}
}

@ARTICLE{E79,
  title = {Extrapolating to the limit of a vector sequence},
  author    = {R. Eddy},
  journal = {Information linkage between applied mathematics and industry, Elsevier},
  year = {1979}
}



@ARTICLE{ALLW18,
  title = {Faster Rates for Convex-Concave Games},
  author    = {Jacob Abernethy and Kevin A. Lai and Kfir Y. Levy and Jun-Kun Wang},
  journal = {COLT},
  year = {2018}
}


@ARTICLE{KB15,
  title = {Adam: A Method for Stochastic Optimization},
  author    = {Diederik P. Kingma and Jimmy Ba},
  journal = {ICLR},
  year = {2015}
}


@ARTICLE{D16,
  title = {Incorporating Nesterov Momentum into Adam},
  author    = {Timothy Dozat},
  journal = {ICLR (Workshop Track)},
  year = {2016}
}

@ARTICLE{MS10,
  title = {Adaptive bound optimization for online convex optimization},
  author    = {H. Brendan McMahan and Matthew J. Streeter},
  journal = {COLT},
  year = {2010}
}

@ARTICLE{TH12,
  title = {RmsProp: Divide the gradient by a running average of its recent magnitude},
  author    = {T. Tieleman and G. Hinton},
  journal = {COURSERA: Neural Networks for Machine Learning},
  year = {2012}
}


@ARTICLE{Z12,
  title = {ADADELTA: An Adaptive Learning Rate Method},
  author    = {Matthew D. Zeiler},
  journal = {arXiv:1212.5701},
  year = {2012}
}

@ARTICLE{DSSC08,
  title = {Efficient projections onto the l1-ball for learning in high dimensions},
  author    = {John C. Duchi and
               Shai Shalev{-}Shwartz and
               Yoram Singer and
               Tushar Chandra},
  journal = {ICML},
  year = {2008}
}

@inproceedings{PS14,
  author    = {Mu Li and
               David G. Andersen and
               Jun Woo Park and
               Alexander J. Smola and
               Amr Ahmed and
               Vanja Josifovski and
               James Long and
               Eugene J. Shekita and
               Bor{-}Yiing Su},
  title     = {Scaling Distributed Machine Learning with the Parameter Server},
  booktitle = {{OSDI}},
  year      = {2014}
}

@ARTICLE{Petumn13,
  title = {More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server},
  author = {Qirong Ho and James Cipar and Henggang Cui and Jin Kyu Kim and Seunghak Lee and Phillip. B. Gibbon
and Garth A. Gibson and Gregory R. Ganger and Eric P. Xing
  },
  booktitle = {NIPS},
  year = {2013}
}


@ARTICLE{GMH13,
  title = {Speech Recognition with Deep Recurrent Neural Networks},
  author = {Alex Graves and Abdel-rahman Mohamed and Geoffrey Hinton},
  journal = {ICASSP},
  year = {2013}
}


@ARTICLE{LFDA17,
  title = {End-to-End Training of Deep Visuomotor Policies},
  author = {Sergey Levine and Chelsea Finn and Trevor Darrell and Pieter Abbeel},
  journal={NIPS},
  year = {2017}
}

@ARTICLE{Atari13,
  title = {Playing Atari With Deep Reinforcement Learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  journal={NIPS (Deep Learning Workshop)},
  year = {2013}
}

@ARTICLE{Gan14,
  title={Generative Adversarial Networks},
  author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  journal={NIPS},
  year={2014}
}


@ARTICLE{Rnet16,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  journal={CVPR},
  year={2016}
}


@ARTICLE{RKK18,
  title={On the Convergence of Adam and Beyond },
  author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
  journal={ICLR},
  year={2018}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@ARTICLE{CNN15,
  title={Striving for Simplicity: The All Convolutional Net},
  author={Jost Springenberg and Alexey Dosovitskiy and Thomas Brox and Martin Riedmiller},
  journal={ICLR},
  year={2015}
}


@ARTICLE{MNIST07,
  title={An Empirical Evaluation of Deep Architectures on Problems with
  Many Factors of Variation},
  author={Hugo Larochelle and Dumitru Erhan and Aaron Courville and James Bergstra and Yoshua Bengio},
  journal={ICML},
  year={2007}
}

@ARTICLE{IMDB11,
  title={Learning Word Vectors for Sentiment Analysis},
  author={Andrew L. Maas and Raymond E. Daly and Peter T. Pham and Dan Huang and Andrew Y. Ng and Christopher Potts},
  journal={ACL},
  year={2011}
}

@inproceedings{Proc:Yu_KDD10,
 author = {Yu, Hsiang-Fu and Hsieh, Cho-Jui and Chang, Kai-Wei and Lin, Chih-Jen},
 title = {Large linear classification when data cannot fit in memory},
 booktitle = {KDD},
 year = {2010},
 location = {Washington, DC, USA},
 pages = {833--842}
}

@inproceedings{WangIP12,
  author    = {De Wang and
               Danesh Irani and
               Calton Pu},
  title     = {Evolutionary study of web spam: Webb Spam Corpus 2011 versus Webb
               Spam Corpus 2006},
  booktitle = {8th International Conference on Collaborative Computing: Networking,
               Applications and Worksharing, CollaborateCom 2012, Pittsburgh, PA,
               USA, October 14-17, 2012},
  pages     = {40--49},
  year      = {2012},
}

@ARTICLE{Proc:ABC_UAI10,
  author    = {Ping Li},
  title     = {Robust LogitBoost and Adaptive Base Class (ABC) LogitBoost},
  journal   = {UAI},
  year      = {2010}
}

@ARTICLE{arXiv:Li2018,
  title={Several Tunable \text{GMM} Kernels},
  author={Ping Li},
  journal   = {arXiv:1805.02830},
  year      = {2018}
}
