\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{RKK18}
\citation{LFDA17}
\citation{Rnet16,goodfellow2014generative}
\citation{Atari13}
\citation{GMH13}
\citation{RKK18}
\citation{KB15}
\citation{TH12}
\citation{Z12}
\citation{D16}
\citation{DHS11,MS10}
\citation{N04}
\citation{P64}
\citation{P64}
\citation{RKK18}
\citation{KB15}
\citation{CJ12,RS13,SALS15,ALLW18}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{KB15,RKK18}
\citation{CJ12,RS13,SALS15,ALLW18}
\citation{H14}
\citation{SALS15}
\citation{KB15}
\citation{P64}
\citation{DHS11}
\citation{RKK18}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{2}{section.2}}
\newlabel{sec:prelim}{{2}{2}{Preliminaries}{section.2}{}}
\newlabel{sec:prelim@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Optimistic Online learning}{2}{subsection.2.1}}
\newlabel{optFTRL}{{1}{2}{Optimistic Online learning}{equation.2.1}{}}
\newlabel{optFTRL@cref}{{[equation][1][]1}{[1][2][]2}}
\newlabel{optFTRL}{{2}{2}{Optimistic Online learning}{equation.2.2}{}}
\newlabel{optFTRL@cref}{{[equation][2][]2}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Adaptive optimization methods}{2}{subsection.2.2}}
\citation{DHS11}
\citation{KB15}
\citation{KB15}
\citation{RKK18}
\citation{RKK18}
\citation{RKK18}
\citation{DHS11}
\citation{N04}
\citation{P64}
\citation{CJ12,RS13,SALS15}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \textsf  {AMSGrad} \citep  {RKK18}}}{3}{algorithm.1}}
\newlabel{alg:amsgrad}{{1}{3}{Adaptive optimization methods}{algorithm.1}{}}
\newlabel{alg:amsgrad@cref}{{[algorithm][1][]1}{[1][2][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\textsf  {OPT-AMSGrad} Algorithm}{3}{section.3}}
\newlabel{sec:opt}{{3}{3}{\textsf {OPT-AMSGrad} Algorithm}{section.3}{}}
\newlabel{sec:opt@cref}{{[section][3][]3}{[1][3][]3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces \textsf  {OPT-AMSGrad}}}{3}{algorithm.2}}
\newlabel{alg:optamsgrad}{{2}{3}{\textsf {OPT-AMSGrad} Algorithm}{algorithm.2}{}}
\newlabel{alg:optamsgrad@cref}{{[algorithm][2][]2}{[1][3][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textsf  {OPT-AMSGRAD}.}}{3}{figure.1}}
\newlabel{fig:scheme}{{1}{3}{\textsf {OPT-AMSGRAD}}{figure.1}{}}
\newlabel{fig:scheme@cref}{{[figure][1][]1}{[1][3][]3}}
\citation{ghadimi2013stochastic}
\citation{ghadimi2013stochastic}
\citation{yan2018unified}
\@writefile{toc}{\contentsline {section}{\numberline {4}Global Convergence of \textsf  {OPT-AMSGrad}}{4}{section.4}}
\newlabel{sec:analysis}{{4}{4}{Global Convergence of \textsf {OPT-AMSGrad}}{section.4}{}}
\newlabel{sec:analysis@cref}{{[section][4][]4}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Nonconvex Analysis: Finite-Time Upper Bound}{4}{subsection.4.1}}
\newlabel{eq:minproblem}{{3}{4}{Nonconvex Analysis: Finite-Time Upper Bound}{equation.4.3}{}}
\newlabel{eq:minproblem@cref}{{[equation][3][]3}{[1][4][]4}}
\newlabel{eq:random}{{4}{4}{Nonconvex Analysis: Finite-Time Upper Bound}{equation.4.4}{}}
\newlabel{eq:random@cref}{{[equation][4][]4}{[1][4][]4}}
\newlabel{ass:nonconv}{{1}{4}{}{assumption.1}{}}
\newlabel{ass:nonconv@cref}{{[assumption][1][]1}{[1][4][]4}}
\newlabel{ass:boundedparam}{{2}{4}{}{assumption.2}{}}
\newlabel{ass:boundedparam@cref}{{[assumption][2][]2}{[1][4][]4}}
\newlabel{ass:smooth}{{3}{4}{}{assumption.3}{}}
\newlabel{ass:smooth@cref}{{[assumption][3][]3}{[1][4][]4}}
\newlabel{ass:guessbound}{{4}{4}{}{assumption.4}{}}
\newlabel{ass:guessbound@cref}{{[assumption][4][]4}{[1][4][]4}}
\newlabel{ass:bounded}{{5}{4}{}{assumption.5}{}}
\newlabel{ass:bounded@cref}{{[assumption][5][]5}{[1][4][]4}}
\newlabel{lem:bound}{{1}{4}{}{Lemma.1}{}}
\newlabel{lem:bound@cref}{{[Lemma][1][]1}{[1][4][]4}}
\newlabel{eq:deftilde}{{5}{4}{Nonconvex Analysis: Finite-Time Upper Bound}{equation.4.5}{}}
\newlabel{eq:deftilde@cref}{{[equation][5][]5}{[1][4][]4}}
\citation{ghadimi2013stochastic}
\citation{ghadimi2013stochastic}
\citation{zhou2018convergence}
\newlabel{lem:momentum}{{2}{5}{}{Lemma.2}{}}
\newlabel{lem:momentum@cref}{{[Lemma][2][]2}{[1][4][]5}}
\newlabel{lem:squarev}{{3}{5}{}{Lemma.3}{}}
\newlabel{lem:squarev@cref}{{[Lemma][3][]3}{[1][5][]5}}
\newlabel{thm:boundopt}{{1}{5}{}{Theorem.1}{}}
\newlabel{thm:boundopt@cref}{{[Theorem][1][]1}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Checking H\ref  {ass:boundedparam} for a Deep Neural Network}{5}{subsection.4.2}}
\newlabel{eq:dnnmodel}{{7}{5}{Checking H\ref {ass:boundedparam} for a Deep Neural Network}{equation.4.7}{}}
\newlabel{eq:dnnmodel@cref}{{[equation][7][]7}{[1][5][]5}}
\newlabel{eq:lossmln}{{8}{5}{Checking H\ref {ass:boundedparam} for a Deep Neural Network}{equation.4.8}{}}
\newlabel{eq:lossmln@cref}{{[equation][8][]8}{[1][5][]5}}
\citation{RS13,SALS15,DISZ18}
\citation{SAB16}
\citation{BZ13}
\citation{WN11}
\citation{CJ76}
\citation{E79}
\citation{SAB16}
\citation{SAB16}
\citation{SAB16}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Training loss vs. Number of iterations. The first row are results with fully-connected NN.}}{6}{figure.2}}
\newlabel{fig:train_loss}{{2}{6}{Training loss vs. Number of iterations. The first row are results with fully-connected NN}{figure.2}{}}
\newlabel{fig:train_loss@cref}{{[figure][2][]2}{[1][5][]6}}
\newlabel{lem:dnnh2}{{4}{6}{}{Lemma.4}{}}
\newlabel{lem:dnnh2@cref}{{[Lemma][4][]4}{[1][5][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical Experiments}{6}{section.5}}
\newlabel{sec:numerical}{{5}{6}{Numerical Experiments}{section.5}{}}
\newlabel{sec:numerical@cref}{{[section][5][]5}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Gradient Estimation}{6}{subsection.5.1}}
\newlabel{nox}{{9}{6}{Gradient Estimation}{equation.5.9}{}}
\newlabel{nox@cref}{{[equation][9][]9}{[1][6][]6}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces \textsf  {Regularized Approximate Minimal Polynomial Extrapolation} (RMPE) \cite  {SAB16} }}{6}{algorithm.3}}
\newlabel{algex}{{3}{6}{Gradient Estimation}{algorithm.3}{}}
\newlabel{algex@cref}{{[algorithm][3][]3}{[1][6][]6}}
\newlabel{key_to_comp}{{10}{6}{Gradient Estimation}{equation.5.10}{}}
\newlabel{key_to_comp@cref}{{[equation][10][]10}{[1][6][]6}}
\citation{RKK18}
\citation{DISZ18}
\citation{RKK18}
\citation{KB15}
\citation{MNIST07}
\citation{CNN15}
\citation{Rnet16}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textit  {MNIST-back-image} + CNN, \textit  {CIFAR10} + Res-18 and \textit  {CIFAR100} + Res-50 . We compare three methods in terms of training (cross-entropy) loss and accuracy, testing loss and accuracy.}}{7}{figure.3}}
\newlabel{fig:testandtrain}{{3}{7}{\textit {MNIST-back-image} + CNN, \textit {CIFAR10} + Res-18 and \textit {CIFAR100} + Res-50 . We compare three methods in terms of training (cross-entropy) loss and accuracy, testing loss and accuracy}{figure.3}{}}
\newlabel{fig:testandtrain@cref}{{[figure][3][]3}{[1][6][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Classification Experiments}{7}{subsection.5.2}}
\citation{MG15}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Choice of parameter $r$}{8}{subsection.5.3}}
\newlabel{fig:compare}{{5.3}{8}{Choice of parameter $r$}{subsection.5.3}{}}
\newlabel{fig:compare@cref}{{[subsection][3][5]5.3}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Some Remarks on the Experiments}{8}{subsection.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{8}{section.6}}
\bibstyle{abbrvnat}
\bibdata{reference}
\bibcite{ALLW18}{{1}{2018}{{Abernethy et~al.}}{{Abernethy, Lai, Levy, and Wang}}}
\bibcite{BZ13}{{2}{2013}{{Brezinski and Zaglia}}{{}}}
\bibcite{CJ76}{{3}{1976}{{Cabay and Jackson}}{{}}}
\bibcite{CJ12}{{4}{2012}{{Chiang et~al.}}{{Chiang, Yang, Lee, Mahdavi, Lu, Jin, and Zhu}}}
\bibcite{DISZ18}{{5}{2018}{{Daskalakis et~al.}}{{Daskalakis, Ilyas, Syrgkanis, and Zeng}}}
\bibcite{defossez2020convergence}{{6}{2020}{{D{\'e}fossez et~al.}}{{D{\'e}fossez, Bottou, Bach, and Usunier}}}
\bibcite{D16}{{7}{2016}{{Dozat}}{{}}}
\bibcite{DHS11}{{8}{2011}{{Duchi et~al.}}{{Duchi, Hazan, and Singer}}}
\bibcite{E79}{{9}{1979}{{Eddy}}{{}}}
\bibcite{ghadimi2013stochastic}{{10}{2013}{{Ghadimi and Lan}}{{}}}
\bibcite{goodfellow2014generative}{{11}{2014}{{Goodfellow et~al.}}{{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio}}}
\bibcite{GMH13}{{12}{2013}{{Graves et~al.}}{{Graves, rahman Mohamed, and Hinton}}}
\bibcite{H14}{{13}{2016}{{Hazan}}{{}}}
\bibcite{Rnet16}{{14}{2016}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{KB15}{{15}{2015}{{Kingma and Ba}}{{}}}
\bibcite{MNIST07}{{16}{2007}{{Larochelle et~al.}}{{Larochelle, Erhan, Courville, Bergstra, and Bengio}}}
\bibcite{LFDA17}{{17}{2017}{{Levine et~al.}}{{Levine, Finn, Darrell, and Abbeel}}}
\bibcite{MG15}{{18}{2015}{{Martens and Grosse}}{{}}}
\bibcite{MS10}{{19}{2010}{{McMahan and Streeter}}{{}}}
\bibcite{Atari13}{{20}{2013}{{Mnih et~al.}}{{Mnih, Kavukcuoglu, Silver, Graves, Antonoglou, Wierstra, and Riedmiller}}}
\bibcite{N04}{{21}{2004}{{Nesterov}}{{}}}
\bibcite{P64}{{22}{1964}{{Polyak}}{{}}}
\bibcite{RS13}{{23}{2013}{{Rakhlin and Sridharan}}{{}}}
\bibcite{RKK18}{{24}{2018}{{Reddi et~al.}}{{Reddi, Kale, and Kumar}}}
\bibcite{SAB16}{{25}{2016}{{Scieur et~al.}}{{Scieur, d'Aspremont, and Bach}}}
\bibcite{CNN15}{{26}{2015}{{Springenberg et~al.}}{{Springenberg, Dosovitskiy, Brox, and Riedmiller}}}
\bibcite{SALS15}{{27}{2015}{{Syrgkanis et~al.}}{{Syrgkanis, Agarwal, Luo, and Schapire}}}
\bibcite{TH12}{{28}{2012}{{Tieleman and Hinton}}{{}}}
\bibcite{WN11}{{29}{2011}{{Walker and Ni.}}{{}}}
\bibcite{yan2018unified}{{30}{2018}{{Yan et~al.}}{{Yan, Yang, Li, Lin, and Yang}}}
\bibcite{Z12}{{31}{2012}{{Zeiler}}{{}}}
\bibcite{zhou2018convergence}{{32}{2018}{{Zhou et~al.}}{{Zhou, Tang, Yang, Cao, and Gu}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proofs of Auxiliary Lemmas}{12}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Proof of Lemma\nobreakspace  {}\ref  {lem:bound}}{12}{subsection.A.1}}
\newlabel{app:lembound}{{A.1}{12}{Proof of Lemma~\ref {lem:bound}}{subsection.A.1}{}}
\newlabel{app:lembound@cref}{{[subappendix][1][2147483647,1]A.1}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Proof of Lemma\nobreakspace  {}\ref  {lem:momentum} }{12}{subsection.A.2}}
\newlabel{app:lemmomentum}{{A.2}{12}{Proof of Lemma~\ref {lem:momentum}}{subsection.A.2}{}}
\newlabel{app:lemmomentum@cref}{{[subappendix][2][2147483647,1]A.2}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Proof of Lemma\nobreakspace  {}\ref  {lem:squarev} }{12}{subsection.A.3}}
\newlabel{app:lemsquarev}{{A.3}{12}{Proof of Lemma~\ref {lem:squarev}}{subsection.A.3}{}}
\newlabel{app:lemsquarev@cref}{{[subappendix][3][2147483647,1]A.3}{[1][12][]12}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Proofs of Theorem\nobreakspace  {}\ref  {thm:boundopt}}{13}{appendix.B}}
\newlabel{app:thmboundopt}{{B}{13}{Proofs of Theorem~\ref {thm:boundopt}}{appendix.B}{}}
\newlabel{app:thmboundopt@cref}{{[appendix][2][2147483647]B}{[1][13][]13}}
\newlabel{eq:smoothness}{{22}{14}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.22}{}}
\newlabel{eq:smoothness@cref}{{[equation][22][2147483647]22}{[1][13][]14}}
\newlabel{eq:termA1}{{24}{14}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.24}{}}
\newlabel{eq:termA1@cref}{{[equation][24][2147483647]24}{[1][14][]14}}
\newlabel{eq:termA2}{{25}{14}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.25}{}}
\newlabel{eq:termA2@cref}{{[equation][25][2147483647]25}{[1][14][]14}}
\newlabel{eq:termA}{{26}{14}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.26}{}}
\newlabel{eq:termA@cref}{{[equation][26][2147483647]26}{[1][14][]14}}
\newlabel{eq:termB1}{{27}{14}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.27}{}}
\newlabel{eq:termB1@cref}{{[equation][27][2147483647]27}{[1][14][]14}}
\newlabel{eq:termB2}{{28}{14}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.28}{}}
\newlabel{eq:termB2@cref}{{[equation][28][2147483647]28}{[1][14][]14}}
\newlabel{eq:termB3}{{30}{15}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.30}{}}
\newlabel{eq:termB3@cref}{{[equation][30][2147483647]30}{[1][14][]15}}
\newlabel{eq:termB}{{32}{15}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.32}{}}
\newlabel{eq:termB@cref}{{[equation][32][2147483647]32}{[1][15][]15}}
\newlabel{eq:term3}{{33}{15}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.33}{}}
\newlabel{eq:term3@cref}{{[equation][33][2147483647]33}{[1][15][]15}}
\newlabel{eq:expectationtildegrad}{{35}{15}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.35}{}}
\newlabel{eq:expectationtildegrad@cref}{{[equation][35][2147483647]35}{[1][15][]15}}
\newlabel{eq:bound1}{{36}{15}{Proofs of Theorem~\ref {thm:boundopt}}{equation.B.36}{}}
\newlabel{eq:bound1@cref}{{[equation][36][2147483647]36}{[1][15][]15}}
\citation{zhou2018convergence}
\citation{defossez2020convergence}
\@writefile{toc}{\contentsline {section}{\numberline {C}Proof of Lemma\nobreakspace  {}\ref  {lem:dnnh2} (Boundedness of the iterates)}{17}{appendix.C}}
\newlabel{app:lemdnnh2}{{C}{17}{Proof of Lemma~\ref {lem:dnnh2} (Boundedness of the iterates)}{appendix.C}{}}
\newlabel{app:lemdnnh2@cref}{{[appendix][3][2147483647]C}{[1][17][]17}}
\newlabel{eq:mildassumptions}{{45}{17}{}{equation.C.45}{}}
\newlabel{eq:mildassumptions@cref}{{[equation][45][2147483647]45}{[1][17][]17}}
\newlabel{eq:boundderivativeloss}{{46}{17}{Proof of Lemma~\ref {lem:dnnh2} (Boundedness of the iterates)}{equation.C.46}{}}
\newlabel{eq:boundderivativeloss@cref}{{[equation][46][2147483647]46}{[1][17][]17}}
\newlabel{eq:decrease}{{49}{18}{Proof of Lemma~\ref {lem:dnnh2} (Boundedness of the iterates)}{equation.C.49}{}}
\newlabel{eq:decrease@cref}{{[equation][49][2147483647]49}{[1][18][]18}}
\newlabel{eq:gradientatell}{{50}{18}{Proof of Lemma~\ref {lem:dnnh2} (Boundedness of the iterates)}{equation.C.50}{}}
\newlabel{eq:gradientatell@cref}{{[equation][50][2147483647]50}{[1][18][]18}}
