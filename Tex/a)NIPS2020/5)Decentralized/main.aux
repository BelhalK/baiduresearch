\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{chilimbi2014project,mcmahan2016communication}
\citation{alistarh2017qsgd,lin2017deep,wangni2018gradient,stich2018sparsified,wang2018atomo,tang2019doublesqueeze}
\citation{aji2017sparse}
\citation{chen2010approximate,ge2013optimized,jegou2010product}
\citation{duchi2011dual}
\citation{lian2017can}
\citation{duchi2011adaptive}
\citation{kingma2014adam}
\citation{reddi2019convergence}
\citation{robbins1951stochastic}
\citation{reddi2020adaptive}
\citation{reddi2020adaptive}
\providecommand\tcolorbox@label[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{nazari2019dadam}
\citation{boyd2011distributed}
\citation{duchi2011dual}
\citation{nedic2009distributed}
\citation{shi2015extra}
\citation{di2016next}
\citation{hong2017prox}
\citation{lian2017can}
\citation{tang2018d}
\citation{assran2018stochastic}
\citation{nazari2019dadam}
\citation{reddi2019convergence}
\citation{duchi2011adaptive}
\citation{kingma2014adam}
\citation{reddi2019convergence}
\citation{ward2018adagrad}
\citation{li2018convergence}
\citation{chen2018convergence}
\citation{zou2018convergence}
\citation{agarwal2018case,luo2019adaptive,zaheer2018adaptive}
\@writefile{toc}{\contentsline {section}{\numberline {2}Decentralized Adaptive Training and Divergence of DADAM}{2}{section.2}}
\newlabel{sec:prelim}{{2}{2}{Decentralized Adaptive Training and Divergence of DADAM}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Related Work}{2}{subsection.2.1}}
\citation{chen2018convergence,ward2018adagrad}
\citation{nazari2019dadam}
\citation{nedic2009distributed,yuan2016convergence}
\citation{nazari2019dadam}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Decentralized Optimization }{3}{subsection.2.2}}
\newlabel{eq:minproblem}{{1}{3}{Decentralized Optimization}{equation.2.1}{}}
\newlabel{a:diff}{{1}{3}{}{assumptionA.1}{}}
\newlabel{a:boundsto}{{2}{3}{}{assumptionA.2}{}}
\newlabel{a:boundedvar}{{3}{3}{}{assumptionA.3}{}}
\newlabel{a:matrixW}{{4}{3}{}{assumptionA.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Divergence of DADAM}{3}{subsection.2.3}}
\citation{nazari2019dadam}
\citation{nazari2019dadam}
\citation{reddi2020adaptive}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces DADAM (with N nodes)\relax }}{4}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg: dadam}{{1}{4}{DADAM (with N nodes)\relax }{figure.caption.2}{}}
\newlabel{thm: dadam_diverge}{{1}{4}{}{theorem.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Decentralized Adaptive Gradient Methods and their Convergence}{4}{section.3}}
\newlabel{sec:main}{{3}{4}{Decentralized Adaptive Gradient Methods and their Convergence}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Importance and Difficulties of Consensus on Adaptive Learning Rates}{4}{subsection.3.1}}
\citation{luo2019adaptive}
\citation{chen2018convergence}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Decentralized Adaptive Gradient Unifying Framework}{5}{subsection.3.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Decentralized Adaptive Gradient Method (with N nodes)\relax }}{5}{figure.caption.3}}
\newlabel{alg: dadaptive}{{2}{5}{Decentralized Adaptive Gradient Method (with N nodes)\relax }{figure.caption.3}{}}
\newlabel{thm: dagm_converge}{{2}{5}{}{theorem.2}{}}
\newlabel{eq: thm1}{{2}{5}{}{equation.3.2}{}}
\citation{yan2018unified,chen2018convergence}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Decentralized AMSGrad (with N nodes)\relax }}{6}{figure.caption.4}}
\newlabel{alg: damsgrad}{{3}{6}{Decentralized AMSGrad (with N nodes)\relax }{figure.caption.4}{}}
\newlabel{thm: dams_converge}{{3}{6}{}{theorem.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Convergence Analysis}{6}{subsection.3.3}}
\@writefile{toc}{\contentsline {paragraph}{Proof of Theorem \ref  {thm: dagm_converge}.}{6}{section*.5}}
\newlabel{eq: seq_z_sketch}{{3}{6}{Proof of Theorem \ref {thm: dagm_converge}}{equation.3.3}{}}
\newlabel{lem: z_diff}{{1}{6}{}{lemma.1}{}}
\newlabel{eq: exp_telescope_sketch}{{4}{7}{Proof of Theorem \ref {thm: dagm_converge}}{equation.3.4}{}}
\newlabel{eq: to_merge_sketch}{{5}{7}{Proof of Theorem \ref {thm: dagm_converge}}{equation.3.5}{}}
\citation{lian2017can}
\citation{lecun1998mnist}
\@writefile{toc}{\contentsline {paragraph}{Proof of Theorem \ref  {thm: dams_converge}}{8}{section*.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Illustrative Numerical Experiments}{8}{subsection.3.4}}
\newlabel{sec:numerical}{{3.4}{8}{Illustrative Numerical Experiments}{subsection.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training loss and Testing accuracy for homogeneous and heterogeneous data\relax }}{8}{figure.caption.7}}
\newlabel{fig: homo_data}{{1}{8}{Training loss and Testing accuracy for homogeneous and heterogeneous data\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{8}{section.4}}
\newlabel{sec:conclusion}{{4}{8}{Conclusion}{section.4}{}}
\bibdata{reference}
\bibcite{agarwal2018case}{{1}{2018}{{Agarwal et~al.}}{{Agarwal, Bullins, Chen, Hazan, Singh, Zhang, and Zhang}}}
\bibcite{aji2017sparse}{{2}{2017}{{Aji and Heafield}}{{}}}
\bibcite{alistarh2017qsgd}{{3}{2017}{{Alistarh et~al.}}{{Alistarh, Grubic, Li, Tomioka, and Vojnovic}}}
\bibcite{assran2018stochastic}{{4}{2018}{{Assran et~al.}}{{Assran, Loizou, Ballas, and Rabbat}}}
\bibcite{boyd2011distributed}{{5}{2011}{{Boyd et~al.}}{{Boyd, Parikh, Chu, Peleato, Eckstein, et~al.}}}
\bibcite{chen2018convergence}{{6}{2018}{{Chen et~al.}}{{Chen, Liu, Sun, and Hong}}}
\bibcite{chen2010approximate}{{7}{2010}{{Chen et~al.}}{{Chen, Guan, and Wang}}}
\bibcite{chilimbi2014project}{{8}{2014}{{Chilimbi et~al.}}{{Chilimbi, Suzue, Apacible, and Kalyanaraman}}}
\bibcite{di2016next}{{9}{2016}{{Di~Lorenzo and Scutari}}{{}}}
\bibcite{duchi2011adaptive}{{10}{2011{a}}{{Duchi et~al.}}{{Duchi, Hazan, and Singer}}}
\bibcite{duchi2011dual}{{11}{2011{b}}{{Duchi et~al.}}{{Duchi, Agarwal, and Wainwright}}}
\bibcite{ge2013optimized}{{12}{2013}{{Ge et~al.}}{{Ge, He, Ke, and Sun}}}
\bibcite{hong2017prox}{{13}{2017}{{Hong et~al.}}{{Hong, Hajinezhad, and Zhao}}}
\bibcite{jegou2010product}{{14}{2010}{{Jegou et~al.}}{{Jegou, Douze, and Schmid}}}
\bibcite{kingma2014adam}{{15}{2014}{{Kingma and Ba}}{{}}}
\bibcite{lecun1998mnist}{{16}{1998}{{LeCun}}{{}}}
\bibcite{li2018convergence}{{17}{2018}{{Li and Orabona}}{{}}}
\bibcite{lian2017can}{{18}{2017}{{Lian et~al.}}{{Lian, Zhang, Zhang, Hsieh, Zhang, and Liu}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Broader Impact of Our Work}{9}{section.5}}
\bibcite{lin2017deep}{{19}{2017}{{Lin et~al.}}{{Lin, Han, Mao, Wang, and Dally}}}
\bibcite{luo2019adaptive}{{20}{2019}{{Luo et~al.}}{{Luo, Xiong, Liu, and Sun}}}
\bibcite{mcmahan2016communication}{{21}{2016}{{McMahan et~al.}}{{McMahan, Moore, Ramage, Hampson, et~al.}}}
\bibcite{nazari2019dadam}{{22}{2019}{{Nazari et~al.}}{{Nazari, Tarzanagh, and Michailidis}}}
\bibcite{nedic2009distributed}{{23}{2009}{{Nedic and Ozdaglar}}{{}}}
\bibcite{reddi2020adaptive}{{24}{2020}{{Reddi et~al.}}{{Reddi, Charles, Zaheer, Garrett, Rush, Kone{\v {c}}n{\`y}, Kumar, and McMahan}}}
\bibcite{reddi2019convergence}{{25}{2019}{{Reddi et~al.}}{{Reddi, Kale, and Kumar}}}
\bibcite{robbins1951stochastic}{{26}{1951}{{Robbins and Monro}}{{}}}
\bibcite{shi2015extra}{{27}{2015}{{Shi et~al.}}{{Shi, Ling, Wu, and Yin}}}
\bibcite{stich2018sparsified}{{28}{2018}{{Stich et~al.}}{{Stich, Cordonnier, and Jaggi}}}
\bibcite{tang2018d}{{29}{2018}{{Tang et~al.}}{{Tang, Lian, Yan, Zhang, and Liu}}}
\bibcite{tang2019doublesqueeze}{{30}{2019}{{Tang et~al.}}{{Tang, Lian, Zhang, and Liu}}}
\bibcite{wang2018atomo}{{31}{2018}{{Wang et~al.}}{{Wang, Sievert, Liu, Charles, Papailiopoulos, and Wright}}}
\bibcite{wangni2018gradient}{{32}{2018}{{Wangni et~al.}}{{Wangni, Wang, Liu, and Zhang}}}
\bibcite{ward2018adagrad}{{33}{2018}{{Ward et~al.}}{{Ward, Wu, and Bottou}}}
\bibcite{yan2018unified}{{34}{2018}{{Yan et~al.}}{{Yan, Yang, Li, Lin, and Yang}}}
\bibcite{yuan2016convergence}{{35}{2016}{{Yuan et~al.}}{{Yuan, Ling, and Yin}}}
\bibcite{zaheer2018adaptive}{{36}{2018}{{Zaheer et~al.}}{{Zaheer, Reddi, Sachan, Kale, and Kumar}}}
\bibcite{zou2018convergence}{{37}{2018}{{Zou and Shen}}{{}}}
\bibstyle{plainnat}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proof of Theorem \ref  {thm: dagm_converge}}{12}{appendix.A}}
\newlabel{app: proof_thm_adm}{{A}{12}{Proof of Theorem \ref {thm: dagm_converge}}{appendix.A}{}}
\newlabel{eq: seq_z}{{6}{12}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.6}{}}
\@writefile{loe}{\contentsline {Lemma*}{\numberline {\let \autodot \@empty }Lemma}{12}{thmt@dummyctr.dummy.1}}
\newlabel{eq: update_z}{{7}{12}{}{equation.A.7}{}}
\newlabel{eq: exp_lip}{{11}{12}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.11}{}}
\newlabel{eq: u_to_u_bar}{{12}{12}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.12}{}}
\newlabel{eq: split_1}{{13}{13}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.13}{}}
\newlabel{eq: exp_split}{{14}{13}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.14}{}}
\newlabel{eq: exp_telescope}{{15}{13}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.15}{}}
\newlabel{eq: T_3_bound_first}{{17}{14}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.17}{}}
\newlabel{eq: update_X}{{18}{14}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.18}{}}
\newlabel{eq: t2_matrix}{{19}{14}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.19}{}}
\newlabel{eq: update_x_decom}{{20}{14}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.20}{}}
\newlabel{eq: x_ql}{{21}{14}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.21}{}}
\newlabel{eq: T_5_bound}{{22}{14}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.22}{}}
\newlabel{eq: T_2_bound}{{24}{15}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.24}{}}
\newlabel{lem: mean_after_max}{{2}{15}{}{lemma.2}{}}
\newlabel{eq: r_decrease}{{25}{15}{}{equation.A.25}{}}
\newlabel{eq: r_reduce}{{26}{16}{}{equation.A.26}{}}
\newlabel{eq: T_6_bound}{{30}{16}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.30}{}}
\newlabel{eq: T_1}{{32}{17}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.32}{}}
\newlabel{eq: diff_u_t}{{33}{18}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.33}{}}
\newlabel{eq: split_var}{{38}{19}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.38}{}}
\newlabel{eq: variance_bound_1}{{41}{20}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.41}{}}
\newlabel{eq: diff_u}{{42}{20}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.42}{}}
\newlabel{eq: diff_g}{{44}{20}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.44}{}}
\newlabel{eq: final_bound}{{46}{21}{Proof of Theorem \ref {thm: dagm_converge}}{equation.A.46}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Proof of Theorem \ref  {thm: dams_converge}}{23}{appendix.B}}
\newlabel{app: proof_ams}{{B}{23}{Proof of Theorem \ref {thm: dams_converge}}{appendix.B}{}}
\newlabel{eq: rep_thm1}{{49}{23}{Proof of Theorem \ref {thm: dams_converge}}{equation.B.49}{}}
\newlabel{eq: sub_thm1}{{52}{23}{Proof of Theorem \ref {thm: dams_converge}}{equation.B.52}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Proof of Lemmas}{25}{appendix.C}}
\newlabel{app: proof_lemmas}{{C}{25}{Proof of Lemmas}{appendix.C}{}}
\newlabel{eq: update_z}{{54}{25}{}{equation.C.54}{}}
\newlabel{eq: r_decrease}{{57}{25}{}{equation.C.57}{}}
\newlabel{eq: r_reduce}{{58}{25}{}{equation.C.58}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Additional experiments and details}{27}{appendix.D}}
\newlabel{app: experiments}{{D}{27}{Additional experiments and details}{appendix.D}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Performance comparison of different stepsizes for DGD\relax }}{27}{figure.caption.9}}
\newlabel{fig: sgd_curve}{{2}{27}{Performance comparison of different stepsizes for DGD\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Performance comparison of different stepsizes for decentralized AMSGrad\relax }}{27}{figure.caption.10}}
\newlabel{fig: amsgrad_curve}{{3}{27}{Performance comparison of different stepsizes for decentralized AMSGrad\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Performance comparison of different stepsizes for DADAM\relax }}{28}{figure.caption.11}}
\newlabel{fig: adam_curve}{{4}{28}{Performance comparison of different stepsizes for DADAM\relax }{figure.caption.11}{}}
