
@inproceedings{wawu19,
  title={AdaGrad stepsizes: sharp convergence over nonconvex landscapes},
  author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
  booktitle={International Conference on Machine Learning},
  pages={6677--6686},
  year={2019}
}

@article{duha11,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@inproceedings{sare18,
  title={On the convergence of adam and beyond},
  author={Sashank, J REDDI and SATYEN, KALE and SANJIV, KUMAR},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{zare18,
  title={Adaptive methods for nonconvex optimization},
  author={Zaheer, Manzil and Reddi, Sashank and Sachan, Devendra and Kale, Satyen and Kumar, Sanjiv},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9793--9803},
  year={2018}
}

@article{romo51,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}



@inproceedings{kiba15,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={In Proceedings
of the 3rd International Conference on Learning Representations (ICLR)},
  year={2015}
}

@article{tige12,
  title={RMSprop: Divide the gradient by a running average of its recent magnitude.},
  author={Tijmen Tieleman and Geoffrey Hinton},
  journal={COURSERA: Neural networks for machine learning},
  year={2012}
}


@inproceedings{wiro17,
title={The marginal value of adaptive gradient methods in machine learning},
  author={Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4148--4158},
  year={2017}
}

@inproceedings{
luxi2019,
title={Adaptive Gradient Methods with Dynamic Bound of Learning Rate},
author={Liangchen Luo and Yuanhao Xiong and Yan Liu},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{keso2017,
  title={Improving generalization performance by switching from adam to sgd},
  author={Keskar, Nitish Shirish and Socher, Richard},
  journal={arXiv preprint arXiv:1712.07628},
  year={2017}
}

@article{chgu2018,
  title={Closing the generalization gap of adaptive gradient methods in training deep neural networks},
  author={Chen, Jinghui and Gu, Quanquan},
  journal={arXiv preprint arXiv:1806.06763},
  year={2018}
}

@inproceedings{reka2018,
title={On the Convergence of Adam and Beyond},
author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
booktitle={International Conference on Learning Representations},
year={2018},
}

@inproceedings{zare2018,
  title={Adaptive methods for nonconvex optimization},
  author={Zaheer, Manzil and Reddi, Sashank and Sachan, Devendra and Kale, Satyen and Kumar, Sanjiv},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9793--9803},
  year={2018}
}

@inproceedings{cheli2019,
title={On the Convergence of A Class of Adam-Type Algorithms  for Non-Convex Optimization},
author={Xiangyi Chen and Sijia Liu and Ruoyu Sun and Mingyi Hong},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{zosh2019,
  title={A sufficient condition for convergences of adam and rmsprop},
  author={Zou, Fangyu and Shen, Li and Jie, Zequn and Zhang, Weizhong and Liu, Wei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={11127--11135},
  year={2019}
}

@article{ghla2013,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}

@inproceedings{hare2016,
  title={Train faster, generalize better: Stability of stochastic gradient descent},
  author={Hardt, Moritz and Recht, Ben and Singer, Yoram},
  booktitle={International Conference on Machine Learning},
  pages={1225--1234},
  year={2016}
}

@article{dwro2014,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Foundations and Trends{\textregistered} in Theoretical Computer Science},
  volume={9},
  number={3--4},
  pages={211--407},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@inproceedings{dwfe2015a,
  title={Generalization in adaptive data analysis and holdout reuse},
  author={Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toni and Reingold, Omer and Roth, Aaron},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2350--2358},
  year={2015}
}

@article{dwfe2015b,
  title={The reusable holdout: Preserving validity in adaptive data analysis},
  author={Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron},
  journal={Science},
  volume={349},
  number={6248},
  pages={636--638},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{dwfe2015c,
  title={Preserving statistical validity in adaptive data analysis},
  author={Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron Leon},
  booktitle={Proceedings of the forty-seventh annual ACM symposium on Theory of computing},
  pages={117--126},
  year={2015},
  organization={ACM}
}

@inproceedings{kula2018,
  title={Data-Dependent Stability of Stochastic Gradient Descent},
  author={Kuzborskij, Ilja and Lampert, Christoph},
  booktitle={International Conference on Machine Learning},
  pages={2820--2829},
  year={2018}
}

@inproceedings{rara2017,
  title={Non-convex learning via Stochastic Gradient Langevin Dynamics: a nonasymptotic analysis},
  author={Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},
  booktitle={Conference on Learning Theory},
  pages={1674--1703},
  year={2017}
}

@inproceedings{mowa2018,
  title={Generalization Bounds of SGLD for Non-convex Learning: Two Theoretical Viewpoints},
  author={Mou, Wenlong and Wang, Liwei and Zhai, Xiyu and Zheng, Kai},
  booktitle={Conference On Learning Theory},
  pages={605--638},
  year={2018}
}

@inproceedings{pejo2018,
  title={Generalization error bounds for noisy, iterative algorithms},
  author={Pensia, Ankit and Jog, Varun and Loh, Po-Ling},
  booktitle={2018 IEEE International Symposium on Information Theory (ISIT)},
  pages={546--550},
  year={2018},
  organization={IEEE}
}

@article{chji2018,
  title={Stability and convergence trade-off of iterative optimization algorithms},
  author={Chen, Yuansi and Jin, Chi and Yu, Bin},
  journal={arXiv preprint arXiv:1804.01619},
  year={2018}
}

@article{lilu2019,
  title={On generalization error bounds of noisy gradient methods for non-convex learning},
  author={Li, Jian and Luo, Xuanyuan and Qiao, Mingda},
  journal={arXiv preprint arXiv:1902.00621},
  year={2019}
}

@article{chmo2011,
  title={Differentially private empirical risk minimization},
  author={Chaudhuri, Kamalika and Monteleoni, Claire and Sarwate, Anand D},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Mar},
  pages={1069--1109},
  year={2011}
}

@inproceedings{basm2014,
  title={Private empirical risk minimization: Efficient algorithms and tight error bounds},
  author={Bassily, Raef and Smith, Adam and Thakurta, Abhradeep},
  booktitle={2014 IEEE 55th Annual Symposium on Foundations of Computer Science},
  pages={464--473},
  year={2014},
  organization={IEEE}
}

@inproceedings{waye2017,
  title={Differentially private empirical risk minimization revisited: Faster and more general},
  author={Wang, Di and Ye, Minwei and Xu, Jinhui},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2722--2731},
  year={2017}
}

@inproceedings{wach2019,
  title={Differentially Private Empirical Risk Minimization with Non-convex Loss Functions},
  author={Wang, Di and Chen, Changyou and Xu, Jinhui},
  booktitle={International Conference on Machine Learning},
  pages={6526--6535},
  year={2019}
}

@inproceedings{waxu2019,
  title={Differentially private empirical risk minimization with smooth non-convex loss functions: A non-stationary view},
  author={Wang, Di and Xu, Jinhui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={1182--1189},
  year={2019}
}

@inproceedings{zhch2018,
  title={Stable Gradient Descent.},
  author={Zhou, Yingxue and Chen, Sheng and Banerjee, Arindam},
  booktitle={UAI},
  pages={766--775},
  year={2018}
}

@article{lebo1998,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@techreport{krhi2009,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  institution={Citeseer}
}

@article{mama1993,
  title={Building a large annotated corpus of english: the Penn Treebank},
  author={Marcus, Mitchell, and Beatrice Santorini, and Mary Ann Marcinkiewicz},
  journal={Computational linguistics-Association for Computational Linguistics},
  volume={19},
  number={2},
  pages={313--330},
  year={1993},
  publisher={MIT Press}
}

@inproceedings{stni2018,
title={Regularizing and Optimizing {LSTM} Language Models},
author={Stephen Merity and Nitish Shirish Keskar and Richard Socher},
booktitle={International Conference on Learning Representations},
year={2018},
}

@inproceedings{hezh2016,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{sizi2014,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}


@book{shbe14,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@article{boel02,
  title={Stability and generalization},
  author={Bousquet, Olivier and Elisseeff, Andr{\'e}},
  journal={Journal of machine learning research},
  volume={2},
  number={Mar},
  pages={499--526},
  year={2002}
}

@inproceedings{abch16,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  pages={308--318},
  year={2016}
}

@article{dwro16,
  title={Concentrated Differential Privacy},
  author={Dwork, Cynthia and Rothblum, Guy N},
  journal={arXiv preprint arXiv:1603.01887},
  year={2016}
}

@inproceedings{bust16,
  title={Concentrated differential privacy: Simplifications, extensions, and lower bounds},
  author={Bun, Mark and Steinke, Thomas},
  booktitle={Theory of Cryptography Conference},
  pages={635--658},
  year={2016},
  organization={Springer}
}

@article{zhta18,
  title={On the convergence of adaptive gradient methods for nonconvex optimization},
  author={Zhou, Dongruo and Tang, Yiqi and Yang, Ziyan and Cao, Yuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1808.05671},
  year={2018}
}