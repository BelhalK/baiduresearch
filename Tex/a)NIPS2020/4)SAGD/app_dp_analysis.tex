


\begin{comment}
\textbf{Assumptions}
\begin{enumerate}
    \item  $ f: \mathbb{R}^d \rightarrow \mathbb{R}$ is differentiable (not necessarily convex), bounded from below by $f^\star$,
and has L-Lipschitz gradient, i.e.,
\begin{equation}
    \nabla f(\w) -\nabla f(\w^\prime) \leq L \|\w-\w^\prime \|, ~ \forall \w, \w^\prime \in \cW
\end{equation}
\item  The noisy gradient is bounded:
\begin{equation}
    \|\tilde \g_t\|_2^2 \leq G
\end{equation}

\item  The $l_1$ norm of the individual gradient is bounded:
\begin{equation}
    \|\nabla \ell (\w,\z) \|_1 \leq G_1, \ \ \  \forall \w \in \cW, \z \in \cZ
\end{equation}
\end{enumerate}


\textbf{Generalization guarantee of differential privacy}




\begin{lemm} \label{lem: gen_basic}
Let $\cA$ be an $\epsilon$-differentially private gradient descent algorithm 
which has access to the training set $S$ of size $n$. Let $\w_t = \cA(S)$ be the parameters generated at each iteration $t \in [T]$ and $\hat \g_t$ be the empircal gradient on $S$. Them, for any $\sigma >0$, $\beta \geq 6\exp(\frac{-\sigma^2 n}{4G_1^2})$, if the privacy cost of $\cA$ satisfies $\epsilon \leq \frac{\sigma}{2G_1}$, we have
\begin{equation}
    \mathbb{P}\left\{ |\hat \g_t^i - \g_t^i| \geq  \sigma \right\} \leq \beta,
\end{equation}
for every $ i\in [d]$ and every $t \in [T]$.
\end{lemm}
\end{comment}



\begin{comment}
\begin{lemm} 
Let $\cA$ be an $(\epsilon, \delta)$-differentially private gradient descent algorithm 
which has access to the training set $S$ of size $n$. Let $\w_t = \cA(S)$ be the parameters generated at each iteration $t \in [T]$ and $\hat \g_t$ be the empircal gradient on $S$. Them, for any $\sigma >0$, $\beta > 0$, if the privacy cost of $\cA$ satisfies $\varepsilon \leq \frac{\sigma}{13}$, $\delta \leq \frac{\sigma \beta}{26 \ln(26/\sigma)}$ and the sample size $n \geq \frac{2\ln(8/\delta)}{\varepsilon^2}$, we have
\begin{equation}
    \mathbb{P}\left\{ |\hat \g_t^i - \g_t^i| \geq  \sigma \right\} \leq \beta,
\end{equation}
for every $ i\in [d]$ and every $t \in [T]$.
\end{lemm}
\end{comment}


%\textbf{Proof of Lemma \ref{lem: gen_adv}:} 



%Note that Lemma \ref{lem: gen_adv} is the instantiation of Corollary 8 from \cite{dwfe15}.


%\subsection{Proof of Lemma \ref{lemma dpp}:} 

%\begin{proof}
%At each iteration $t$, the algorithm is composed of two sequential parts: \textbf{DPG} to access the training set $S$ and compute $\tilde \g_t$, and parameter update based on estimated $\tilde \g_t$. We mark the \textbf{DPG} as part $\mathcal{A}$ and the gradient descent as part $\mathcal{B}$. We first show $\mathcal{A}$ preserves $\frac{G_1}{n\sigma}$-differential privacy. Then according to the \emph{post-processing property} of differential privacy (Proposition 2.1 in \cite{dwro2014}) we have $\mathcal{B} \circ \mathcal{A}$ is also $\frac{G_1}{n\sigma}$-differentially private.
	
%The part $\mathcal{A}$ (DPG-Lap) uses the basic tool from differential privacy, the ``Laplace Mechanism'' (Definition 3.3 in \citep{dwro2014}). 
%The Laplace Mechanism adds i.i.d. Laplace noise to each coordinate of the output. Adding noise from $Lap(\sigma)$ to a query of $G_1/n$
% sensitivity preserves $G_1/n\sigma$-differential privacy by ( Theorem 3.6 in \cite{dwro2014}).
 %Over $T$ iterations, we have $T$ applications of a DPG-Lap. By the advanced composition theorem (Theorem 3.20 in \cite{dwro2014}), $T$ applications of a $\frac{G_1}{n\sigma}$-differentially private algorithm is $(\frac{\sqrt{T \ln(1/\delta)} G_1}{n\sigma}, \delta)$-deferentially private. 
 %So SAGD with DPG-Lap is $(\frac{\sqrt{T \ln(2/\delta)} 2G_1}{n\sigma}, \delta)$-deferentially private.
%\end{proof}




%\subsection{Batch Sparse Vector Mechanism}

%\subsection{Proof of Lemma \ref{lemma: dpp-sparse}:}


By applying Theorem 8 from \citet{dwfe2015a} to gradient computation, we can get the Lemma \ref{lem: gen_adv}.

\lemgenadv*

\proof 
Theorem 8 in \citet{dwfe2015a}  shows that in order to achieve generalization error $\tau$ with probability $1-\rho$ for a $(\epsilon, \delta)$-differentially private algorithm (i.e., in order
to guarantee for every function $\phi_t$, $\forall t \in [T]$, we have $\mathbb{P}\left[\left|\mathcal{P}\left[\phi_t\right]-\mathcal{E}_{S}\left[\phi_t\right]\right| \geq \tau\right] \leq \rho$), where $\mathcal{P}\left[\phi_t\right]$ is the population value, $\mathcal{E}_{S}\left[\phi_t\right]$ is the empirical value evaluated on $S$ and $\rho$ and $\tau$ are any positive constant, we can set the $\epsilon \leq \frac{\tau}{13}$ and $\delta \leq \frac{\tau \rho}{26 \ln (26 / \tau)}$. In our context, $\tau = \sigma$, $\beta =\rho$, $\phi_t$ is 
the gradient computation function $\nabla \ell(\w_t,\z)$,  $\mathcal{P}\left[\phi_t\right]$ represents the population gradient $\g_t^i$, $\forall i\in [p]$, and $\mathcal{E}_{S}\left[\phi_t\right]$ represents the sample gradient $\hat \g_t^i$, $\forall i\in [p]$. Thus we have $\mathbb{P}\left\{\left|\hat{\mathbf{g}}_{t}^{i}-\mathbf{g}_{t}^{i}\right| \geq \tau\right\} \leq \rho$ if $\epsilon \leq \frac{\sigma}{13}, \delta \leq \frac{\sigma \beta}{26 \ln (26 / \sigma)}$.

\subsection{Proof of Lemma \ref{lemma dpp}}


\lemdpp*

\begin{proof}
At each iteration $t$, the algorithm is composed of two sequential parts: DPG to access the training set $S$ and compute $\tilde \g_t$, and parameter update based on estimated $\tilde \g_t$. We mark the DPG as part $\mathcal{A}$ and the gradient descent as part $\mathcal{B}$. We first show $\mathcal{A}$ preserves $\frac{G_1}{n\sigma}$-differential privacy. Then according to the \emph{post-processing property} of differential privacy (Proposition 2.1 in~\cite{dwro2014}) we have $\mathcal{B} \circ \mathcal{A}$ is also $\frac{G_1}{n\sigma}$-differentially private.
	
The part $\mathcal{A}$ (DPG-Lap) uses the basic tool from differential privacy, the ``Laplace Mechanism'' (Definition 3.3 in~\citep{dwro2014}). 
The Laplace Mechanism adds i.i.d. Laplace noise to each coordinate of the output. Adding noise from $Lap(\sigma)$ to a query of $G_1/n$
 sensitivity preserves $G_1/n\sigma$-differential privacy by ( Theorem 3.6 in~\cite{dwro2014}).
 Over $T$ iterations, we have $T$ applications of a DPG-Lap. By the advanced composition theorem (Theorem 3.20 in~\cite{dwro2014}), $T$ applications of a $\frac{G_1}{n\sigma}$-differentially private algorithm is $(\frac{\sqrt{T \ln(1/\delta)} G_1}{n\sigma}, \delta)$-differentially private. 
 So SAGD with DPG-Lap is $(\frac{\sqrt{T \ln(1/\delta)} 2G_1}{n\sigma}, \delta)$-differentially private.
\end{proof}

\subsection{Proof of Theorem \ref{thm: acc_basic}}

\theoaccbasic*

\begin{proof}
The concentration bound is decomposed into two parts:
\begin{equation}
    \begin{split}
    &\mathbb{P} 
    \left\{ \|\tilde \g_t - \g_t\| \geq \sqrt{d}\sigma(1+\mu)\right\} \\
    \leq&   
    \underbrace{ \mathbb{P}\left\{ \|\tilde \g_t - \hat \g_t\| \geq  \sqrt{d}\sigma \mu\right\} }_{\text{$T_1$: empirical error}} 
     + \underbrace{\mathbb{P}\left\{ \|\hat \g_t - \g_t\| \geq \sqrt{d}\sigma \right\}}_{\text{$T_2$: generalization error}} \nr
    \end{split}
\end{equation}
In the above inequality, there are two types of error we need to control. The first type of error, referred to as empirical error $T_1$, is the deviation between the differentially
private estimated gradient $\tilde \g_t$ and the empirical gradient $\hat \g_t$. The second type of error, referred to as generalization error $T_2$, is the deviation
between the empirical gradient $\hat \g_t$ and the population gradient $\g_t$. 

The second term $T_2$ can be bounded thorough the generalization guarantee of differential privacy. Recall that from  Lemma~\ref{lem: gen_adv}, under the condition in Theorem~\ref{thm: acc_sparse}, we have for all $t \in [T]$, $i \in [d]$: 
\begin{equation}
    \mathbb{P}\left\{ |\hat \g_t^i - \g_t^i| \geq  \sigma \right\} \leq \beta \nr
\end{equation}
So that we have 
\begin{align} \label{eq: gen1}
   \nr \mathbb{P}\left\{ \|\hat \g_t - \g_t\| \geq  \sqrt{d}\sigma \right\} &\leq \mathbb{P}\left\{ \|\hat \g_t - \g_t\|_\infty \geq  \sigma  \right\} \\ \nr &\leq d \mathbb{P}\left\{ |\hat \g_t^i - \g_t^i| \geq  \sigma \right\} \\ &\leq
    d\beta 
\end{align}

Now we bound the second term $T_1$. Recall that $\tilde \g_t = \hat \g_t + \b_t$, where $\b_t$ is a noise vector with each coordinate drawn from Laplace noise Lap$(\sigma)$. In this case, we have
\begin{align} \label{eq: acc1}
    \nr \mathbb{P}\left\{ \|\tilde \g_t - \hat \g_t\| \geq  \sqrt{d}\sigma \mu \right\} 
    &\leq \mathbb{P} \left\{ \|\b_t\| \geq  \sqrt{d}\sigma \mu \right\} \\ 
  \nr  &\leq \mathbb{P} \left\{ \|\b_t\|_\infty \geq  \sigma \mu \right\} \\ 
  \nr  &\leq d \mathbb{P} \left\{ |\b_t^i| \geq \sigma \mu \right\}\\
    &= d \exp(-\mu)
\end{align}

The second inequality comes from $\|\b_t\| \leq \sqrt{d}\|\b_t\|_\infty$. The
last equality comes from the property of Laplace distribution. Combine \eqref{eq: gen1} and \eqref{eq: acc1}, we complete the proof.
\end{proof}

\subsection{Proof of Lemma \ref{lemma: dpp-sparse}}

\lemdppsparse*

\begin{proof}
At each iteration $t$, the algorithm is composed of two sequential parts: DPG-Sparse (part $\mathcal{A}$) and parameter update based on estimated $\tilde \g_t$ (part $\mathcal{B}$).
%which accesses the training set $S$ and compute $\tilde \g_t$, and parameter update based on estimated $\tilde \g_t$. We mark the DPG-Sparse as part $\mathcal{A}$ and the gradient descent as part $\mathcal{B}$.
We first show $\mathcal{A}$ preserves $\frac{2G_1}{n\sigma}$-differential privacy. Then according to the \emph{post-processing property} of differential privacy (Proposition 2.1 in~\cite{dwro2014}) we have $\mathcal{B} \circ \mathcal{A}$ is also $\frac{2G_1}{n\sigma}$-differentially private.
	
The part $\mathcal{A}$ (DPG-Sparse) is a composition of basic tools from differential privacy, the ``Sparse Vector Algorithm'' (Algorithm 2 in~\citep{dwro2014}) and the ``Laplace Mechanism'' (Definition 3.3 in~\citep{dwro2014}). In our setting, the sparse vector algorithm takes as input a sequence of $T$ sensitivity $G_1/n$ queries, and for each query, attempts to determine whether the value of the query, evaluated on the private dataset $S_1$, is above a fixed threshold $\gamma + \tau$ or below it. In our instantiation, the  $S_1$ is the private data set, and each function corresponds to the gradient computation function $ \hat \g_t$ which is of sensitivity $G_1/n$. 
%SAGD is equivalent to the following procedure: we run the sparse vector algorithm for with $T$ queries corresponding to  gradient computation function $ \hat \g_t, t \in [T]$, and noise rate $\sigma$. 
By the privacy guarantee of the sparse vector algorithm, the sparse vector portion of SAGD satisfies $G_1/n\sigma$-differential privacy. The Laplace mechanism portion of SAGD
satisfies $G_1/n\sigma$-differential privacy by ( Theorem 3.6 in~\cite{dwro2014}). Finally, the composition of two mechanisms satisfies $\frac{2G_1}{n\sigma}$-differential privacy. For the sparse vector technique, only the query that fails the validation, corresponding to the `above threshold', release the privacy
of private dataset $S_1$ and pays a $\frac{2G_1}{n\sigma}$ privacy cost. 
Over all the iterations $T$, We have $C_{s}$ queries fail the validation.
Thus, by the advanced composition theorem (Theorem 3.20 in~\cite{dwro2014}), $C_{s}$ applications of a $\frac{2G}{n\sigma}$-differentially private algorithm is  $(\frac{\sqrt{C_{s} \ln(2/\delta)} 2G_1}{n\sigma}, \delta)$-differentially private. So SAGD with DPG-Sparse is $(\frac{\sqrt{C_{s} \ln(2/\delta)} 2G_1}{n\sigma}, \delta)$-differentially private.
\end{proof}
    


\subsection{Proof of Theorem \ref{thm: acc_sparse}:}

\theoaccsparse*

\begin{proof}
The concentration bound can be decomposed into two parts:
\begin{align}\notag
\mathbb{P}\left\{ \|\tilde \g_t - \g_t\| \geq \sqrt{d}\sigma(1+\mu)\right\}  \leq \underbrace{ \mathbb{P}\left\{ \|\tilde \g_t - \hat \g_{s_1,t}\| \geq \sqrt{d}\sigma \mu\right\} }_{\text{$T_1$: empirical error}} +  \underbrace{\mathbb{P}\left\{ \|\hat \g_{s_1,t} - \g_t\| \geq \sqrt{d}\sigma \right\}}_{\text{$T_2$: generalization error}}
\end{align}
%In the above inequality, there are two types of error we need to control. The first type of error, referred to as empirical error $T_1$, is the the deviation between the differentially
%private estimate gradient $\tilde \g_t$ and the empirical gradient $\hat \g_t$. The second type of error, referred to as generalization error $T_2$, is the deviation
%between the empirical gradient $\hat \g_t$ and the population gradient $\g_t$. 

%The second term $T_2$ can be bounded thorough the generalization guarantee of differential privacy. Recall that from  Lemma \ref{lem: gen_adv}, under the condition in Theorem \ref{thm: acc_sparse}, we have for all $t \in [T]$ and for all $i \in [d]$: 
%\begin{equation}
%    \mathbb{P}\left\{ |\hat \g_{s_1,t}^i - \g_t^i| \geq  \sigma \right\} \leq \beta
%\end{equation}
So that we have 
\begin{align} \notag
    \mathbb{P}\left\{ \|\hat \g_{s_1,t} - \g_t\| \geq  \sqrt{d}\sigma \right\} 
    &\leq \mathbb{P}\left\{ \|\hat \g_{s_1,t} - \g_t\|_\infty \geq  \sigma \right\} \\\notag
    &\leq d \mathbb{P}\left\{ |\hat \g_{s_1,t}^i - \g_t^i| \geq  \sigma \right\} \\\label{eq: gen2}
    &\leq d\beta 
\end{align}

Now we bound the second term $T_1$ by considering two cases, by depending on whether DPG-3 answers the query $\tilde \g_t$ by 
returning $\tilde \g_t = \hat \g_{s_1,t} + \v_t$ or by returning $\tilde \g_t = \hat \g_{s_2,t}$. In the first case, we have 
\begin{equation}
    \|\tilde \g_t - \hat \g_{s_1,t}\| = \|\v_t\| \nr
\end{equation}
and
\begin{equation}
\begin{split}
    \mathbb{P}\left\{ \|\tilde \g_t - \hat \g_{s_1,t}\| \geq \sqrt{d}\sigma \mu  \right\}  = \mathbb{P} \left\{ \|\v_t\| \geq  \sqrt{d}\sigma \mu \right\} \leq d \exp(-\mu) \nr
\end{split}
\end{equation}
The last inequality comes from the $\|\v_t\| \leq \sqrt{d}\|\v_t\|_\infty$ and properties of the Laplace distribution. 

In the second case, we have 
\begin{equation}
    \|\tilde \g_t - \hat \g_{s_1,t} \| = \| \hat \g_{s_2,t} -\hat \g_{s_1,t} \| \leq |\gamma| + |\tau| \nr
\end{equation}
and 
\begin{equation}
\begin{split}
\mathbb{P} \left\{ \|\tilde \g_t - \hat \g_{s_1,t}\| \geq \sqrt{d}\sigma \mu  \right\} =& \mathbb{P} \left\{ |\gamma| + |\tau| 
 \geq   \sqrt{d}\sigma \mu \right\} \\ 
 \leq&
  \mathbb{P} \left\{ |\gamma|  \geq   \frac{2}{6}\sqrt{d}\sigma \mu \right\} +  \mathbb{P} \left\{ |\tau|  \geq   \frac{4}{6}\sqrt{d}\sigma \mu \right\} \\
 =& 2\exp(-\sqrt{d}\mu /6) \nr
\end{split}
\end{equation}

Combining these two cases, we have
\begin{align}\notag 
\mathbb{P} 
\left\{ \|\tilde \g_t - \hat \g_{s_1,t}\| \geq \sqrt{d}\sigma \mu  \right\}  \leq & \max \left\{ 
\mathbb{P} \left\{ \|\v_t\| \geq  \sqrt{d}\sigma \mu \right\}, 
\mathbb{P} \left\{ |\gamma| + |\tau|
 \geq   \sqrt{d}\sigma \mu \right\}
\right\} \\\notag 
\leq& \max \left\{ d\exp(-\mu), 2\exp(-\sqrt{d}\mu /6) \right\} \\\label{eq: acc2}
=& d\exp(-\mu)
\end{align}

Combine \eqref{eq: gen2} and \eqref{eq: acc2}, we complete the proof.

\end{proof}
