\documentclass[11pt]{article}
%\usepackage{fullpage,graphicx,algorithm,algorithmic,bm,amsmath,amsthm,amssymb,color,hyperref,cite,natbib}

% if you need to pass options to natbib, use, e.g.:
%\PassOptionsToPackage{numbers}{natbib}
\usepackage{natbib,fullpage}
\usepackage{bm,amsmath,amsthm,amssymb,multicol,algorithmic,algorithm,enumitem}
\usepackage{wrapfig,lipsum}
\usepackage[textwidth=1cm,textsize=footnotesize]{todonotes}

% ready for submission
\usepackage{neurips_2020}

\usepackage[colorlinks=true,
linkcolor=red,
urlcolor=blue,
citecolor=blue]{hyperref}
\usepackage{hyperref}
\usepackage{cleveref}

\setlength{\parskip}{.2cm}

\newtheorem{Fact}{Fact}
\newtheorem{Lemma}{Lemma}
\newtheorem{Prop}{Proposition}
\newtheorem{Theorem}{Theorem}
\newtheorem{Def}{Definition}
\newtheorem{Corollary}{Corollary}
\newtheorem{Conjecture}{Conjecture}
\newtheorem{Property}{Property}
\newtheorem{Observation}{Observation}
%\theorembodyfont{\rmfamily}
\newtheorem{Exa}{Example}
\newtheorem{assumption}{H\!\!}
\newtheorem{assumptionA}{S\!\!}
\newtheorem{assumptionL}{L\!\!}
\newtheorem{Remark}{Remark}
\newtheorem*{Lemma*}{Lemma}
\newtheorem*{Theorem*}{Theorem}
 \makeatletter
\renewenvironment{proof}[1][\proofname]{%
   \par\pushQED{\qed}\normalfont%
   \topsep6\p@\@plus6\p@\relax
   \trivlist\item[\hskip\labelsep\bfseries#1]%
   \ignorespaces
}{%
   \popQED\endtrivlist\@endpefalse
}
\makeatother

%%%%%%%%%%% Stuffs for Tikz %%%%%%%%%%%%%%%%%%
\usepackage{pgfplots}
\usepackage{xargs}
\usepackage{stmaryrd}
\usetikzlibrary{arrows,shapes,calc,tikzmark,backgrounds,matrix,decorations.markings}
\usepgfplotslibrary{fillbetween}

\pgfplotsset{compat=1.3}

\usepackage{relsize}
\tikzset{fontscale/.style = {font=\relsize{#1}}
    }

\definecolor{lavander}{cmyk}{0,0.48,0,0}
\definecolor{violet}{cmyk}{0.79,0.88,0,0}
\definecolor{burntorange}{cmyk}{0,0.52,1,0}

\def\lav{lavander!90}
\def\oran{orange!30}

\definecolor{asuorange}{rgb}{1,0.699,0.0625}
\definecolor{asured}{rgb}{0.598,0,0.199}
\definecolor{asuborder}{rgb}{0.953,0.484,0}
\definecolor{asugrey}{rgb}{0.309,0.332,0.340}
\definecolor{asublue}{rgb}{0,0.555,0.836}
\definecolor{asugold}{rgb}{1,0.777,0.008}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{shortcuts_OPT}

%\renewcommand{\textwidth}{5.5in}

% Here's the definition of Sb, stolen from amstex
    \makeatletter
    \def\multilimits@{\bgroup
  \Let@
  \restore@math@cr
  \default@tag
 \baselineskip\fontdimen10 \scriptfont\tw@
 \advance\baselineskip\fontdimen12 \scriptfont\tw@
 \lineskip\thr@@\fontdimen8 \scriptfont\thr@@
 \lineskiplimit\lineskip
 \vbox\bgroup\ialign\bgroup\hfil$\m@th\scriptstyle{##}$\hfil\crcr}
    \def\Sb{_\multilimits@}
    \def\endSb{\crcr\egroup\egroup\egroup}
\makeatother

\newtheoremstyle{t}         %name
    {\baselineskip}{2\topsep}      %space above and below
    {\rm}                   %Body font
    {0pt}{\bfseries}  %Heading indent and font
    {}                      %after heading
    { }                      %head after space
    {\thmname{#1}\thmnumber{#2}.}

\theoremstyle{t}
\newtheorem{q}{Q}
\parindent=0pt

%\newcommand{\eric}[1]{\todo[color=red!20]{{\bf EM:} #1}}
%\newcommand{\erici}[1]{\todo[color=red!20,inline]{{\bf EM:} #1}}
%\newcommand{\belhal}[1]{\todo[color=green!20]{{\bf BK:} #1}}
%\newcommand{\belhali}[1]{\todo[color=green!20,inline]{{\bf BK:} #1}}
%\newcommand{\toco}[1]{\todo[color=yellow!20]{{\bf To:} #1}}



\makeatletter
\DeclareRobustCommand*\cal{\@fontswitch\relax\mathcal}
\makeatother

\begin{document}
\title{Federated Stochastic Approximation of the EM Algorithm}
%\author{}
\date{\today}

\maketitle

\begin{abstract}
To be completed
\end{abstract}


\section{SAEM algorithm for Federated Learning}
\begin{itemize}
\item SA of the expectations
\item Monte Carlo approximations
\item Exponential Family
\item Statistics stored on devices and parameters computed on device
\item FedAvg on central server $-->$ boils down to the Averaging of parameters that we may do in standard central settings (Polyak)
\item Applications to PK-PD modeling
\end{itemize}

\section{Notations and Algorithm}

We minimize the negated log incomplete data likelihood 
\begin{align} \label{eq:em_motivate}
\begin{split} 
 \min_{ \theta \in \Theta }~ \overline{L} ( \theta ) \eqdef  L ( \theta ) + r (\theta) \quad \text{with}~~L(\theta) = \frac{1}{n} \sum_{i=1}^n L_i( \theta) \eqdef  \frac{1}{n} \sum_{i=1}^n \big\{ - \log g( y_i ; \theta ) \big\}\eqs,
\end{split} 
\end{align}


Consider a curved exponential family
\beq \label{eq:exp}
f(z_i,y_i; \theta) = h  (z_i,y_i) \textrm{exp} ( \pscal{S(z_i,y_i)}{\phi(\theta)} - \psi(\theta) )\eqs,
\eeq

Then EM reads

\begin{align}\label{eq:definition-overline-bss}
\overline{s}_i(\theta) \eqdef \int_{\Zset} S(z_i,y_i) p(z_i|y_i;\theta) \mu(\rmd z_i) \eqsp,
\end{align}
%\begin{align}\label{eq:definition-overline-bss}
%\begin{split} 
%& \overline{s}(\theta)= \frac{1}{n} \sum_{i=1}^n \overline{s}_i(\theta) \\
%& \text{where}  \quad \overline{s}_i(\theta)= \int_{\Zset} S(z_i,y_i) p(z_i|y_i;\theta) \mu(\rmd z_i) \eqsp,
%\end{split} 
%\end{align}
and the \textit{M-step} is given by
\begin{align}\label{eq:mstep}
\overline{\theta}( \overline{s}(\theta) ) \eqdef \argmin_{ \vartheta \in \theta } ~\big\{ \Pen( \vartheta ) + \psi( \vartheta) - \pscal{ \overline{s}(\theta)}{ \phi ( \vartheta) } \big\} \eqsp.
\end{align}


In the case where the expectations are intractable, then \eqref{eq:definition-overline-bss} becomes:

\beq\label{eq:stats}
\begin{split}
 \tilde{S}^{(k+1)} \eqdef \frac{1}{n} \sum_{i=1}^n \tilde{S}^{(k+1)}_i = \frac{1}{n} \sum_{i=1}^n\frac{1}{M_k} \sum_{m=1}^{M_k} S(z_{i,m}^{(k)}, y_i) \eqs,
\end{split}
\eeq



\subsection{Periodic averaging of the local models}

\begin{algorithm}[H]
\caption{FL-SAEM with parameter averaging} \label{alg:flsaem}
\begin{algorithmic}[1]
%\small
\STATE \textbf{Input}: .
\STATE Init: $\theta_{0} \in \Theta \subseteq \mathbb R^d $, as the global model and $\bar{\theta}_0 =  \frac{1}{n} \sum_{i=1}^n \theta_0$.
\FOR{$r=1$ to $R$}
\FOR{parallel for device $i \in D^{r}$}
\STATE Set $\hat{\theta}^{(0,k)}_i = \hat{\theta}^{(k)}$.
\FOR{$t=1$ to $T$}
\STATE Draw M samples $\{z_{i,m}^{(t,k)}\}_{m=1}^{M}$ under model $\hat{\theta}^{(t,k)}_i$
\STATE Compute the surrogate sufficient statistics $\tilde{S}_{i}^{(t,k+1)}$
\STATE Update local model:
$$
\hat{\theta}^{(t,k+1)}_i = \overline{\theta}( \tilde{S}_i^{(t,k+1)}) 
$$
\ENDFOR
\STATE Devices send $\hat{\theta}^{(T,k+1)}_i$ to server.
\ENDFOR
\STATE Server computes \textbf{the average of the local models}:
$$
\hat{\theta}^{(k+1)} = \frac{1}{n} \sum_{i=1}^n \hat{\theta}^{(T,k+1)}_i
$$ 
and send global model back to the devices. \label{line:final}
\ENDFOR
\end{algorithmic}
\end{algorithm}


\subsection{Periodic averaging of the local statistics}

\begin{algorithm}[H]
\caption{FL-SAEM with statistics averaging} \label{alg:flsaem2}
\begin{algorithmic}[1]
%\small
\STATE \textbf{Input}: .
\STATE Init: $\theta_{0} \in \Theta \subseteq \mathbb R^d $, as the global model and $\bar{\theta}_0 =  \frac{1}{n} \sum_{i=1}^n \theta_0$.
\FOR{$r=1$ to $R$}
\FOR{parallel for device $i \in D^{r}$}
\STATE Set $\hat{\theta}^{(0,k)}_i = \hat{\theta}^{(k)}$.
\FOR{$t=1$ to $T$}
\STATE \textcolor{red}{ Here one local iteration, $T=1$}
\STATE Draw M samples $z_{i,m}^{(k)}$ under model $\hat{\theta}^{(t,k)}_i$
\STATE Compute the surrogate sufficient statistics $\tilde{S}_{i}^{(t,k+1)}$
\ENDFOR
\STATE Devices send local statistics $\tilde{S}_{i}^{(t,k+1)}$ to server.
\ENDFOR
\STATE Server computes \textbf{global model using the aggregated statistics}:
$$
\hat{\theta}^{(k+1)} = \overline{\theta}( \tilde{S}^{(t,k+1)}) 
$$
where $\tilde{S}^{(t,k+1)} = (\tilde{S}_i^{(t,k+1)}, i \in D_r)$  and send global model back to the devices. 
\ENDFOR
\end{algorithmic}
\end{algorithm}



\newpage

\bibliographystyle{abbrvnat}
\bibliography{ref}



%-----------------------------------------------------------------------------
%\vspace{0.4cm}

\end{document} 
