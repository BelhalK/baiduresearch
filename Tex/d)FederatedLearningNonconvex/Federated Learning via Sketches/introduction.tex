% !TEX root = main.tex
\section{Introduction}
Increasing applications in machine learning include the learning of a complex model across a large amount of devices in a distributed manner.
Two natural problems arise from this setting. 
The first one 





The main contributions of this paper are summarized as follows:
\begin{itemize}
    \item We develop a general algorithm for communication-efficient and privacy preserving federated learning based on a novel compression algorithm. 
    This latter leverage two commonly used compression methods and display an unbiased compressed estimator of the full gradient.
    
    \item Based on the current compression methods, we provide 
\end{itemize}

The remaining of the paper is organized as follows.
Section~\ref{sec:problem} gives a formal presentation of the general problem. 
Section~\ref{sec:compression} describes the various compression algorithms used for communication efficiency and privacy preservation, and introduces our new compression method.
The training algorithms are provided in Section~\ref{sec:algos} and their respective analysis in the strongly-convex or nonconvex cases are provided Section~\ref{sec:analysis}.



 

\textbf{Related Work for Distributed Setting:} 


\textbf{Related Work for Privacy-preserving Setting:} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%